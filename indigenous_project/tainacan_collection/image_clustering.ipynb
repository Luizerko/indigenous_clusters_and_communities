{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef9795d-0158-4db9-8f3a-ec9139c1f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading dataset\n",
    "ind_df = pd.read_csv('data/indigenous_collection_processed.csv', index_col='id')\n",
    "print(f'Dataframe columns: \\n{ind_df.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc645b59-5f75-4644-8482-a2aeb836d2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "# Creating skip cell command\n",
    "@register_cell_magic\n",
    "def skip(line, cell):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1297d5-556c-4811-b8d4-1761e8750542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centralizing main imports so we can run the models separately\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from training_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561deae7-07e5-412b-86b4-4f42b9ce3b52",
   "metadata": {},
   "source": [
    "# Image Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dfc3e7-84fa-48da-a625-239a17b0e021",
   "metadata": {},
   "source": [
    "Clustering experiments with image feature extractors. The idea is to fine-tune some pre-trained models on our dataset and then remove the last layer of the model to cluster on the embedding space projections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecfe485-3be5-4694-8198-c50a3d03555e",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a1f9c8-c490-4d69-a6e1-f8aa2d1280e7",
   "metadata": {},
   "source": [
    "For fine-tuning the model on our dataset, we are going to try a few different labels and study how they affect the generated emebdding space. For now, we focus *povo* and *categoria*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce8b405-dd10-44cd-8d6c-31d4c4d81131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out corrupted images\n",
    "corrupted_images = []\n",
    "for index, row in ind_df.loc[ind_df['image_path'].notna()].iterrows():\n",
    "    try:\n",
    "        Image.open(row['image_path'])\n",
    "    except Exception as e:\n",
    "        corrupted_images.append(row['image_path'])\n",
    "        ind_df.loc[index, 'image_path'] = pd.NA\n",
    "print(f'{len(corrupted_images)} corrupted images')\n",
    "\n",
    "# Creating 'image_path_br' column\n",
    "ind_df['image_path_br'] = ind_df['image_path'].values\n",
    "ind_df.loc[ind_df['image_path_br'].notna(), 'image_path_br'] = \\\n",
    "    ind_df.loc[ind_df['image_path_br'].notna(), \\\n",
    "               'image_path'].apply(lambda path: \\\n",
    "                                   f\"data/br_images/{path.split('/')[-1].split('.')[0]}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9804fc-d317-492a-88c1-72cad645cfb4",
   "metadata": {},
   "source": [
    "## ViT Base Patch-16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dd4318-0161-463e-94dc-ba1987cdb366",
   "metadata": {},
   "source": [
    "### Pre-trained Embedding Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb70f6d-7d44-40f5-b2f5-94053a767665",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting the proper device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Building dataset for column 'povo' (though no specific column is used on off-the-shelf model)\n",
    "vit_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "povo_labels, name_to_num, num_to_name = preparing_image_labels(ind_df, 'povo')\n",
    "povo_dataset = ImageDataset(povo_labels, transform=vit_transform, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e247fc-988b-4850-b908-ed363357f2b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Projecting data onto the off-the-shelf pre-trained embedding space from ViT\n",
    "from transformers import ViTModel\n",
    "\n",
    "# Loading model\n",
    "model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "model.to(device)\n",
    "\n",
    "# Getting data\n",
    "povo_dataloader = DataLoader(povo_dataset, batch_size=512, shuffle=True, \\\n",
    "                             num_workers=0, pin_memory=True)\n",
    "\n",
    "# Computing image embeddings\n",
    "image_embeddings, _ = get_embeddings(model, povo_dataloader, device)\n",
    "image_embeddings = np.concatenate(image_embeddings, axis=0)\n",
    "\n",
    "# Computing data projection\n",
    "vanilla_vit_trimap, vanilla_vit_tsne, vanilla_vit_umap = data_projections(image_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4ef9ea-b565-4e07-b343-c0a32c8709a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up memory\n",
    "clean_mem([model, image_embeddings])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f18e80f-1305-4675-8f89-e70f6ee00187",
   "metadata": {},
   "source": [
    "### Fine-Tuning Embedding Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397cc9e7-c214-4327-bc09-827d8b0413c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our own ViT classifier head for fine-tuning\n",
    "class ViTClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ViTClassifier, self).__init__()\n",
    "        self.vit = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "        self.classifier = nn.Linear(self.vit.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.vit(x)\n",
    "        \n",
    "        # Getting embeddings from last_hidden_state of CLS token (maybe pooler_output?)\n",
    "        embeddings = outputs['last_hidden_state'][:, 0, :]\n",
    "        # embeddings = outputs['pooler_output']\n",
    "\n",
    "        logits = self.classifier(embeddings)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0093a1e-f85f-48b9-b75e-391fb8cd390b",
   "metadata": {},
   "source": [
    "#### *povo* Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1eed02-7da5-4671-8136-390d5530246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Studying data distribution to filter out rare classes\n",
    "povo_categories, categories_keys, categories_freq, \\\n",
    "qs, masks = study_class_distribution(povo_labels)\n",
    "\n",
    "# Filtering classes so that we retain around 85% of data\n",
    "povo_filtered_categories = {}\n",
    "povo_filtered_categories_names = {}\n",
    "for c in masks[3][0]:\n",
    "    povo_filtered_categories[categories_keys[c]] = povo_categories[categories_keys[c]]\n",
    "    \n",
    "    povo_filtered_categories_names[num_to_name[categories_keys[c]]] = \\\n",
    "    povo_categories[categories_keys[c]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6a5e63-5680-4a09-a96e-c6fbb91b28b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering dataframe for selected categories\n",
    "threshold_multiplier = 2\n",
    "minority_classes, majority_classes, labels_minority, labels_majority, \\\n",
    "val_labels, test_labels, povo_augmented_dataset, povo_balanced_val_dataset, \\\n",
    "povo_balanced_test_dataset = filter_image_data_distribution(ind_df, \\\n",
    "                                                            povo_filtered_categories_names, \\\n",
    "                                                            vit_transform, \\\n",
    "                                                            threshold_multiplier, \\\n",
    "                                                            'povo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa94d49e-e893-4a83-8917-b34f6a83031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting old and new class distributions\n",
    "plot_class_distributions(povo_categories, povo_filtered_categories, labels_minority, \\\n",
    "                         labels_majority, threshold_multiplier, 'povo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be368210-2317-4991-aac4-12dc1fd6e9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the dataset is still unbalanced, we also create class weights for the loss function\n",
    "povo_class_weights = compute_class_weights(povo_filtered_categories, labels_minority, \\\n",
    "                                           labels_majority, device, threshold_multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fe3bdc-df2c-40ed-b0c7-a2ac7989e256",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Recreating datasets for proper training and testing\n",
    "povo_train_val_labels = povo_labels.copy()\n",
    "povo_test_labels_aux = random.sample(list(povo_train_val_labels), \\\n",
    "                                     int(0.1*len(povo_train_val_labels)))\n",
    "povo_test_labels = {}\n",
    "for key in povo_test_labels_aux:\n",
    "    povo_test_labels[key] = povo_train_val_labels[key]\n",
    "    del povo_train_val_labels[key]\n",
    "    \n",
    "povo_train_val_dataset = ImageDataset(povo_train_val_labels, transform=vit_transform, \\\n",
    "                                      augment=False)\n",
    "povo_test_dataset = ImageDataset(povo_test_labels, transform=vit_transform, augment=False)\n",
    "\n",
    "# Setting-up training, executing training and then running tests\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "num_classes = ind_df['povo'].nunique()\n",
    "model = ViTClassifier(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=2e-5, weight_decay=2e-6)\n",
    "model_name = 'vit_povo'\n",
    "column_name = 'povo'\n",
    "\n",
    "execute_train_test(povo_train_val_dataset, povo_test_dataset, device, batch_size, epochs, \\\n",
    "                   num_classes, model, criterion, opt, model_name, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cadd8d-96a2-4f7a-aa6f-6164a8787dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0871d528-56a5-4773-8e47-92426a19c1cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retraining model with augmented dataset to see the difference in the results\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "num_classes = len(povo_filtered_categories)\n",
    "model = ViTClassifier(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=povo_class_weights)\n",
    "opt = optim.Adam(model.parameters(), lr=2e-5, weight_decay=2e-6)\n",
    "model_name = 'balanced_vit_povo'\n",
    "column_name = 'povo'\n",
    "\n",
    "execute_train_test(povo_augmented_dataset, povo_balanced_test_dataset, device, batch_size, \\\n",
    "                   epochs, num_classes, model, criterion, opt, model_name, column_name, \\\n",
    "                   povo_balanced_val_dataset)\n",
    "\n",
    "povo_vit_trimap, povo_vit_tsne, \\\n",
    "povo_vit_umap, povo_image_indices = compute_classifier_embeddings(povo_dataloader, model, \\\n",
    "                                                                  device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799005dd-9445-498d-839e-b4ab7999f97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0a9205-5eaf-4bbe-ba8c-79f0d81653d8",
   "metadata": {},
   "source": [
    "#### *categoria* Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fade66-3cd8-4a50-a8f1-da9b84b1f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now rebalancing the 'categoria' column\n",
    "categoria_labels, name_to_num, num_to_name = preparing_image_labels(ind_df, 'categoria')\n",
    "categoria_dataset = ImageDataset(categoria_labels, transform=vit_transform)\n",
    "categoria_dataloader = DataLoader(categoria_dataset, batch_size=512, shuffle=True, \\\n",
    "                                  num_workers=0, pin_memory=True)\n",
    "\n",
    "categoria_categories, categories_keys, categories_freq, qs, \\\n",
    "masks = study_class_distribution(categoria_labels)\n",
    "\n",
    "# Filtering out 'etnobotânica' (and 'armas')\n",
    "filter_out = [name_to_num['etnobotânica']]\n",
    "categoria_filtered_categories = {}\n",
    "categoria_filtered_categories_names = {}\n",
    "for c in set(name_to_num.values()) - set(filter_out):\n",
    "    categoria_filtered_categories[categories_keys[c]] = \\\n",
    "    categoria_categories[categories_keys[c]]\n",
    "    \n",
    "    categoria_filtered_categories_names[num_to_name[categories_keys[c]]] = \\\n",
    "    categoria_categories[categories_keys[c]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9493d23c-372a-4c29-a1b1-13bb41f7f1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering dataframe for selected categories\n",
    "threshold_multiplier = 1.5\n",
    "minority_classes, majority_classes, labels_minority, labels_majority, val_labels, \\\n",
    "test_labels, categoria_augmented_dataset, categoria_balanced_val_dataset, \\\n",
    "categoria_balanced_test_dataset = \\\n",
    "filter_image_data_distribution(ind_df, categoria_filtered_categories_names, vit_transform, \\\n",
    "                               threshold_multiplier, 'categoria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051ce382-430c-4026-8484-145c1da501d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting old and new class distributions\n",
    "plot_class_distributions(categoria_categories, categoria_filtered_categories, \\\n",
    "                         labels_minority, labels_majority, threshold_multiplier, 'categoria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f03e8aa-db16-4cfc-a7f3-3b0dc41f4186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the dataset is still unbalanced, we also create class weights for the loss function\n",
    "categoria_class_weights = compute_class_weights(categoria_filtered_categories, \\\n",
    "                                                labels_minority, labels_majority, device, \\\n",
    "                                                threshold_multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47f319d-f46f-4197-bc9b-7006224bac68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Recreating datasets for proper training and testing\n",
    "categoria_train_val_labels = categoria_labels.copy()\n",
    "categoria_test_labels_aux = random.sample(list(categoria_train_val_labels), \\\n",
    "                                          int(0.1*len(categoria_train_val_labels)))\n",
    "categoria_test_labels = {}\n",
    "for key in categoria_test_labels_aux:\n",
    "    categoria_test_labels[key] = categoria_train_val_labels[key]\n",
    "    del categoria_train_val_labels[key]\n",
    "    \n",
    "categoria_train_val_dataset = ImageDataset(categoria_train_val_labels, \\\n",
    "                                           transform=vit_transform, augment=False)\n",
    "categoria_test_dataset = ImageDataset(categoria_test_labels, \\\n",
    "                                      transform=vit_transform, augment=False)\n",
    "\n",
    "# Setting-up training, executing training and then running tests\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "num_classes = ind_df['categoria'].nunique()\n",
    "model = ViTClassifier(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-5, weight_decay=2e-6)\n",
    "model_name = 'vit_categoria'\n",
    "column_name = 'categoria'\n",
    "\n",
    "execute_train_test(categoria_train_val_dataset, categoria_test_dataset, device, batch_size, \\\n",
    "                   epochs, num_classes, model, criterion, opt, model_name, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b870b664-c0e4-43b1-b2a0-b96bfd2461cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddf8fac-6f67-4ea7-ab8c-8d2be9add2e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retraining model with augmented dataset to see the difference in the results\n",
    "batch_size = 16\n",
    "epochs = 30\n",
    "num_classes = len(categoria_filtered_categories)\n",
    "model = ViTClassifier(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=categoria_class_weights)\n",
    "opt = optim.Adam(model.parameters(), lr=3e-6, weight_decay=1e-6)\n",
    "model_name = 'balanced_vit_categoria'\n",
    "column_name = 'categoria'\n",
    "\n",
    "execute_train_test(categoria_augmented_dataset, categoria_balanced_test_dataset, device, \\\n",
    "                   batch_size, epochs, num_classes, model, criterion, opt, model_name, \\\n",
    "                   column_name, categoria_balanced_val_dataset)\n",
    "\n",
    "categoria_vit_trimap, categoria_vit_tsne, categoria_vit_umap, \\\n",
    "categoria_image_indices = compute_classifier_embeddings(categoria_dataloader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f58fdaa-04d0-44fc-93a0-5ebbf9b7a4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201b8d15-cfd1-4048-93e8-267cefb70251",
   "metadata": {},
   "source": [
    "#### *tipo_de_materia_prima* Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c773629-dfd3-43ec-8e5a-c9e8e4117fa7",
   "metadata": {},
   "source": [
    "#### Multi-Head Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81730faf-1ab3-4473-9268-04b25559bc14",
   "metadata": {},
   "source": [
    "### Visualizing and Comparing Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7622319c-08ac-475d-8376-c66bd3e76fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing data for later plot on tool\n",
    "norm_factor = 12\n",
    "vanilla_vit_trimap = normalize(vanilla_vit_trimap, norm_factor)\n",
    "vanilla_vit_tsne = normalize(vanilla_vit_tsne, norm_factor)\n",
    "vanilla_vit_umap = normalize(vanilla_vit_umap, norm_factor)\n",
    "\n",
    "povo_vit_trimap = normalize(povo_vit_trimap, norm_factor)\n",
    "povo_vit_tsne = normalize(povo_vit_tsne, norm_factor)\n",
    "povo_vit_umap = normalize(povo_vit_umap, norm_factor)\n",
    "\n",
    "categoria_vit_trimap = normalize(categoria_vit_trimap, norm_factor)\n",
    "categoria_vit_tsne = normalize(categoria_vit_tsne, norm_factor)\n",
    "categoria_vit_umap = normalize(categoria_vit_umap, norm_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fce310-fb5f-4218-afb7-5ffcb02dbf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing resulting projections\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.suptitle('Comparing Projections of ViT Models')\n",
    "\n",
    "# Plotting vanilla ViT projections\n",
    "for i, (vanilla_vit, proj_name) in enumerate(zip([vanilla_vit_trimap, \\\n",
    "                                                  vanilla_vit_tsne, vanilla_vit_umap], \\\n",
    "                                                 ['TriMap', 't-SNE', 'UMAP'])):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.scatter(vanilla_vit[:, 0], vanilla_vit[:, 1], c='b')\n",
    "    plt.title(\"Vanilla ViT with \" + proj_name)\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "# Plotting ViT fine-tuned on 'povo' projections\n",
    "for i, (povo_vit, proj_name) in enumerate(zip([povo_vit_trimap, \\\n",
    "                                               povo_vit_tsne, povo_vit_umap], \\\n",
    "                                              ['TriMap', 't-SNE', 'UMAP'])):\n",
    "    plt.subplot(3, 3, i+4)\n",
    "    plt.scatter(povo_vit[:, 0], povo_vit[:, 1], c='r')\n",
    "    plt.title(\"ViT Fine-Tuned on 'povo' with \" + proj_name)\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "# Plotting ViT fine-tuned on 'categoria' projections\n",
    "for i, (categoria_vit, proj_name) in enumerate(zip([categoria_vit_trimap, \\\n",
    "                                                    categoria_vit_tsne, categoria_vit_umap], \\\n",
    "                                                   ['TriMap', 't-SNE', 'UMAP'])):\n",
    "    plt.subplot(3, 3, i+7)\n",
    "    plt.scatter(categoria_vit[:, 0], categoria_vit[:, 1], c='g')\n",
    "    plt.title(\"ViT Fine-Tuned on 'categoria' with \" + proj_name)\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d358406-41c1-40ba-8580-398ff90a1872",
   "metadata": {},
   "source": [
    "### Visualizing Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7ccb9a-0d2f-4f97-adc5-686a4310b555",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filtering dataframe to get only the part that contains images\n",
    "filtered_df = ind_df.loc[ind_df['image_path'].notna()]\n",
    "\n",
    "# Visualizing 'povo' cluster\n",
    "visualizing_clusters(filtered_df, povo_vit_umap, povo_image_indices, 'povo', 'UMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a072ba0-1e61-4288-b4ff-27ad22e1c3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing 'categoria' cluster\n",
    "visualizing_clusters(filtered_df, categoria_vit_umap, categoria_image_indices, \\\n",
    "                     'categoria', 'UMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba8e8d-256f-4681-9fa8-8c1026781225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving outputs for visualization tool\n",
    "_ = saving_outputs(filtered_df, povo_labels, povo_vit_umap, povo_image_indices, 'povo', \\\n",
    "                   'povo_vit.csv')\n",
    "\n",
    "_ = saving_outputs(filtered_df, categoria_labels, categoria_vit_umap, \\\n",
    "                   categoria_image_indices, 'categoria', 'categoria_vit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50709824-9e61-4a0e-9963-fd10b5a1f727",
   "metadata": {},
   "source": [
    "## DINOv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c9fd41-14e6-48a0-836f-d4ee23073892",
   "metadata": {},
   "source": [
    "### Pre-Trained Embedding Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c387c93-d1e2-458d-85d8-ebc65a74559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, AutoModel\n",
    "\n",
    "# Rebuilding dataset with DINO transform and dataloader with smaller batch_size because of \n",
    "# the model's size\n",
    "dino_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(256, interpolation=InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop((224, 224)),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "povo_dataset = ImageDataset(povo_labels, tranform=dino_transform, augment=False)\n",
    "povo_dataloader = DataLoader(povo_dataset, batch_size=8, shuffle=True, \\\n",
    "                             num_workers=0, pin_memory=True)\n",
    "\n",
    "# Loading model and pre-processor\n",
    "dino_processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')\n",
    "model = AutoModel.from_pretrained('facebook/dinov2-base')\n",
    "model.to(device)\n",
    "\n",
    "# Projecting data onto the off-the-shelf pre-trained embedding space from DINOv2\n",
    "image_embeddings, _ = get_embeddings(model, povo_dataloader, device, model_name='dino')\n",
    "image_embeddings = np.concatenate(image_embeddings, axis=0)\n",
    "\n",
    "# Computing data reduced-dimensionality projections\n",
    "_, _, vanilla_dino_umap = data_projections(image_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be58a9f5-d316-427f-bbf5-5155d6597e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up memory\n",
    "clean_mem([model, image_embeddings])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fba030-df4f-434a-a90e-d08cebc2e38b",
   "metadata": {},
   "source": [
    "### Fine-Tuning Embedding Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96872a49-4b39-4693-872a-627e5191ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our own DINO classifier head for fine-tuning\n",
    "class DINOClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ViTClassifier, self).__init__()\n",
    "        self.dino = AutoModel.from_pretrained('facebook/dinov2-base')\n",
    "        self.classifier = nn.Linear(self.dino.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.dino(x)\n",
    "        \n",
    "        # Getting embeddings from last_hidden_state of CLS token (maybe pooler_output?)\n",
    "        embeddings = outputs['last_hidden_state'][:, 0, :]\n",
    "        # embeddings = outputs['pooler_output']\n",
    "\n",
    "        logits = self.classifier(embeddings)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6609639-35a5-4fae-b1a8-799d4a37a585",
   "metadata": {},
   "source": [
    "#### *povo* Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39e11a4-c5cb-4524-9dc5-3f2fca00adaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import training_utils\n",
    "# importlib.reload(training_utils)\n",
    "# from training_utils import *\n",
    "\n",
    "# Recreating datasets for proper training and testing\n",
    "povo_train_val_dataset = ImageDataset(povo_train_val_labels, transform=dino_transform, \\\n",
    "                                      augment=False)\n",
    "povo_test_dataset = ImageDataset(povo_test_labels, transform=dino_transform, augment=False)\n",
    "\n",
    "# Setting-up training, executing training and then running tests\n",
    "batch_size = 8\n",
    "epochs = 30\n",
    "num_classes = ind_df['povo'].nunique()\n",
    "model = DINOClassifier(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=2e-5, weight_decay=2e-6)\n",
    "model_name = 'dino_povo'\n",
    "column_name = 'povo'\n",
    "\n",
    "execute_train_test(povo_train_val_dataset, povo_test_dataset, device, batch_size, epochs, \\\n",
    "                   num_classes, model, criterion, opt, model_name, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d344a880-6b48-4743-bf7d-81e8388027c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ed537e-c895-4f46-a748-97bb0cf56995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering dataframe for selected categories. We need to recompute this part of the dataset\n",
    "# because of the different transform used\n",
    "threshold_multiplier = 2\n",
    "minority_classes, majority_classes, labels_minority, labels_majority, \\\n",
    "val_labels, test_labels, povo_augmented_dataset, povo_balanced_val_dataset, \\\n",
    "povo_balanced_test_dataset = filter_image_data_distribution(ind_df, \\\n",
    "                                                            povo_filtered_categories_names, \\\n",
    "                                                            dino_transform, \\\n",
    "                                                            threshold_multiplier, \\\n",
    "                                                            'povo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78db26c8-d6f3-4dbb-8f9f-b6804b352454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retraining model with augmented dataset to see the difference in the results\n",
    "batch_size = 8\n",
    "epochs = 30\n",
    "num_classes = len(povo_filtered_categories)\n",
    "model = DINOClassifier(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=povo_class_weights)\n",
    "opt = optim.Adam(model.parameters(), lr=2e-5, weight_decay=2e-6)\n",
    "model_name = 'balanced_dino_povo'\n",
    "column_name = 'povo'\n",
    "\n",
    "execute_train_test(povo_augmented_dataset, povo_balanced_test_dataset, device, batch_size, \\\n",
    "                   epochs, num_classes, model, criterion, opt, model_name, column_name, \\\n",
    "                   povo_balanced_val_dataset)\n",
    "\n",
    "_, _, \\\n",
    "povo_dino_umap, povo_image_indices = compute_classifier_embeddings(povo_dataloader, model, \\\n",
    "                                                                   device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44177d06-88d6-427d-be2e-f56afda2d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064d659b-247f-4ec8-996f-b0f50e36c3ed",
   "metadata": {},
   "source": [
    "#### *categoria* Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c80e65-f3e3-447b-84b6-af6d6f114a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now creating the 'categoria' dataset\n",
    "categoria_dataset = ImageDataset(categoria_labels, transform=dino_transform)\n",
    "categoria_dataloader = DataLoader(categoria_dataset, batch_size=8, shuffle=True, \\\n",
    "                                  num_workers=0, pin_memory=True)\n",
    "\n",
    "# Recreating datasets for proper training and testing\n",
    "categoria_train_val_dataset = ImageDataset(categoria_train_val_labels, \\\n",
    "                                           transform=dino_transform, augment=False)\n",
    "categoria_test_dataset = ImageDataset(categoria_test_labels, transform=dino_transform, \\\n",
    "                                      augment=False)\n",
    "\n",
    "# Setting-up training, executing training and then running tests\n",
    "batch_size = 8\n",
    "epochs = 30\n",
    "num_classes = ind_df['categoria'].nunique()\n",
    "model = DINOClassifier(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-5, weight_decay=2e-6)\n",
    "model_name = 'dino_categoria'\n",
    "column_name = 'categoria'\n",
    "\n",
    "execute_train_test(categoria_train_val_dataset, categoria_test_dataset, device, batch_size, \\\n",
    "                   epochs, num_classes, model, criterion, opt, model_name, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765e7abf-864d-4e92-a0e7-031725fa9d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff0224d-df2c-432e-87c6-4d8f30906601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering dataframe for selected categories. We need to recompute this part of the dataset\n",
    "# because of the different transform used\n",
    "threshold_multiplier = 1.5\n",
    "minority_classes, majority_classes, labels_minority, labels_majority, \\\n",
    "val_labels, test_labels, categoria_augmented_dataset, categoria_balanced_val_dataset, \\\n",
    "categoria_balanced_test_dataset = \\\n",
    "filter_image_data_distribution(ind_df, categoria_filtered_categories_names, dino_transform, \\\n",
    "                               threshold_multiplier, 'categoria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506c7d49-68a2-4593-86a0-b916298e888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retraining model with augmented dataset to see the difference in the results\n",
    "batch_size = 8\n",
    "epochs = 30\n",
    "num_classes = len(categoria_filtered_categories)\n",
    "model = DINOClassifier(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=povo_class_weights)\n",
    "opt = optim.Adam(model.parameters(), lr=2e-5, weight_decay=2e-6)\n",
    "model_name = 'balanced_dino_categoria'\n",
    "column_name = 'categoria'\n",
    "\n",
    "execute_train_test(categoria_augmented_dataset, categoria_balanced_test_dataset, device, \\\n",
    "                   batch_size, epochs, num_classes, model, criterion, opt, model_name, \\\n",
    "                   column_name, categoria_balanced_val_dataset)\n",
    "\n",
    "_, _, \\\n",
    "categoria_dino_umap, categoria_image_indices = \\\n",
    "compute_classifier_embeddings(categoria_dataloader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498b0ccb-5116-4131-ae55-446a32140d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd39684-1acb-43ef-a8f5-55f1a38de449",
   "metadata": {},
   "source": [
    "#### *tipo_de_materia_prima* Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff69dbc0-c068-49e5-9ead-cba4df5f6621",
   "metadata": {},
   "source": [
    "### Visualizing and Comparing Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57420473-f668-471a-86fa-e3306d01f59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing data for later plot on tool\n",
    "vanilla_dino_umap = normalize(vanilla_dino_umap, norm_factor)\n",
    "povo_dino_umap = normalize(povo_dino_umap, norm_factor)\n",
    "categoria_dino_umap = normalize(categoria_dino_umap, norm_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ef94fc-64d8-4863-9695-7588e6ca47d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing resulting projections\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.suptitle('Comparing Projections of ViT and DINO Models')\n",
    "\n",
    "# Plotting all ViT projections\n",
    "for i, (vit_proj, proj_name) in enumerate(zip([vanilla_vit_umap, \\\n",
    "                                               povo_vit_umap, categoria_vit_umap], \\\n",
    "                                              ['Vanilla', 'povo', 'categoria'])):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.scatter(vit_proj[:, 0], vit_proj[:, 1], c='b')\n",
    "    plt.title(f\"{proj_name} ViT\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "# Plotting all DINO projections\n",
    "for i, (dino_proj, proj_name) in enumerate(zip([vanilla_dino_umap, \\\n",
    "                                                povo_dino_umap, categoria_dino_umap], \\\n",
    "                                               ['Vanilla', 'povo', 'categoria'])):\n",
    "    plt.subplot(3, 3, i+4)\n",
    "    plt.scatter(dino_proj[:, 0], vit_proj[:, 1], c='r')\n",
    "    plt.title(f\"{proj_name} DINO\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
