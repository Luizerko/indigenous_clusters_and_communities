{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad54d83b-f807-40e5-b297-fd046fa68fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe columns: \n",
      "Index(['url', 'thumbnail', 'creation_date', 'modification_date',\n",
      "       'numero_do_item', 'tripticos', 'categoria', 'nome_do_item',\n",
      "       'nome_do_item_dic', 'colecao', 'coletor', 'doador', 'modo_de_aquisicao',\n",
      "       'data_de_aquisicao', 'ano_de_aquisicao', 'data_de_confeccao', 'autoria',\n",
      "       'nome_etnico', 'descricao', 'dimensoes', 'funcao', 'materia_prima',\n",
      "       'tecnica_confeccao', 'descritor_tematico', 'descritor_comum',\n",
      "       'numero_de_pecas', 'itens_relacionados', 'responsavel_guarda',\n",
      "       'inst_detentora', 'povo', 'autoidentificacao', 'lingua',\n",
      "       'estado_de_origem', 'geolocalizacao', 'pais_de_origem', 'exposicao',\n",
      "       'referencias', 'disponibilidade', 'qualificacao', 'historia_adm',\n",
      "       'notas_gerais', 'observacao', 'conservacao', 'image_path'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading dataset\n",
    "ind_df = pd.read_csv('data/indigenous_collection.csv', index_col='id')\n",
    "print(f'Dataframe columns: \\n{ind_df.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65ad39c6-a57d-422f-bafa-3b66c5c62bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "@register_cell_magic\n",
    "def skip(line, cell):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ce00d1-4dce-4f11-9273-18393a80f968",
   "metadata": {},
   "source": [
    "## Exploring the Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cc2eb2e-64a5-4bf5-bbfa-0b1c68c6b985",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "\n",
    "# How many item do we have?\n",
    "print(f'Amount of items: {len(ind_df)}')\n",
    "\n",
    "# How many items per category?\n",
    "print(f'Amount of items per category: \\n{ind_df.groupby([\"categoria\"]).count()[\"url\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "349be5d6-0b25-4b40-afd9-80de7df96490",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "\n",
    "# How many items with images do we have?\n",
    "print(f'Amount of items with images: {len(ind_df[ind_df[\"thumbnail\"].notna()])}')\n",
    "\n",
    "# How many items with images do we have per category?\n",
    "print(f'Amount of items with image per category: \\n{ind_df.groupby([\"categoria\"]).count()[\"thumbnail\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa6b27b5-524d-4159-b46b-b833800cc839",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# How many items do we have per community?\n",
    "print(f'Amount of items per community: \\n{ind_df.groupby([\"povo\"]).count()[\"url\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb1c9ec2-3939-4d4b-8996-29938044eb58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "\n",
    "# How many items do we have per category per community?\n",
    "print(f'Amount of items per category per community: \\n{ind_df.groupby([\"categoria\", \"povo\"]).count()[\"url\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e93a6672-44b9-44d6-915b-7466373b06fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "\n",
    "# How many items with image do we have per category per community?\n",
    "print(f'Amount of items with image per category per community: \\n{ind_df.groupby([\"categoria\", \"povo\"]).count()[\"thumbnail\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32d406f1-0d9b-4f9c-aa62-61bf1256efc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "\n",
    "# Function to answer three basic questions about a column\n",
    "# 1. How many unique values of the column do we have?\n",
    "# 2. How many items have that column?\n",
    "# 2. How many items do we have per unique value of the column?\n",
    "def column_basic_info(column):\n",
    "    n_unique_items = ind_df[column].nunique()\n",
    "    print('Amount of unique ' + column + f': {n_unique_items}')\n",
    "    print('Amount of items with an associated ' + column + f': {sum(ind_df[column].notna())}')\n",
    "    \n",
    "    if n_unique_items < len(ind_df)/4:\n",
    "        print('Amount of items per ' + column + f': \\n{ind_df.groupby([column]).count()[\"url\"]}')\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Exploring basic infor about other columns\n",
    "other_columns = [col for col in ind_df.columns]\n",
    "\n",
    "for col in other_columns:\n",
    "    column_basic_info(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf6ca34-0d8e-406f-b5a2-f150636ea9d8",
   "metadata": {},
   "source": [
    "## Studying, Organizing and Filtering Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af436a1b-703d-4c43-a6d2-4d47dc4e2869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation of each column\n",
    "# url               -> Link to the object in Tainacan's archive.\n",
    "\n",
    "# thumbnail         -> Link to thumbnail image of element. NaN if there's no image associated with the object.\n",
    "\n",
    "# creation_date     -> Creation date of the object in Tainacan's archive. This is an internal variable from the platform.\n",
    "\n",
    "# modification_date -> Date of last modification of the object in Tainacan's archive. This is an internal variable from the platform.\n",
    "\n",
    "# numero_do_item    -> String identifying the item. It has multiple formats (DD.D.DD, DD.D.DDC, D, DD, DDD, DDDD, DDDDC, DDDDCCC and more).\n",
    "\n",
    "# tripticos         -> No relevant explanation (D.DD or DD.DD).\n",
    "\n",
    "# categoria         -> Category of the item. There are ten different and well-defined of these.\n",
    "\n",
    "# nome_do_item      -> Name of the object. Sometimes its followed by an observation in parenthesis.\n",
    "\n",
    "# nome_do_item_dic  -> New version of 'nome_do_item_de_acordo_com_o_dicionario'. Name of the item according to dictionary. \n",
    "#                      A second and more generic name of the object.\n",
    "\n",
    "# colecao           -> Name of the collection the item belongs to.\n",
    "\n",
    "# coletor           -> Person or institution responsible for collecting the item.\n",
    "\n",
    "# doador            -> Person or institution responsible for donating the item to the museum.\n",
    "\n",
    "# modo_de_aquisicao -> How the item was obtained, either bought, donated, exchanged, another way or unknown.\n",
    "\n",
    "# data_de_aquisicao -> When the item was acquired by the museum.\n",
    "\n",
    "# ano_de_aquisicao  -> New version of 'ano_de_aquisicao_do_objeto'. The year in which the item was acquired by the museum.\n",
    "\n",
    "# data_de_confeccao -> New version of 'data_de_confeccao_do_item'. When the item was made.\n",
    "\n",
    "# autoria           -> Person or institutions that made the item. Sometimes its followed by an observation in parenthesis.\n",
    "\n",
    "# nome_etnico       -> New version of 'nome_etnico_do_item'. Indigenous name of the item. Normally the noun itself is inside quotes and\n",
    "#                      sometimes more information can be found on the string.\n",
    "\n",
    "# descricao         -> Description of the object. Commonly includes material, parts that it is made of (or how it was made), and \n",
    "#                      functionality.\n",
    "\n",
    "# dimensoes         -> Dimensions of the object.\n",
    "\n",
    "# funcao            -> Function of the object.\n",
    "\n",
    "# materia_prima     -> New version of 'materia-prima'. Material the object is made of. Materials are subdivided in a few categories:\n",
    "#                      'animal', 'vegetal', 'mineral' and 'sintetico'.\n",
    "\n",
    "# tecnica_confeccao -> New version of 'tecnica_de_confeccao'. Techniques used to make the item.\n",
    "\n",
    "# descritor_tematico-> A few words that describe themes to which the item is related.\n",
    "\n",
    "# descritor_comum   -> A few words that describe categories related to the item more generically. It is not clear how it is actually \n",
    "#                      different from 'descritor_tematico'.\n",
    "\n",
    "# numero_de_pecas   -> Number of pieces for an item with an associated string, normally a short 'description' of the pieces.\n",
    "\n",
    "# itens_relacionados-> New version of 'itens_relacionados_ao_objeto'. List of other items (in 'numer_do_item' form) related to the item.\n",
    "\n",
    "# responsavel_guarda-> New version of 'responsavel_pela_guarda'. Museum responsible for the item (wither Museu do Indio or musees  \n",
    "#                      d'historie naturalle, industriel commerciel e d'ethnographiede).\n",
    "\n",
    "# inst_detentora    -> New version of 'instituicao_detentora'. Museum that has the item (always Museu do Indio).\n",
    "\n",
    "# povo              -> Community associated to the item.\n",
    "\n",
    "# autoidentificacao -> List of communities associated to the item by the original owner of the item.\n",
    "\n",
    "# lingua            -> Language of the community associated to the item.\n",
    "\n",
    "# estado_de_origem  -> List of brazilian states associated with the item.\n",
    "\n",
    "# geolocalizacao    -> New version of 'localizacao_geografica_especifica'. String describing specifics of the location where the item comes\n",
    "#                      from (either city, community, description of the location or smoething else). \n",
    "\n",
    "# pais_de_origem    -> Country where the item is from.\n",
    "\n",
    "# exposicao         -> New version of 'participacao_em_exposicao'. Exhibition in which the item took part, possibly together with the date\n",
    "#                      it was returned to the museum.\n",
    "\n",
    "# referencias       -> New version of 'referencia_bibliografica'. String containing all the bibliographic references to the item.\n",
    "\n",
    "# disponibilidade   -> New version of 'disponibilidade_do_objeto'. Whether the object is not accessible, locally accessible or completly\n",
    "#                      accessible.\n",
    "\n",
    "# qualificacao      -> Yet another description column.\n",
    "\n",
    "# historia_adm      -> New version of 'historia_administrativa'. String normally containing the history of how the item was acquired by\n",
    "#                      the museum. Sometimes it contains random information either about the object or about a person related to the object.\n",
    "\n",
    "# notas_gerais      -> String containing all sorts of information, directly related or not to the item.\n",
    "\n",
    "# observacao        -> New version of 'observacao_sobre_o_item'. Yet another string containing all sorts of information, directly related\n",
    "#                      or not to the item.\n",
    "\n",
    "# conservacao       -> New version of 'estado_de_conservacao'. Conservation state of the item. Either good, regular or bad.\n",
    "\n",
    "# image_path        -> Local path to associated image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68562830-6aad-4a94-a9e5-e9e5696605bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "\n",
    "import re\n",
    "\n",
    "# Fixing data types\n",
    "ind_df['creation_date'] = pd.to_datetime(ind_df['creation_date'])\n",
    "ind_df['modification_date'] = pd.to_datetime(ind_df['modification_date'])\n",
    "\n",
    "# Fixing name\n",
    "ind_df.rename(columns={'nome_do_item_de_acordo_com_o_dicionario': 'nome_do_item_dic'}, inplace=True)\n",
    "\n",
    "# Extracting correct date when possible\n",
    "def parse_dates_1(date_str):\n",
    "    try:\n",
    "        return pd.to_datetime(date_str)\n",
    "    except:\n",
    "        # Possible formats that are not completly random\n",
    "        for fmt in (\"%Y%m%d\", \"%Y%m00\", \"$Y\", \"%Y0\", \"%Y00\", \"%Y000\", \"%Y0000\", \"%Y00000\", \"%Y000000\", \"%Y%m%dE7\"):\n",
    "            try:\n",
    "                return pd.to_datetime(date_str.replace('.',''), format=fmt)\n",
    "            except ValueError:\n",
    "                continue\n",
    "        return pd.NaT\n",
    "ind_df['data_de_aquisicao'] = ind_df['data_de_aquisicao'].apply(parse_dates_1)\n",
    "\n",
    "# Fixing name and extracting correct year when possible\n",
    "def extract_year(date):\n",
    "    return pd.to_datetime(date).year if pd.notnull(date) else pd.NaT\n",
    "ind_df.rename(columns={'ano_de_aquisicao_do_objeto': 'ano_de_aquisicao'}, inplace=True)\n",
    "ind_df['ano_de_aquisicao'] = ind_df['ano_de_aquisicao'].apply(extract_year)\n",
    "\n",
    "# Fixing name and extracting correct date\n",
    "def parse_dates_2(date):\n",
    "    # Is it already a date?\n",
    "    try:\n",
    "        return pd.to_datetime(date).date()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Remove '?' and try to match an year\n",
    "    date = date.replace('?', '')\n",
    "    try:\n",
    "        if len(date) == 4 and date.isdigit():\n",
    "            return pd.to_datetime(f'{date}-01-01').date()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Do we have a date of the type '<month_in_portuguese> of YYYY'?\n",
    "    try:\n",
    "        date = date_entry.lower().strip()\n",
    "        months_pt = {'janeiro': '01', 'fevereiro': '02', 'março': '03', 'abril': '04', 'maio': '05', 'junho': '06', 'julho': '07', \\\n",
    "                     'agosto': '08', 'setembro': '09', 'outubro': '10', 'novembro': '11', 'dezembro': '12'}\n",
    "        for month_pt, month_num in months_pt.items():\n",
    "            if month_pt in date:\n",
    "                year = ''.join(filter(str.isdigit, date))\n",
    "                return pd.to_datetime(f'{year}-{month_num}-01').date()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Do we have multiple years split by '|'?\n",
    "    if '|' in date:\n",
    "        years = date.split('|')\n",
    "        years = [year.strip() for year in years if year.strip().isdigit()]\n",
    "        return [pd.to_datetime(f'{year}-01-01').date() for year in years]\n",
    "\n",
    "    # Do we have multiple years split by '/'?\n",
    "    elif '/' in date:\n",
    "        years = date.split('/')\n",
    "        years = [year.strip() for year in years if year.strip().isdigit()]\n",
    "        return [pd.to_datetime(f'{year}-01-01').date() for year in years]\n",
    "    \n",
    "    return pd.NaT\n",
    "ind_df.rename(columns={'data_de_confeccao_do_item': 'data_de_confeccao'}, inplace=True)\n",
    "ind_df['data_de_confeccao'] = ind_df['data_de_confeccao'].apply(parse_dates_2)\n",
    "\n",
    "# Fixing name\n",
    "ind_df.rename(columns={'nome_etnico_do_item': 'nome_etnico'}, inplace=True)\n",
    "\n",
    "# Extracting dimensions of the object [length, width, height, diameter]\n",
    "all_dimensions = []\n",
    "for index, value in ind_df['dimensoes'].items():\n",
    "    dimensions = [.0, .0, .0, .0]\n",
    "\n",
    "    # Do I even have information do be extracted?\n",
    "    if type(value) is not str:\n",
    "        all_dimensions.append(pd.NA)\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            # Fix typos and change ',' to '.' for type casting later\n",
    "            string_dimensions = value.replace(',o', ',0')\n",
    "            string_dimensions = string_dimensions.replace(',', '.')\n",
    "\n",
    "            # Matching numbers and studying context to decide what we are measuring (length, width, height or diameter)\n",
    "            numbers = re.findall(r'\\d+\\.\\d', string_dimensions)\n",
    "            for number in numbers:\n",
    "                num_pos = string_dimensions.find(number)\n",
    "                context = string_dimensions[num_pos:min(num_pos+len(number)+18, len(string_dimensions))].lower()\n",
    "\n",
    "                # Checking if we have meters or centimeters\n",
    "                if len(re.findall(r'(?<!c)m', string_dimensions[num_pos:min(num_pos+len(number)+4, len(string_dimensions))])) > 0:\n",
    "                    number = float(number)*100\n",
    "                else:\n",
    "                    number = float(number)\n",
    "                \n",
    "                if 'comprimento' in context:\n",
    "                    dimensions[0] = number\n",
    "                elif 'largura' in context:\n",
    "                    dimensions[1] = number\n",
    "                elif 'altura' in context:\n",
    "                    dimensions[2] = number\n",
    "                elif 'diametro' in context:\n",
    "                    dimensions[3] = number\n",
    "        except Exception as e:\n",
    "            print(number, context, e)\n",
    "            all_dimensions.append(pd.NA)\n",
    "            continue\n",
    "\n",
    "        # Last sanity check to account for degenerate strings\n",
    "        if sum(dimensions) != .0:\n",
    "            all_dimensions.append(dimensions)\n",
    "        else:\n",
    "            all_dimensions.append(pd.NA)\n",
    "ind_df['dimensoes'] = all_dimensions\n",
    "\n",
    "\n",
    "# Fixing name and parsing 'materia_prima' into a list of lists with materials\n",
    "# [[<'animal' materials>], [<'vegetal' materials>], [<'sintetico' materials>]]\n",
    "def parse_materials(row):\n",
    "    if type(row) is not str:\n",
    "        return pd.NA\n",
    "    \n",
    "    material_categories = {'animal': [], 'vegetal': [], 'mineral': [], 'sintetico': []}\n",
    "\n",
    "    # Preprocessing string\n",
    "    materials = row.split('|')\n",
    "    for material in materials:\n",
    "        material = material.strip().replace('&gt;', '>')\n",
    "\n",
    "        # Matching categories and materials\n",
    "        match = re.match(r'(\\w+)\\s*>\\s*(.*)', material)\n",
    "        try:\n",
    "            c, m = match.groups()\n",
    "            material_categories[c].append(m.strip())\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return [material_categories['animal'], material_categories['vegetal'], material_categories['sintetico']]\n",
    "ind_df.rename(columns={'materia-prima': 'materia_prima'}, inplace=True)\n",
    "ind_df['materia_prima'] = ind_df['materia_prima'].apply(parse_materials)\n",
    "\n",
    "# Generic parsing function to deal with more well-behaved columns\n",
    "def parse_generic(row):\n",
    "    if type(row) is not str:\n",
    "        return pd.NA\n",
    "    return [c.strip() for c in row.split('|')]\n",
    "\n",
    "# Fixing name and parsing 'tecnica_confeccao' into a list with all the ways the techniques used to make the item\n",
    "ind_df.rename(columns={'tecnica_de_confeccao': 'tecnica_confeccao'}, inplace=True)\n",
    "ind_df['tecnica_confeccao'] = ind_df['tecnica_confeccao'].apply(parse_generic)\n",
    "\n",
    "# Parsing 'descritor_tematico' into a list with all the words of themes related to the item\n",
    "ind_df['descritor_tematico'] = ind_df['descritor_tematico'].apply(parse_generic)\n",
    "\n",
    "# Parsing 'descritor_comum' into a list with all the generic words related to the item\n",
    "ind_df['descritor_comum'] = ind_df['descritor_comum'].apply(parse_generic)\n",
    "\n",
    "# Parsing 'numero_de_pecas' into a list containing the number of pieces and the associated 'description' of the pieces\n",
    "def parse_number_of_pieces(row):\n",
    "    if type(row) is not str:\n",
    "        return pd.NA\n",
    "\n",
    "    # Processing number of pieces string\n",
    "    pieces_information = row.strip().split(' ', 1)\n",
    "    try:\n",
    "        number = pieces_information[0].strip()\n",
    "        description = ''\n",
    "        if len(pieces_information) > 1:\n",
    "            description = pieces_information[1].strip()\n",
    "\n",
    "        return [int(number), description]\n",
    "\n",
    "    except:\n",
    "        return pd.NA\n",
    "ind_df['numero_de_pecas'] = ind_df['numero_de_pecas'].apply(parse_number_of_pieces)\n",
    "\n",
    "# Fixing name and parsing 'itens_relacionados' into a list with all the related items (in 'numero_do_item' form)\n",
    "ind_df.rename(columns={'itens_relacionados_ao_objeto': 'itens_relacionados'}, inplace=True)\n",
    "ind_df['itens_relacionados'] = ind_df['itens_relacionados'].apply(parse_generic)\n",
    "\n",
    "# Fixing name\n",
    "ind_df.rename(columns={'responsavel_pela_guarda': 'responsavel_guarda'}, inplace=True)\n",
    "\n",
    "# Fixing name\n",
    "ind_df.rename(columns={'instituicao_detentora': 'inst_detentora'}, inplace=True)\n",
    "\n",
    "# Parsing 'autoidentificacao' into a list with all communities associated to the item by the original owner of the item\n",
    "ind_df['autoidentificacao'] = ind_df['autoidentificacao'].apply(parse_generic)\n",
    "\n",
    "# Processing language information to standardize it\n",
    "def processing_language(row):\n",
    "    if type(row) is not str or row.strip() == 'sem identificacao' or row.strip() == 'sem identificação':\n",
    "        return pd.NA\n",
    "    return row.strip()\n",
    "ind_df['lingua'] = ind_df['lingua'].apply(processing_language)\n",
    "\n",
    "# Processing state information to standardize it\n",
    "def processing_state(row):\n",
    "    if type(row) is not str or row.strip() == 's/ procedencia':\n",
    "        return pd.NA\n",
    "\n",
    "    # Mapping states to acronyms\n",
    "    state_to_acronym = {'acre': 'AC', 'alagoas': 'AL', 'amapa': 'AP', 'amazonas': 'AM', 'bahia': 'BA', 'ceara': 'CE', \\\n",
    "                        'distrito federal': 'DF', 'espirito santo': 'ES', 'goias': 'GO', 'maranhao': 'MA', 'mato grosso': 'MT',\\\n",
    "                        'mato grosso do sul': 'MS', 'minas gerais': 'MG', 'para': 'PA', 'paraiba': 'PB', 'parana': 'PR',\\\n",
    "                        'pernambuco': 'PE', 'piaui': 'PI', 'rio de janeiro': 'RJ', 'rio grande do norte': 'RN', 'rio grande do sul': 'RS',\\\n",
    "                        'rondonia': 'RO', 'roraima': 'RR', 'santa catarina': 'SC', 'sao paulo': 'SP', 'sergipe': 'SE', 'tocantins': 'TO'}\n",
    "    state_list = []\n",
    "    for c in row.split('|'):\n",
    "        c = c.strip()\n",
    "        state_list.append(state_to_acronym[c])\n",
    "    \n",
    "    return state_list\n",
    "ind_df['estado_de_origem'] = ind_df['estado_de_origem'].apply(processing_state)\n",
    "\n",
    "# Fixing name\n",
    "ind_df.rename(columns={'localizacao_geografica_especifica': 'geolocalizacao'}, inplace=True)\n",
    "\n",
    "# Parsing 'pais_de_origem' into a list with all countries associated with the origin of the item\n",
    "ind_df['pais_de_origem'] = ind_df['pais_de_origem'].apply(parse_generic)\n",
    "\n",
    "# Fixing name and processing 'exposicao' information to standardize it\n",
    "def processing_exhibition(row):\n",
    "    if type(row) is not str:\n",
    "        return pd.NA\n",
    "    \n",
    "    # Cleaning text\n",
    "    text = re.sub(r'\\s+', ' ', row).strip()\n",
    "\n",
    "    # Extracting exhibition\n",
    "    exhibition = re.match(r'^(.*?)\\s*(?=data de retorno das pecas|$)', text)\n",
    "    exhibition = exhibition.group(1).strip()\n",
    "    \n",
    "    # Possibly extracting and converting date\n",
    "    date = re.search(r'\\b(janeiro|fevereiro|marco|abril|maio|junho|julho|agosto|setembro|outubro|novembro|dezembro) \\d{1,2}, \\d{4}\\b', text)\n",
    "    months_pt = {'janeiro': '01', 'fevereiro': '02', 'março': '03', 'abril': '04','maio': '05', 'junho': '06', 'julho': '07', \\\n",
    "                 'agosto': '08', 'setembro': '09', 'outubro': '10', 'novembro': '11', 'dezembro': '12'}\n",
    "    if date:\n",
    "        date = date.group()\n",
    "        for m_pt, m_num in months_pt.items():\n",
    "            if m_pt in date:\n",
    "                date = date.replace(m_pt, m_num)\n",
    "        date = pd.to_datetime(date, format='%m %d, %Y').date()\n",
    "    \n",
    "        return [exhibition, date]\n",
    "\n",
    "    return [exhibition, ]\n",
    "ind_df.rename(columns={'participacao_em_exposicao': 'exposicao'}, inplace=True)\n",
    "ind_df['exposicao'] = ind_df['exposicao'].apply(processing_exhibition)\n",
    "\n",
    "# Fixing name\n",
    "ind_df.rename(columns={'referencia_bibliografica': 'referencias'}, inplace=True)\n",
    "\n",
    "# Fixing name\n",
    "ind_df.rename(columns={'disponibilidade_do_objeto': 'disponibilidade'}, inplace=True)\n",
    "\n",
    "# Fixing name\n",
    "ind_df.rename(columns={'historia_administrativa': 'historia_adm'}, inplace=True)\n",
    "\n",
    "# Fixing name\n",
    "ind_df.rename(columns={'observacao_sobre_o_item': 'observacao'}, inplace=True)\n",
    "\n",
    "# Fixing name\n",
    "ind_df.rename(columns={'estado_de_conservacao': 'conservacao'}, inplace=True)\n",
    "\n",
    "# Saving new version of dataframe\n",
    "ind_df.to_csv('data/indigenous_collection.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
