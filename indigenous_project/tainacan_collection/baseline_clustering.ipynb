{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f385fe-0854-4881-865c-7607ed0a2ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe columns: \n",
      "Index(['url', 'thumbnail', 'creation_date', 'modification_date',\n",
      "       'numero_do_item', 'tripticos', 'categoria', 'nome_do_item',\n",
      "       'nome_do_item_dic', 'colecao', 'coletor', 'doador', 'modo_de_aquisicao',\n",
      "       'data_de_aquisicao', 'ano_de_aquisicao', 'data_de_confeccao', 'autoria',\n",
      "       'nome_etnico', 'descricao', 'dimensoes', 'funcao', 'materia_prima',\n",
      "       'tecnica_confeccao', 'descritor_tematico', 'descritor_comum',\n",
      "       'numero_de_pecas', 'itens_relacionados', 'responsavel_guarda',\n",
      "       'inst_detentora', 'povo', 'autoidentificacao', 'lingua',\n",
      "       'estado_de_origem', 'geolocalizacao', 'pais_de_origem', 'exposicao',\n",
      "       'referencias', 'disponibilidade', 'qualificacao', 'historia_adm',\n",
      "       'notas_gerais', 'observacao', 'conservacao', 'image_path'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading dataset\n",
    "ind_df = pd.read_csv('data/indigenous_collection_processed.csv', index_col='id')\n",
    "print(f'Dataframe columns: \\n{ind_df.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76a2d38e-6b82-4556-836c-9fab3d3b5759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "# Creating skip cell command\n",
    "@register_cell_magic\n",
    "def skip(line, cell):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8aa497-fcc8-4b16-9128-44984adceb7b",
   "metadata": {},
   "source": [
    "## Baseline Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacdae52-984a-4b1d-a49d-74cac8c0c64d",
   "metadata": {},
   "source": [
    "### Random Orthogonal Projection\n",
    "\n",
    "For this step, we are going to use a few categoric features of the data. Since we don't have any kind of taxonomy on the categories of each feature, the approach will be to use **random orthogonal projections** for the categories to be equidistant in the hyperspace. This way, we keep the representation unbiased - not placing some categories closer to other categories randomly.\n",
    "\n",
    "Selected features (*italic features are being evaluated*):\n",
    "- categoria (10 categories)\n",
    "- *ano_de_confeccao (75 categories)*\n",
    "- tipo_materia_prima (4 categories)\n",
    "- *povo (187 categories)*\n",
    "- *lingua (41 categories)*\n",
    "- estado_de_origem (27 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abbceaba-845a-483f-9120-a48bb80315c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "55663    [animal, vegetal]\n",
       "55668            [vegetal]\n",
       "55673                   []\n",
       "55678                   []\n",
       "55688                   []\n",
       "               ...        \n",
       "41913            [vegetal]\n",
       "41918                   []\n",
       "41923            [vegetal]\n",
       "41928                   []\n",
       "41933            [vegetal]\n",
       "Name: tipo_materia_prima, Length: 20965, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# Creating feature 'tipo_materia_prima'\n",
    "tipo_materia_prima = []\n",
    "for index, row in ind_df.iterrows():\n",
    "    tipo_materia_prima_aux = []\n",
    "    \n",
    "    if type(row['materia_prima']) is not float:\n",
    "        material_list = ast.literal_eval(row['materia_prima'])\n",
    "        \n",
    "        if len(material_list[0]) > 0:\n",
    "            tipo_materia_prima_aux.append('animal')\n",
    "        if len(material_list[1]) > 0:\n",
    "            tipo_materia_prima_aux.append('vegetal')\n",
    "        if len(material_list[2]) > 0:\n",
    "            tipo_materia_prima_aux.append('mineral')\n",
    "        if len(material_list[3]) > 0:\n",
    "            tipo_materia_prima_aux.append('sintetico')\n",
    "\n",
    "    tipo_materia_prima.append(tipo_materia_prima_aux)\n",
    "    \n",
    "ind_df['tipo_materia_prima'] = tipo_materia_prima\n",
    "ind_df['tipo_materia_prima']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "683203e5-804f-4ad2-8109-264bb9a2b5bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the final array: (20965, 38)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Fixing experiments for testing\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generating random orthonormal projection (equidistant categorical representation)\n",
    "def rand_ortho_mat(k):\n",
    "    q = np.random.randn(k, k-1)\n",
    "    q, _ = np.linalg.qr(q)\n",
    "    return q\n",
    "\n",
    "# Getting embeddings for each category in each feature\n",
    "tipos_materia_prima = ['animal', 'vegetal', 'mineral', 'sintetico']\n",
    "estados = ['AC', 'AL', 'AP', 'AM', 'BA', 'CE', 'DF', 'ES', 'GO', 'MA',\\\n",
    "           'MT', 'MS', 'MG', 'PA', 'PB', 'PR', 'PE', 'PI', 'RJ', 'RN',\\\n",
    "           'RS', 'RO', 'RR', 'SC', 'SP', 'SE', 'TO']\n",
    "\n",
    "features = ['categoria', 'tipo_materia_prima', 'estado_de_origem']\n",
    "feature_index_map = []\n",
    "qs = []\n",
    "for feature in features:\n",
    "    if feature == 'tipo_materia_prima':\n",
    "        qs.append(rand_ortho_mat(len(tipos_materia_prima)))\n",
    "        feature_index_map.append({k: i for i, k in enumerate(tipos_materia_prima)})\n",
    "        \n",
    "    elif feature == 'estado_de_origem':\n",
    "        qs.append(rand_ortho_mat(len(estados)))\n",
    "        feature_index_map.append({k: i for i, k in enumerate(estados)})\n",
    "    \n",
    "    else:\n",
    "        qs.append(rand_ortho_mat(ind_df[feature].nunique()))\n",
    "        feature_index_map.append({k: i for i, k in enumerate(ind_df[feature].unique())})\n",
    "\n",
    "# Projecting datapoints\n",
    "features_size = ind_df['categoria'].nunique() + len(tipos_materia_prima) + len(estados)\n",
    "data_points = []\n",
    "for index, row in ind_df.iterrows():\n",
    "    data_point = []\n",
    "    \n",
    "    if type(row['categoria']) is not float:\n",
    "        data_point.append(qs[0][feature_index_map[0][row['categoria']]])\n",
    "    else:\n",
    "        data_point.append(np.zeros_like(qs[0][0]))\n",
    "\n",
    "    if type(row['tipo_materia_prima']) is not float:\n",
    "        data_point_aux = np.zeros_like(qs[1][0])\n",
    "        for materia in row['tipo_materia_prima']:\n",
    "            data_point_aux += qs[1][feature_index_map[1][materia]]\n",
    "        data_point.append(data_point_aux)\n",
    "    else:\n",
    "        data_point.append(np.zeros_like(qs[1][0]))\n",
    "\n",
    "    if type(row['estado_de_origem']) is not float:\n",
    "        data_point_aux = np.zeros_like(qs[2][0])\n",
    "        for estado in ast.literal_eval(row['estado_de_origem']):\n",
    "            data_point_aux += qs[2][feature_index_map[2][estado]]\n",
    "        data_point.append(data_point_aux)\n",
    "    else:\n",
    "        data_point.append(np.zeros_like(qs[2][0]))\n",
    "\n",
    "    data_point = np.concatenate(data_point)\n",
    "    data_points.append(data_point)\n",
    "\n",
    "data_points = np.stack(data_points)\n",
    "print(f'Shape of the final array: {data_points.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a8b9f3-3702-40ad-9eaa-8c179c1e22da",
   "metadata": {},
   "source": [
    "### Projecting Data Points Onto Lower Dimensional Space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d7ec16-ba70-4253-9a3a-3dc6d1e48d49",
   "metadata": {},
   "source": [
    "In here we try two main techniques, mainly because of their abilities to preserve distances between points (or rather global structure of the dataset). The first one is MDS, which should work alright for low-dimensional data, but is probably not the one to use on higher dimensionality. The second one is TriMap, a more general approach that should work well enough in high dimensional data as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45da0a17-8e4a-444d-b852-6452c214dda3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
