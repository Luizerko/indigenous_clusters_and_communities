{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef9795d-0158-4db9-8f3a-ec9139c1f258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe columns: \n",
      "Index(['url', 'thumbnail', 'creation_date', 'modification_date',\n",
      "       'numero_do_item', 'tripticos', 'categoria', 'nome_do_item',\n",
      "       'nome_do_item_dic', 'colecao', 'coletor', 'doador', 'modo_de_aquisicao',\n",
      "       'data_de_aquisicao', 'ano_de_aquisicao', 'data_de_confeccao', 'autoria',\n",
      "       'nome_etnico', 'descricao', 'dimensoes', 'funcao', 'materia_prima',\n",
      "       'tecnica_confeccao', 'descritor_tematico', 'descritor_comum',\n",
      "       'numero_de_pecas', 'itens_relacionados', 'responsavel_guarda',\n",
      "       'inst_detentora', 'povo', 'autoidentificacao', 'lingua',\n",
      "       'estado_de_origem', 'geolocalizacao', 'pais_de_origem', 'exposicao',\n",
      "       'referencias', 'disponibilidade', 'qualificacao', 'historia_adm',\n",
      "       'notas_gerais', 'observacao', 'conservacao', 'image_path'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading dataset\n",
    "ind_df = pd.read_csv('../data/indigenous_collection_processed.csv', index_col='id')\n",
    "print(f'Dataframe columns: \\n{ind_df.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc645b59-5f75-4644-8482-a2aeb836d2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "# Creating skip cell command\n",
    "@register_cell_magic\n",
    "def skip(line, cell):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd1297d5-556c-4811-b8d4-1761e8750542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centralizing main imports so we can run the models separately\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from image_training_utils import *\n",
    "\n",
    "# import image_training_utils\n",
    "# importlib.reload(image_training_utils)\n",
    "# from image_training_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561deae7-07e5-412b-86b4-4f42b9ce3b52",
   "metadata": {},
   "source": [
    "# Image Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dfc3e7-84fa-48da-a625-239a17b0e021",
   "metadata": {},
   "source": [
    "Clustering experiments with image feature extractors. The idea is to fine-tune some pre-trained transformer models on our dataset and then remove the last layer of the model to cluster on the embedding space projections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecfe485-3be5-4694-8198-c50a3d03555e",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a1f9c8-c490-4d69-a6e1-f8aa2d1280e7",
   "metadata": {},
   "source": [
    "For fine-tuning the model on our dataset, we are going to try a couple different labels (*povo* and *categoria*) and study how they affect the generated emebdding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ce8b405-dd10-44cd-8d6c-31d4c4d81131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 corrupted images\n"
     ]
    }
   ],
   "source": [
    "# Filtering out corrupted images\n",
    "corrupted_images = []\n",
    "for index, row in ind_df.loc[ind_df['image_path'].notna()].iterrows():\n",
    "    try:\n",
    "        Image.open('../'+row['image_path'])\n",
    "    except Exception as e:\n",
    "        corrupted_images.append(row['image_path'])\n",
    "        ind_df.loc[index, 'image_path'] = pd.NA\n",
    "print(f'{len(corrupted_images)} corrupted images')\n",
    "\n",
    "# Creating 'image_path_br' column\n",
    "ind_df['image_path_br'] = ind_df['image_path'].values\n",
    "ind_df.loc[ind_df['image_path_br'].notna(), 'image_path_br'] = \\\n",
    "    ind_df.loc[ind_df['image_path_br'].notna(), \\\n",
    "               'image_path'].apply(lambda path: \\\n",
    "                                   f\"data/br_images/{path.split('/')[-1].split('.')[0]}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9804fc-d317-492a-88c1-72cad645cfb4",
   "metadata": {},
   "source": [
    "## ViT Base Patch-16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dd4318-0161-463e-94dc-ba1987cdb366",
   "metadata": {},
   "source": [
    "### Pre-trained Embedding Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eb70f6d-7d44-40f5-b2f5-94053a767665",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting the proper device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Building dataset for column 'povo' (though no specific column is used on off-the-shelf model)\n",
    "vit_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "povo_labels, povo_name_to_num, povo_num_to_name = preparing_image_labels(ind_df, 'povo')\n",
    "povo_dataset = ImageDataset(povo_labels, transform=vit_transform, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34e247fc-988b-4850-b908-ed363357f2b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|█████████████████████████████████████████| 23/23 [03:16<00:00,  8.54s/it]\n",
      "/home/lui/anaconda3/envs/ind_thesis/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Projecting data onto the off-the-shelf pre-trained embedding space from ViT\n",
    "from transformers import ViTModel\n",
    "\n",
    "# Loading model\n",
    "model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "model.to(device)\n",
    "\n",
    "# Getting data\n",
    "povo_dataloader = DataLoader(povo_dataset, batch_size=512, shuffle=True, \\\n",
    "                             num_workers=0, pin_memory=True)\n",
    "\n",
    "# Computing image embeddings\n",
    "image_embeddings, vanilla_image_indices = get_embeddings(model, povo_dataloader, device)\n",
    "image_embeddings = np.concatenate(image_embeddings, axis=0)\n",
    "vanilla_image_indices = np.concatenate(vanilla_image_indices, axis=0)\n",
    "\n",
    "# Computing data projection\n",
    "vanilla_vit_trimap, vanilla_vit_tsne, vanilla_vit_umap = data_projections(image_embeddings)\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model, image_embeddings])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f18e80f-1305-4675-8f89-e70f6ee00187",
   "metadata": {},
   "source": [
    "### Fine-Tuning Embedding Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "397cc9e7-c214-4327-bc09-827d8b0413c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our own ViT classifier (multi-)head for fine-tuning\n",
    "class ViTClassifier(nn.Module):\n",
    "    def __init__(self, num_classes1, num_classes2=0, freeze=0):\n",
    "        super(ViTClassifier, self).__init__()\n",
    "        self.vit = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "        self.classifier1 = nn.Linear(self.vit.config.hidden_size, num_classes1)\n",
    "        self.multi_head = False\n",
    "        \n",
    "        # Multi-head architecture\n",
    "        if num_classes2 > 0:\n",
    "            self.classifier2 = nn.Linear(self.vit.config.hidden_size, num_classes2)\n",
    "            self.multi_head = True\n",
    "        \n",
    "        self.freeze_layers(freeze)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.vit(x)\n",
    "        \n",
    "        # Getting embeddings from last_hidden_state of CLS token (maybe pooler_output?)\n",
    "        embeddings = outputs['last_hidden_state'][:, 0, :]\n",
    "        # embeddings = outputs['pooler_output']\n",
    "\n",
    "        logits1 = self.classifier1(embeddings)\n",
    "        if self.multi_head:\n",
    "            logits2 = self.classifier2(embeddings)\n",
    "            return logits1, logits2\n",
    "        return logits1\n",
    "\n",
    "    # Freezing early layers so we don't lose generalization and speed up training\n",
    "    def freeze_layers(self, freeze):\n",
    "        if freeze <= 0:\n",
    "            return\n",
    "\n",
    "        # Accounting for the embedding freeze\n",
    "        freeze -= 1\n",
    "        \n",
    "        for name, param in self.vit.named_parameters():\n",
    "            if \"embeddings\" in name:\n",
    "                param.requires_grad = False\n",
    "            elif int(name.split('.')[2]) < freeze:\n",
    "                param.requires_grad = False\n",
    "            else:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0093a1e-f85f-48b9-b75e-391fb8cd390b",
   "metadata": {},
   "source": [
    "#### *povo* Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f1eed02-7da5-4671-8136-390d5530246d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile X Data Percentage:\n",
      "Q-10: 1.00, 99.84% of data\n",
      "Q-25: 4.00, 99.18% of data\n",
      "Q-50: 19.00, 95.96% of data\n",
      "Q-75: 65.75, 83.18% of data\n",
      "Q-90: 158.20, 63.25% of data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Studying data distribution to filter out rare classes\n",
    "povo_categories, categories_keys, categories_freq, \\\n",
    "qs, masks = study_class_distribution(povo_labels)\n",
    "\n",
    "# Filtering classes so that we retain around 85% of data\n",
    "povo_filtered_categories = {}\n",
    "povo_filtered_categories_names = {}\n",
    "for c in masks[3][0]:\n",
    "    povo_filtered_categories[categories_keys[c]] = povo_categories[categories_keys[c]]\n",
    "    \n",
    "    povo_filtered_categories_names[povo_num_to_name[categories_keys[c]]] = \\\n",
    "    povo_categories[categories_keys[c]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd6a5e63-5680-4a09-a96e-c6fbb91b28b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering dataframe for selected categories\n",
    "threshold_multiplier = 2\n",
    "minority_classes, majority_classes, labels_minority, labels_majority, \\\n",
    "val_labels, test_labels, povo_augmented_dataset, povo_balanced_val_dataset, \\\n",
    "povo_balanced_test_dataset = filter_image_data_distribution(ind_df, \\\n",
    "                                                            povo_filtered_categories_names, \\\n",
    "                                                            vit_transform, \\\n",
    "                                                            threshold_multiplier, \\\n",
    "                                                            'povo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa94d49e-e893-4a83-8917-b34f6a83031e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting old and new class distributions\n",
    "plot_class_distributions(povo_categories, povo_filtered_categories, labels_minority, \\\n",
    "                         labels_majority, threshold_multiplier, 'povo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be368210-2317-4991-aac4-12dc1fd6e9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the dataset is still unbalanced, we also create class weights for the loss function\n",
    "povo_class_weights = compute_class_weights(povo_filtered_categories, labels_minority, \\\n",
    "                                           labels_majority, device, threshold_multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fe3bdc-df2c-40ed-b0c7-a2ac7989e256",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   5%|██▎                                          | 1/20 [04:30<1:25:45, 270.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 1\n",
      "Epoch 1, Loss: 1102.5018, Validation Accuracy: 0.3468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  10%|████▌                                        | 2/20 [09:01<1:21:12, 270.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 2\n",
      "Epoch 2, Loss: 810.3684, Validation Accuracy: 0.4581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  15%|██████▊                                      | 3/20 [13:32<1:16:45, 270.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 3\n",
      "Epoch 3, Loss: 618.3408, Validation Accuracy: 0.5182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  20%|█████████                                    | 4/20 [18:03<1:12:11, 270.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 4\n",
      "Epoch 4, Loss: 455.8129, Validation Accuracy: 0.5507\n"
     ]
    }
   ],
   "source": [
    "# Recreating datasets for proper training and testing\n",
    "povo_train_val_labels = povo_labels.copy()\n",
    "povo_test_labels_aux = random.sample(list(povo_train_val_labels), \\\n",
    "                                     int(0.1*len(povo_train_val_labels)))\n",
    "povo_test_labels = {}\n",
    "for key in povo_test_labels_aux:\n",
    "    povo_test_labels[key] = povo_train_val_labels[key]\n",
    "    del povo_train_val_labels[key]\n",
    "    \n",
    "povo_train_val_dataset = ImageDataset(povo_train_val_labels, transform=vit_transform, \\\n",
    "                                      augment=False)\n",
    "povo_test_dataset = ImageDataset(povo_test_labels, transform=vit_transform, augment=False)\n",
    "\n",
    "# Setting-up training, executing training and then running tests\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "num_classes = ind_df['povo'].dropna().nunique()\n",
    "model = ViTClassifier(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=5e-5, weight_decay=2e-6)\n",
    "model_name = 'vit_povo'\n",
    "column_name = 'povo'\n",
    "\n",
    "test_prec, test_rec = execute_train_test(povo_train_val_dataset, povo_test_dataset, device, \\\n",
    "                                         batch_size, epochs, num_classes, model, criterion, \\\n",
    "                                         opt, model_name, column_name)\n",
    "prec_rec_on_selected_classes(povo_categories, povo_filtered_categories, test_prec, test_rec)\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0871d528-56a5-4773-8e47-92426a19c1cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retraining model with augmented dataset to see the difference in the results\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "num_classes = len(povo_filtered_categories)\n",
    "model = ViTClassifier(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=povo_class_weights)\n",
    "opt = optim.Adam(model.parameters(), lr=2e-5, weight_decay=2e-6)\n",
    "model_name = 'balanced_vit_povo'\n",
    "column_name = 'povo'\n",
    "\n",
    "execute_train_test(povo_augmented_dataset, povo_balanced_test_dataset, device, batch_size, \\\n",
    "                   epochs, num_classes, model, criterion, opt, model_name, column_name, \\\n",
    "                   povo_balanced_val_dataset)\n",
    "\n",
    "povo_vit_trimap, povo_vit_tsne, \\\n",
    "povo_vit_umap, povo_image_indices = compute_classifier_embeddings(povo_dataloader, model, \\\n",
    "                                                                  device)\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4ae93b-0c01-4264-8334-042474bd2b70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training partially frozen model on balanced dataset to see the difference in results\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "num_classes = len(povo_filtered_categories)\n",
    "freeze = 7\n",
    "model = ViTClassifier(num_classes, freeze=freeze).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=povo_class_weights)\n",
    "opt = optim.Adam(model.parameters(), lr=2e-5, weight_decay=2e-6)\n",
    "model_name = 'frozen_vit_povo'\n",
    "column_name = 'povo'\n",
    "\n",
    "execute_train_test(povo_augmented_dataset, povo_balanced_test_dataset, device, batch_size, \\\n",
    "                   epochs, num_classes, model, criterion, opt, model_name, column_name, \\\n",
    "                   povo_balanced_val_dataset)\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0a9205-5eaf-4bbe-ba8c-79f0d81653d8",
   "metadata": {},
   "source": [
    "#### *categoria* Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fade66-3cd8-4a50-a8f1-da9b84b1f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now rebalancing the 'categoria' column\n",
    "categoria_labels, categoria_name_to_num, categoria_num_to_name = \\\n",
    "preparing_image_labels(ind_df, 'categoria')\n",
    "categoria_dataset = ImageDataset(categoria_labels, transform=vit_transform)\n",
    "categoria_dataloader = DataLoader(categoria_dataset, batch_size=512, shuffle=True, \\\n",
    "                                  num_workers=0, pin_memory=True)\n",
    "\n",
    "categoria_categories, categories_keys, categories_freq, qs, \\\n",
    "masks = study_class_distribution(categoria_labels)\n",
    "\n",
    "# Filtering out 'etnobotânica' (and 'armas')\n",
    "filter_out = [categoria_name_to_num['etnobotânica']]\n",
    "categoria_filtered_categories = {}\n",
    "categoria_filtered_categories_names = {}\n",
    "for c in set(categoria_name_to_num.values()) - set(filter_out):\n",
    "    categoria_filtered_categories[categories_keys[c]] = \\\n",
    "    categoria_categories[categories_keys[c]]\n",
    "    \n",
    "    categoria_filtered_categories_names[categoria_num_to_name[categories_keys[c]]] = \\\n",
    "    categoria_categories[categories_keys[c]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9493d23c-372a-4c29-a1b1-13bb41f7f1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering dataframe for selected categories\n",
    "threshold_multiplier = 1.5\n",
    "minority_classes, majority_classes, labels_minority, labels_majority, val_labels, \\\n",
    "test_labels, categoria_augmented_dataset, categoria_balanced_val_dataset, \\\n",
    "categoria_balanced_test_dataset = \\\n",
    "filter_image_data_distribution(ind_df, categoria_filtered_categories_names, vit_transform, \\\n",
    "                               threshold_multiplier, 'categoria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051ce382-430c-4026-8484-145c1da501d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting old and new class distributions\n",
    "plot_class_distributions(categoria_categories, categoria_filtered_categories, \\\n",
    "                         labels_minority, labels_majority, threshold_multiplier, 'categoria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f03e8aa-db16-4cfc-a7f3-3b0dc41f4186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the dataset is still unbalanced, we also create class weights for the loss function\n",
    "categoria_class_weights = compute_class_weights(categoria_filtered_categories, \\\n",
    "                                                labels_minority, labels_majority, device, \\\n",
    "                                                threshold_multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47f319d-f46f-4197-bc9b-7006224bac68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Recreating datasets for proper training and testing\n",
    "categoria_train_val_labels = categoria_labels.copy()\n",
    "categoria_test_labels_aux = random.sample(list(categoria_train_val_labels), \\\n",
    "                                          int(0.1*len(categoria_train_val_labels)))\n",
    "categoria_test_labels = {}\n",
    "for key in categoria_test_labels_aux:\n",
    "    categoria_test_labels[key] = categoria_train_val_labels[key]\n",
    "    del categoria_train_val_labels[key]\n",
    "    \n",
    "categoria_train_val_dataset = ImageDataset(categoria_train_val_labels, \\\n",
    "                                           transform=vit_transform, augment=False)\n",
    "categoria_test_dataset = ImageDataset(categoria_test_labels, \\\n",
    "                                      transform=vit_transform, augment=False)\n",
    "\n",
    "# Setting-up training, executing training and then running tests\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "num_classes = ind_df['categoria'].dropna().nunique()\n",
    "model = ViTClassifier(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-5, weight_decay=2e-6)\n",
    "model_name = 'vit_categoria'\n",
    "column_name = 'categoria'\n",
    "\n",
    "test_prec, test_rec = execute_train_test(categoria_train_val_dataset, categoria_test_dataset, \\\n",
    "                                         device, batch_size, epochs, num_classes, model, \\\n",
    "                                         criterion, opt, model_name, column_name)\n",
    "prec_rec_on_selected_classes(categoria_categories, categoria_filtered_categories, test_prec, \\\n",
    "                             test_rec)\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddf8fac-6f67-4ea7-ab8c-8d2be9add2e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retraining model with augmented dataset to see the difference in the results\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "num_classes = len(categoria_filtered_categories)\n",
    "model = ViTClassifier(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=categoria_class_weights)\n",
    "opt = optim.Adam(model.parameters(), lr=3e-6, weight_decay=1e-6)\n",
    "model_name = 'balanced_vit_categoria'\n",
    "column_name = 'categoria'\n",
    "\n",
    "execute_train_test(categoria_augmented_dataset, categoria_balanced_test_dataset, device, \\\n",
    "                   batch_size, epochs, num_classes, model, criterion, opt, model_name, \\\n",
    "                   column_name, categoria_balanced_val_dataset)\n",
    "\n",
    "categoria_vit_trimap, categoria_vit_tsne, categoria_vit_umap, \\\n",
    "categoria_image_indices = compute_classifier_embeddings(categoria_dataloader, model, device)\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f58fdaa-04d0-44fc-93a0-5ebbf9b7a4d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training partially frozen model on balanced dataset to see the difference in results\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "num_classes = len(categoria_filtered_categories)\n",
    "freeze = 7\n",
    "model = ViTClassifier(num_classes, freeze=freeze).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=categoria_class_weights)\n",
    "opt = optim.Adam(model.parameters(), lr=3e-6, weight_decay=1e-6)\n",
    "model_name = 'frozen_vit_categoria'\n",
    "column_name = 'categoria'\n",
    "\n",
    "execute_train_test(categoria_augmented_dataset, categoria_balanced_test_dataset, device, \\\n",
    "                   batch_size, epochs, num_classes, model, criterion, opt, model_name, \\\n",
    "                   column_name, categoria_balanced_val_dataset)\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c773629-dfd3-43ec-8e5a-c9e8e4117fa7",
   "metadata": {},
   "source": [
    "#### Multi-Head Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a574bade-683d-42b5-805a-4e1a41a89c61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting data that passes both heads' data-filters\n",
    "povo_set = set(np.array(list(povo_labels.keys()))\\\n",
    "                [np.where(np.isin(np.array(list(povo_labels.values())), \\\n",
    "                np.array(list(povo_filtered_categories.keys()))))[0]])\n",
    "categoria_set = set(np.array(list(categoria_labels.keys()))\\\n",
    "                    [np.where(np.isin(np.array(list(categoria_labels.values())), \\\n",
    "                    np.array(list(categoria_filtered_categories.keys()))))[0]])\n",
    "multi_head_keys = [str(x) for x in povo_set.intersection(categoria_set)]\n",
    "\n",
    "# Studying individual and joint classes' distributions\n",
    "povo_freq = {}\n",
    "categoria_freq = {}\n",
    "multi_freq = {}\n",
    "for key in multi_head_keys:\n",
    "    try:\n",
    "        povo_freq[povo_labels[key]] += 1\n",
    "    except:\n",
    "        povo_freq[povo_labels[key]] = 1\n",
    "\n",
    "    try:\n",
    "        categoria_freq[categoria_labels[key]] += 1\n",
    "    except:\n",
    "        categoria_freq[categoria_labels[key]] = 1\n",
    "\n",
    "    try:\n",
    "        multi_freq[f'{(povo_labels[key], categoria_labels[key])}'] += 1\n",
    "    except:\n",
    "        multi_freq[f'{(povo_labels[key], categoria_labels[key])}'] = 1\n",
    "\n",
    "# Utility function to plot rows on data distribution plot\n",
    "def row_bar_plot(col_freq, name, row, rows=3, cols=1, remove_xticks=False):\n",
    "    plt.subplot(rows, cols, row)\n",
    "    plt.bar(list(col_freq.keys()), list(col_freq.values()))\n",
    "    plt.title(name)\n",
    "\n",
    "    if remove_xticks:\n",
    "        plt.xlabel(\"\")\n",
    "        plt.xticks([])\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.suptitle('Classes Distributions for Multi-Head Data')\n",
    "\n",
    "row_bar_plot(povo_freq, \"'povo' Column\", 1)\n",
    "row_bar_plot(categoria_freq, \"'categoria' Column\", 2)\n",
    "row_bar_plot(multi_freq, \"Both Columns (Joint Distribution)\", 3, remove_xticks=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa01612-aadc-4200-ae15-dcfb01d448bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because of the even worse degree of unbalanced data on the joint distribution, we balance\n",
    "# the dataset taking the 'povo' column into consideration and study the new joint distribution\n",
    "multi_povo_labels = {}\n",
    "multi_categoria_labels = {}\n",
    "for key in multi_head_keys:\n",
    "    multi_povo_labels[key] = povo_labels[key]\n",
    "    multi_categoria_labels[key] = categoria_labels[key]\n",
    "\n",
    "# Reusing previous dataset infrastructure to build multi-label dataset\n",
    "multi_povo_categories, categories_keys, categories_freq, \\\n",
    "qs, masks = study_class_distribution(multi_povo_labels)\n",
    "multi_povo_filtered_categories = multi_povo_categories\n",
    "multi_povo_filtered_categories_names = {}\n",
    "for c in categories_keys:\n",
    "    multi_povo_filtered_categories_names[povo_num_to_name[c]] = multi_povo_categories[c]\n",
    "\n",
    "multi_categoria_categories, categories_keys, categories_freq, \\\n",
    "qs, masks = study_class_distribution(multi_categoria_labels)\n",
    "multi_categoria_filtered_categories = multi_categoria_categories\n",
    "multi_categoria_filtered_categories_names = {}\n",
    "for c in categories_keys:\n",
    "    multi_categoria_filtered_categories_names[categoria_num_to_name[c]] = \\\n",
    "    multi_categoria_categories[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffb1c1a-b60b-4a08-82f0-2484d837e78d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filtering dataframe for selected categories\n",
    "threshold_multiplier = 2\n",
    "minority_classes, majority_classes, labels_minority, labels_majority, \\\n",
    "val_labels, test_labels, multi_augmented_dataset, multi_balanced_val_dataset, \\\n",
    "multi_balanced_test_dataset = \\\n",
    "multihead_filter_image_data_distribution(ind_df, [multi_povo_filtered_categories_names, \\\n",
    "                                         multi_categoria_filtered_categories_names], \\\n",
    "                                         vit_transform, threshold_multiplier, \\\n",
    "                                         ['povo', 'categoria'])\n",
    "\n",
    "# Plotting old and new class distributions\n",
    "multihead_plot_class_distributions(multi_povo_categories, multi_povo_filtered_categories, \\\n",
    "                                   labels_minority, labels_majority, threshold_multiplier, \\\n",
    "                                   'povo')\n",
    "\n",
    "multihead_plot_class_distributions(multi_categoria_categories, \\\n",
    "                                   multi_categoria_filtered_categories, \\\n",
    "                                   labels_minority, labels_majority, threshold_multiplier, \\\n",
    "                                   'categoria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb11d70-889b-43f1-819b-12118d21e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the dataset is still unbalanced, we also create class weights for the loss function\n",
    "multi_povo_class_weights = multihead_compute_class_weights(multi_povo_filtered_categories, \\\n",
    "                                                           labels_minority, labels_majority, \\\n",
    "                                                           device, threshold_multiplier, \\\n",
    "                                                           'povo')\n",
    "\n",
    "multi_categoria_class_weights = \\\n",
    "multihead_compute_class_weights(multi_categoria_filtered_categories, labels_minority, \\\n",
    "                                labels_majority, device, threshold_multiplier,'categoria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f343bf-bbd9-496e-9f95-b1a14b914287",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training multi-head model on balanced dataset to see the difference in results\n",
    "batch_size = 16\n",
    "epochs = 30\n",
    "num_classes = [len(multi_povo_filtered_categories), len(multi_categoria_filtered_categories)]\n",
    "model = ViTClassifier(num_classes[0], num_classes[1]).to(device)\n",
    "criterions = [nn.CrossEntropyLoss(weight=multi_povo_class_weights), \\\n",
    "              nn.CrossEntropyLoss(weight=multi_categoria_class_weights)]\n",
    "opt = optim.Adam(model.parameters(), lr=1e-5, weight_decay=3e-6)\n",
    "model_name = 'multihead_vit'\n",
    "column_names = ['povo', 'categoria']\n",
    "arch_name = 'ViT'\n",
    "head_weights = [0.3, 0.7]\n",
    "\n",
    "multihead_execute_train_test(multi_augmented_dataset, multi_balanced_test_dataset, device, \\\n",
    "                             batch_size, epochs, num_classes, model, \\\n",
    "                             criterions, opt, model_name, column_names, \\\n",
    "                             multi_balanced_val_dataset, arch_name, head_weights)\n",
    "\n",
    "multihead_vit_trimap, multihead_vit_tsne, multihead_vit_umap, \\\n",
    "multihead_image_indices = compute_classifier_embeddings(categoria_dataloader, model, device)\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81730faf-1ab3-4473-9268-04b25559bc14",
   "metadata": {},
   "source": [
    "### Visualizing and Comparing Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7622319c-08ac-475d-8376-c66bd3e76fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing data for later plot on tool\n",
    "norm_factor = 12\n",
    "vanilla_vit_trimap = normalize(vanilla_vit_trimap, norm_factor)\n",
    "vanilla_vit_tsne = normalize(vanilla_vit_tsne, norm_factor)\n",
    "vanilla_vit_umap = normalize(vanilla_vit_umap, norm_factor)\n",
    "\n",
    "povo_vit_trimap = normalize(povo_vit_trimap, norm_factor)\n",
    "povo_vit_tsne = normalize(povo_vit_tsne, norm_factor)\n",
    "povo_vit_umap = normalize(povo_vit_umap, norm_factor)\n",
    "\n",
    "categoria_vit_trimap = normalize(categoria_vit_trimap, norm_factor)\n",
    "categoria_vit_tsne = normalize(categoria_vit_tsne, norm_factor)\n",
    "categoria_vit_umap = normalize(categoria_vit_umap, norm_factor)\n",
    "\n",
    "multihead_vit_trimap = normalize(multihead_vit_trimap, norm_factor)\n",
    "multihead_vit_tsne = normalize(multihead_vit_tsne, norm_factor)\n",
    "multihead_vit_umap = normalize(multihead_vit_umap, norm_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fce310-fb5f-4218-afb7-5ffcb02dbf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to plot rows on projection comparison plot\n",
    "def row_scatter_plot(projs, proj_names, row, color, rows=4, cols=4):\n",
    "    for i, (proj, proj_name) in enumerate(zip(projs, proj_names)):\n",
    "        plt.subplot(rows, cols, i+1+(cols*(row-1)))\n",
    "        plt.scatter(proj[:, 0], proj[:, 1], c=color)\n",
    "        plt.title(f\"{proj_name}\")\n",
    "        plt.xlabel(\"\")\n",
    "        plt.ylabel(\"\")\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "\n",
    "# Visualizing resulting projections\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.suptitle('Comparing Projections of ViT Models')\n",
    "\n",
    "# Plotting vanilla ViT projections\n",
    "projs = [vanilla_vit_trimap, vanilla_vit_tsne, vanilla_vit_umap]\n",
    "proj_names = ['Vanilla ViT with TriMap', 'Vanilla ViT with t-SNE', 'Vanilla ViT with UMAP']\n",
    "row_scatter_plot(projs, proj_names, 1, 'b')\n",
    "\n",
    "# Plotting ViT fine-tuned on 'povo' projections\n",
    "projs = [povo_vit_trimap, povo_vit_tsne, povo_vit_umap]\n",
    "proj_names = [\"ViT Fine-Tuned on 'povo' with TriMap\", \"ViT Fine-Tuned on 'povo' with t-SNE\", \\\n",
    "              \"ViT Fine-Tuned on 'povo' with UMAP\"]\n",
    "row_scatter_plot(projs, proj_names, 2, 'r')\n",
    "\n",
    "# Plotting ViT fine-tuned on 'categoria' projections\n",
    "projs = [categoria_vit_trimap, categoria_vit_tsne, categoria_vit_umap]\n",
    "proj_names = [\"ViT Fine-Tuned on 'categoria' with TriMap\", \\\n",
    "              \"ViT Fine-Tuned on 'categoria' with t-SNE\", \\\n",
    "              \"ViT Fine-Tuned on 'categoria' with UMAP\"]\n",
    "row_scatter_plot(projs, proj_names, 3, 'g')\n",
    "\n",
    "# Plotting ViT fine-tuned on 'povo' and 'categoria' (multi-head) projections\n",
    "projs = [multihead_vit_trimap, multihead_vit_tsne, multihead_vit_umap]\n",
    "proj_names = [\"ViT Multi-head Fine-Tuned with TriMap\", \\\n",
    "              \"ViT Multi-head Fine-Tuned with t-SNE\", \\\n",
    "              \"ViT Multi-head Fine-Tuned with UMAP\"]\n",
    "row_scatter_plot(projs, proj_names, 4, 'yellow')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d358406-41c1-40ba-8580-398ff90a1872",
   "metadata": {},
   "source": [
    "### Visualizing Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7ccb9a-0d2f-4f97-adc5-686a4310b555",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filtering dataframe to get only the part that contains images\n",
    "filtered_df = ind_df.loc[ind_df['image_path'].notna()]\n",
    "\n",
    "# Visualizing 'povo' cluster\n",
    "visualizing_clusters(filtered_df, povo_vit_umap, povo_image_indices, 'povo', 'UMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a072ba0-1e61-4288-b4ff-27ad22e1c3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing 'categoria' cluster\n",
    "visualizing_clusters(filtered_df, categoria_vit_umap, categoria_image_indices, \\\n",
    "                     'categoria', 'UMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6824912b-0827-4e88-b3d3-abe9fed90ca7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualizing 'povo' cluster for multi-head modedl\n",
    "visualizing_clusters(filtered_df, multihead_vit_umap, multihead_image_indices, \\\n",
    "                     'povo', 'UMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2d5f57-7fe5-4dfb-b3dc-b550fb26913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing 'categoria' cluster for multi-head modedl\n",
    "visualizing_clusters(filtered_df, multihead_vit_umap, multihead_image_indices, \\\n",
    "                     'categoria', 'UMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba8e8d-256f-4681-9fa8-8c1026781225",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Saving outputs for visualization tool\n",
    "_ = saving_outputs(filtered_df, povo_labels, vanilla_vit_umap, vanilla_image_indices, \\\n",
    "                   save_file='vanilla_vit.csv', no_clusters=True)\n",
    "\n",
    "_ = saving_outputs(filtered_df, povo_labels, povo_vit_umap, povo_image_indices, 'povo', \\\n",
    "                   'povo_vit.csv')\n",
    "\n",
    "_ = saving_outputs(filtered_df, categoria_labels, categoria_vit_umap, \\\n",
    "                   categoria_image_indices, 'categoria', 'categoria_vit.csv')\n",
    "\n",
    "_ = saving_outputs(filtered_df, povo_labels, multihead_vit_umap, \\\n",
    "                   multihead_image_indices, save_file='multihead_vit.csv', no_clusters=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50709824-9e61-4a0e-9963-fd10b5a1f727",
   "metadata": {},
   "source": [
    "## DINOv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c9fd41-14e6-48a0-836f-d4ee23073892",
   "metadata": {},
   "source": [
    "### Pre-Trained Embedding Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c387c93-d1e2-458d-85d8-ebc65a74559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, AutoModel\n",
    "\n",
    "# Rebuilding dataset with DINO transform and dataloader with smaller batch_size because of \n",
    "# the model's size\n",
    "dino_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop((224, 224)),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "povo_dataset = ImageDataset(povo_labels, transform=dino_transform, augment=False)\n",
    "povo_dataloader = DataLoader(povo_dataset, batch_size=16, shuffle=True, \\\n",
    "                             num_workers=0, pin_memory=True)\n",
    "\n",
    "# Loading model and pre-processor\n",
    "dino_processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')\n",
    "model = AutoModel.from_pretrained('facebook/dinov2-base')\n",
    "model.to(device)\n",
    "\n",
    "# Projecting data onto the off-the-shelf pre-trained embedding space from DINOv2\n",
    "image_embeddings, vanilla_image_indices = get_embeddings(model, povo_dataloader, device, \\\n",
    "                                                         model_name='dino')\n",
    "image_embeddings = np.concatenate(image_embeddings, axis=0)\n",
    "vanilla_image_indices = np.concatenate(vanilla_image_indices, axis=0)\n",
    "\n",
    "# Computing data reduced-dimensionality projections\n",
    "_, _, vanilla_dino_umap = data_projections(image_embeddings)\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model, image_embeddings])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fba030-df4f-434a-a90e-d08cebc2e38b",
   "metadata": {},
   "source": [
    "### Fine-Tuning Embedding Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96872a49-4b39-4693-872a-627e5191ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our own DINO classifier head for fine-tuning\n",
    "class DINOClassifier(nn.Module):\n",
    "    def __init__(self, num_classes1, num_classes2=0, freeze=0):\n",
    "        super(DINOClassifier, self).__init__()\n",
    "        self.dino = AutoModel.from_pretrained('facebook/dinov2-base')\n",
    "        self.classifier1 = nn.Linear(self.dino.config.hidden_size, num_classes1)\n",
    "        self.multi_head = False\n",
    "        \n",
    "        # Multi-head architecture\n",
    "        if num_classes2 > 0:\n",
    "            self.classifier2 = nn.Linear(self.dino.config.hidden_size, num_classes2)\n",
    "            self.multi_head = True\n",
    "        \n",
    "        self.freeze_layers(freeze)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        outputs = self.dino(x)\n",
    "        \n",
    "        # Getting embeddings from last_hidden_state of CLS token (maybe pooler_output?)\n",
    "        embeddings = outputs['last_hidden_state'][:, 0, :]\n",
    "        # embeddings = outputs['pooler_output']\n",
    "\n",
    "        logits1 = self.classifier1(embeddings)\n",
    "        if self.multi_head:\n",
    "            logits2 = self.classifier2(embeddings)\n",
    "            return logits1, logits2\n",
    "        return logits1\n",
    "\n",
    "    # Freezing early layers so we don't lose generalization and speed up training\n",
    "    def freeze_layers(self, freeze):\n",
    "        if freeze <= 0:\n",
    "            return\n",
    "\n",
    "        # Accounting for the embedding freeze\n",
    "        freeze -= 1\n",
    "        \n",
    "        for name, param in self.dino.named_parameters():\n",
    "            if \"embeddings\" in name:\n",
    "                param.requires_grad = False\n",
    "            elif int(name.split('.')[2]) < freeze:\n",
    "                param.requires_grad = False\n",
    "            else:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6609639-35a5-4fae-b1a8-799d4a37a585",
   "metadata": {},
   "source": [
    "#### *povo* Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39e11a4-c5cb-4524-9dc5-3f2fca00adaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Recreating datasets for proper training and testing\n",
    "povo_train_val_dataset = ImageDataset(povo_train_val_labels, transform=dino_transform, \\\n",
    "                                      augment=False)\n",
    "povo_test_dataset = ImageDataset(povo_test_labels, transform=dino_transform, augment=False)\n",
    "\n",
    "# Setting-up training, executing training and then running tests\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "num_classes = ind_df['povo'].dropna().nunique()\n",
    "model = DINOClassifier(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-6, weight_decay=3e-7)\n",
    "model_name = 'dino_povo'\n",
    "column_name = 'povo'\n",
    "\n",
    "test_prec, test_rec = execute_train_test(povo_train_val_dataset, povo_test_dataset, device, \\\n",
    "                                        batch_size, epochs, num_classes, model, criterion, \\\n",
    "                                        opt, model_name, column_name, \\\n",
    "                                        architecture_name='DINOv2')\n",
    "prec_rec_on_selected_classes(povo_categories, povo_filtered_categories, test_prec, test_rec)\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ed537e-c895-4f46-a748-97bb0cf56995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering dataframe for selected categories. We need to recompute this part of the dataset\n",
    "# because of the different transform used\n",
    "threshold_multiplier = 2\n",
    "minority_classes, majority_classes, labels_minority, labels_majority, \\\n",
    "val_labels, test_labels, povo_augmented_dataset, povo_balanced_val_dataset, \\\n",
    "povo_balanced_test_dataset = filter_image_data_distribution(ind_df, \\\n",
    "                                                            povo_filtered_categories_names, \\\n",
    "                                                            dino_transform, \\\n",
    "                                                            threshold_multiplier, \\\n",
    "                                                            'povo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78db26c8-d6f3-4dbb-8f9f-b6804b352454",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retraining model with augmented dataset to see the difference in the results\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "num_classes = len(povo_filtered_categories)\n",
    "model = DINOClassifier(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=povo_class_weights)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-6, weight_decay=3e-7)\n",
    "model_name = 'balanced_dino_povo'\n",
    "column_name = 'povo'\n",
    "\n",
    "execute_train_test(povo_augmented_dataset, povo_balanced_test_dataset, device, batch_size, \\\n",
    "                   epochs, num_classes, model, criterion, opt, model_name, column_name, \\\n",
    "                   povo_balanced_val_dataset, architecture_name='DINOv2')\n",
    "\n",
    "# _, _, \\\n",
    "# povo_dino_umap, povo_image_indices = compute_classifier_embeddings(povo_dataloader, model, \\\n",
    "#                                                                    device, 'dino')\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d89dd8-9eea-44e4-8f11-72af1825171b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training partially frozen model on balanced dataset to see the difference in results\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "num_classes = len(povo_filtered_categories)\n",
    "freeze = 9\n",
    "model = DINOClassifier(num_classes, freeze=freeze).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=povo_class_weights)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-6, weight_decay=3e-7)\n",
    "model_name = 'frozen_dino_povo'\n",
    "column_name = 'povo'\n",
    "\n",
    "execute_train_test(povo_augmented_dataset, povo_balanced_test_dataset, device, \\\n",
    "                   batch_size, epochs, num_classes, model, criterion, opt, model_name, \\\n",
    "                   column_name, povo_balanced_val_dataset, architecture_name='DINOv2')\n",
    "\n",
    "_, _, \\\n",
    "povo_dino_umap, povo_image_indices = compute_classifier_embeddings(povo_dataloader, model, \\\n",
    "                                                                   device, 'dino')\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064d659b-247f-4ec8-996f-b0f50e36c3ed",
   "metadata": {},
   "source": [
    "#### *categoria* Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c80e65-f3e3-447b-84b6-af6d6f114a10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now creating the 'categoria' dataset\n",
    "categoria_dataset = ImageDataset(categoria_labels, transform=dino_transform)\n",
    "categoria_dataloader = DataLoader(categoria_dataset, batch_size=8, shuffle=True, \\\n",
    "                                  num_workers=0, pin_memory=True)\n",
    "\n",
    "# Recreating datasets for proper training and testing\n",
    "categoria_train_val_dataset = ImageDataset(categoria_train_val_labels, \\\n",
    "                                           transform=dino_transform, augment=False)\n",
    "categoria_test_dataset = ImageDataset(categoria_test_labels, transform=dino_transform, \\\n",
    "                                      augment=False)\n",
    "\n",
    "# Setting-up training, executing training and then running tests\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "num_classes = ind_df['categoria'].dropna().nunique()\n",
    "model = DINOClassifier(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=3e-7, weight_decay=1e-7)\n",
    "model_name = 'dino_categoria'\n",
    "column_name = 'categoria'\n",
    "\n",
    "test_prec, test_rec = execute_train_test(categoria_train_val_dataset, categoria_test_dataset, \\\n",
    "                                         device, batch_size, epochs, num_classes, model, \\\n",
    "                                         criterion, opt, model_name, column_name, \\\n",
    "                                         architecture_name='DINOv2')\n",
    "prec_rec_on_selected_classes(categoria_categories, categoria_filtered_categories, test_prec, \\\n",
    "                             test_rec)\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff0224d-df2c-432e-87c6-4d8f30906601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering dataframe for selected categories. We need to recompute this part of the dataset\n",
    "# because of the different transform used\n",
    "threshold_multiplier = 1.5\n",
    "minority_classes, majority_classes, labels_minority, labels_majority, \\\n",
    "val_labels, test_labels, categoria_augmented_dataset, categoria_balanced_val_dataset, \\\n",
    "categoria_balanced_test_dataset = \\\n",
    "filter_image_data_distribution(ind_df, categoria_filtered_categories_names, dino_transform, \\\n",
    "                               threshold_multiplier, 'categoria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506c7d49-68a2-4593-86a0-b916298e888e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retraining model with augmented dataset to see the difference in the results\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "num_classes = len(categoria_filtered_categories)\n",
    "model = DINOClassifier(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=categoria_class_weights)\n",
    "opt = optim.Adam(model.parameters(), lr=3e-7, weight_decay=1e-7)\n",
    "model_name = 'balanced_dino_categoria'\n",
    "column_name = 'categoria'\n",
    "\n",
    "execute_train_test(categoria_augmented_dataset, categoria_balanced_test_dataset, device, \\\n",
    "                   batch_size, epochs, num_classes, model, criterion, opt, model_name, \\\n",
    "                   column_name, categoria_balanced_val_dataset, architecture_name='DINOv2')\n",
    "\n",
    "# _, _, \\\n",
    "# categoria_dino_umap, categoria_image_indices = \\\n",
    "# compute_classifier_embeddings(categoria_dataloader, model, device, 'dino')\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498b0ccb-5116-4131-ae55-446a32140d08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training partially frozen model on balanced dataset to see the difference in results\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "num_classes = len(categoria_filtered_categories)\n",
    "freeze = 7\n",
    "model = DINOClassifier(num_classes, freeze=freeze).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=categoria_class_weights)\n",
    "opt = optim.Adam(model.parameters(), lr=3e-7, weight_decay=1e-7)\n",
    "model_name = 'frozen_dino_categoria'\n",
    "column_name = 'categoria'\n",
    "\n",
    "execute_train_test(categoria_augmented_dataset, categoria_balanced_test_dataset, device, \\\n",
    "                   batch_size, epochs, num_classes, model, criterion, opt, model_name, \\\n",
    "                   column_name, categoria_balanced_val_dataset, architecture_name='DINOv2')\n",
    "\n",
    "_, _, \\\n",
    "categoria_dino_umap, categoria_image_indices = \\\n",
    "compute_classifier_embeddings(categoria_dataloader, model, device, 'dino')\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0973b009-6372-4d31-ab43-b0be7ad21ff5",
   "metadata": {},
   "source": [
    "#### Multi-Head Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba1ceba-58c4-412d-bf76-fa70f4f5cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering dataframe for selected categories\n",
    "threshold_multiplier = 2\n",
    "minority_classes, majority_classes, labels_minority, labels_majority, \\\n",
    "val_labels, test_labels, multi_augmented_dataset, multi_balanced_val_dataset, \\\n",
    "multi_balanced_test_dataset = \\\n",
    "multihead_filter_image_data_distribution(ind_df, [multi_povo_filtered_categories_names, \\\n",
    "                                         multi_categoria_filtered_categories_names], \\\n",
    "                                         dino_transform, threshold_multiplier, \\\n",
    "                                         ['povo', 'categoria'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a0004c-9c36-4920-866a-bb035d9985e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the dataset is still unbalanced, we also create class weights for the loss function\n",
    "multi_povo_class_weights = multihead_compute_class_weights(multi_povo_filtered_categories, \\\n",
    "                                                           labels_minority, labels_majority, \\\n",
    "                                                           device, threshold_multiplier, \\\n",
    "                                                           'povo')\n",
    "\n",
    "multi_categoria_class_weights = \\\n",
    "multihead_compute_class_weights(multi_categoria_filtered_categories, labels_minority, \\\n",
    "                                labels_majority, device, threshold_multiplier,'categoria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461388ef-352a-4ee7-acec-88a2205152cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import image_training_utils\n",
    "importlib.reload(image_training_utils)\n",
    "from image_training_utils import *\n",
    "\n",
    "# Training multi-head model on balanced dataset to see the difference in results\n",
    "batch_size = 8\n",
    "epochs = 20\n",
    "num_classes = [len(multi_povo_filtered_categories), len(multi_categoria_filtered_categories)]\n",
    "model = DINOClassifier(num_classes[0], num_classes[1]).to(device)\n",
    "criterions = [nn.CrossEntropyLoss(weight=multi_povo_class_weights), \\\n",
    "              nn.CrossEntropyLoss(weight=multi_categoria_class_weights)]\n",
    "opt = optim.Adam(model.parameters(), lr=3e-7, weight_decay=1e-7)\n",
    "model_name = 'multihead_dino'\n",
    "column_names = ['povo', 'categoria']\n",
    "arch_name = 'DINOv2'\n",
    "head_weights = [0.5, 0.5]\n",
    "\n",
    "multihead_execute_train_test(multi_augmented_dataset, multi_balanced_test_dataset, device, \\\n",
    "                             batch_size, epochs, num_classes, model, \\\n",
    "                             criterions, opt, model_name, column_names, \\\n",
    "                             multi_balanced_val_dataset, arch_name, head_weights)\n",
    "\n",
    "_, _, multihead_dino_umap, \\\n",
    "multihead_image_indices = compute_classifier_embeddings(categoria_dataloader, model, device, \\\n",
    "                                                        'dino')\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff69dbc0-c068-49e5-9ead-cba4df5f6621",
   "metadata": {},
   "source": [
    "### Visualizing and Comparing Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57420473-f668-471a-86fa-e3306d01f59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing data for later plot on tool\n",
    "vanilla_dino_umap = normalize(vanilla_dino_umap, norm_factor)\n",
    "povo_dino_umap = normalize(povo_dino_umap, norm_factor)\n",
    "categoria_dino_umap = normalize(categoria_dino_umap, norm_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ef94fc-64d8-4863-9695-7588e6ca47d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing resulting projections\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.suptitle('Comparing ViT and DINO Projections')\n",
    "\n",
    "# Plotting all ViT projections\n",
    "projs = [vanilla_vit_umap, povo_vit_umap, categoria_vit_umap, multihead_vit_umap]\n",
    "proj_names = [\"Vanilla ViT\", \"'povo' ViT\", \"'categoria' ViT\", \"Multi-head ViT\"]\n",
    "row_scatter_plot(projs, proj_names, 1, 'b', 2, 4)\n",
    "\n",
    "# Plotting all DINO projections\n",
    "projs = [vanilla_dino_umap, povo_dino_umap, categoria_dino_umap, multihead_dino_umap]\n",
    "proj_names = [\"Vanilla DINO\", \"'povo' DINO\", \"'categoria' DINO\", \"Multi-head DINO\"]\n",
    "row_scatter_plot(projs, proj_names, 2, 'r', 2, 4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037b94c6-b159-47ca-b81a-e162b7abf2c6",
   "metadata": {},
   "source": [
    "### Visualizing Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c12e262-61f8-4f7c-96df-cd86e3116a6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filtering dataframe to get only the part that contains images\n",
    "filtered_df = ind_df.loc[ind_df['image_path'].notna()]\n",
    "\n",
    "# Visualizing 'povo' cluster\n",
    "visualizing_clusters(filtered_df, povo_dino_umap, povo_image_indices, 'povo', 'UMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713d034d-00a4-4657-8f13-5fcc255af579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing 'categoria' cluster\n",
    "visualizing_clusters(filtered_df, categoria_dino_umap, categoria_image_indices, \\\n",
    "                     'categoria', 'UMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216f499f-2c92-4e16-b5e5-6f23abb9f694",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualizing 'povo' cluster for multi-head modedl\n",
    "visualizing_clusters(filtered_df, multihead_dino_umap, multihead_image_indices, \\\n",
    "                     'povo', 'UMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c251dd5-3d74-4daf-bcf1-e8b9f0c2e121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing 'categoria' cluster for multi-head modedl\n",
    "visualizing_clusters(filtered_df, multihead_dino_umap, multihead_image_indices, \\\n",
    "                     'categoria', 'UMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ff9039-99fd-40c8-90c7-dd0e2ceb32c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving outputs for visualization tool\n",
    "_ = saving_outputs(filtered_df, povo_labels, vanilla_dino_umap, vanilla_image_indices, \\\n",
    "                   save_file='vanilla_dino.csv', no_clusters=True)\n",
    "\n",
    "_ = saving_outputs(filtered_df, povo_labels, povo_dino_umap, povo_image_indices, 'povo', \\\n",
    "                   'povo_dino.csv')\n",
    "\n",
    "_ = saving_outputs(filtered_df, categoria_labels, categoria_dino_umap, \\\n",
    "                   categoria_image_indices, 'categoria', 'categoria_dino.csv')\n",
    "\n",
    "_ = saving_outputs(filtered_df, povo_labels, multihead_dino_umap, \\\n",
    "                   multihead_image_indices, save_file='multihead_dino.csv', no_clusters=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
