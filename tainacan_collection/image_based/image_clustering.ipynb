{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef9795d-0158-4db9-8f3a-ec9139c1f258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe columns: \n",
      "Index(['url', 'thumbnail', 'creation_date', 'modification_date',\n",
      "       'numero_do_item', 'tripticos', 'categoria', 'nome_do_item',\n",
      "       'nome_do_item_dic', 'colecao', 'coletor', 'doador', 'modo_de_aquisicao',\n",
      "       'data_de_aquisicao', 'ano_de_aquisicao', 'data_de_confeccao', 'autoria',\n",
      "       'nome_etnico', 'descricao', 'dimensoes', 'funcao', 'materia_prima',\n",
      "       'tecnica_confeccao', 'descritor_tematico', 'descritor_comum',\n",
      "       'numero_de_pecas', 'itens_relacionados', 'responsavel_guarda',\n",
      "       'inst_detentora', 'povo', 'autoidentificacao', 'lingua',\n",
      "       'estado_de_origem', 'geolocalizacao', 'pais_de_origem', 'exposicao',\n",
      "       'referencias', 'disponibilidade', 'qualificacao', 'historia_adm',\n",
      "       'notas_gerais', 'observacao', 'conservacao', 'image_path'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading dataset\n",
    "ind_df = pd.read_csv('../data/indigenous_collection_processed.csv', index_col='id')\n",
    "print(f'Dataframe columns: \\n{ind_df.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc645b59-5f75-4644-8482-a2aeb836d2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "# Creating skip cell command\n",
    "@register_cell_magic\n",
    "def skip(line, cell):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd1297d5-556c-4811-b8d4-1761e8750542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centralizing main imports so we can run the models separately\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from image_training_utils import *\n",
    "\n",
    "# import image_training_utils\n",
    "# importlib.reload(image_training_utils)\n",
    "# from image_training_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561deae7-07e5-412b-86b4-4f42b9ce3b52",
   "metadata": {},
   "source": [
    "# Image Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dfc3e7-84fa-48da-a625-239a17b0e021",
   "metadata": {},
   "source": [
    "Clustering experiments with image feature extractors. The idea is to fine-tune some pre-trained transformer models on our dataset and then remove the last layer of the model to cluster on the embedding space projections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecfe485-3be5-4694-8198-c50a3d03555e",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a1f9c8-c490-4d69-a6e1-f8aa2d1280e7",
   "metadata": {},
   "source": [
    "For fine-tuning the model on our dataset, we are going to try a couple different labels (*povo* and *categoria*) and study how they affect the generated emebdding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ce8b405-dd10-44cd-8d6c-31d4c4d81131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 corrupted images\n"
     ]
    }
   ],
   "source": [
    "# Filtering out corrupted images\n",
    "corrupted_images = []\n",
    "for index, row in ind_df.loc[ind_df['image_path'].notna()].iterrows():\n",
    "    try:\n",
    "        Image.open('../'+row['image_path'])\n",
    "    except Exception as e:\n",
    "        corrupted_images.append(row['image_path'])\n",
    "        ind_df.loc[index, 'image_path'] = pd.NA\n",
    "print(f'{len(corrupted_images)} corrupted images')\n",
    "\n",
    "# Creating 'image_path_br' column\n",
    "ind_df['image_path_br'] = ind_df['image_path'].values\n",
    "ind_df.loc[ind_df['image_path_br'].notna(), 'image_path_br'] = \\\n",
    "    ind_df.loc[ind_df['image_path_br'].notna(), \\\n",
    "               'image_path'].apply(lambda path: \\\n",
    "                                   f\"data/br_images/{path.split('/')[-1].split('.')[0]}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9804fc-d317-492a-88c1-72cad645cfb4",
   "metadata": {},
   "source": [
    "## ViT Base Patch-16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dd4318-0161-463e-94dc-ba1987cdb366",
   "metadata": {},
   "source": [
    "### Pre-trained Embedding Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eb70f6d-7d44-40f5-b2f5-94053a767665",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting the proper device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Building dataset for column 'povo' (though no specific column is used on off-the-shelf model)\n",
    "vit_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "povo_labels, povo_name_to_num, povo_num_to_name = preparing_image_labels(ind_df, 'povo')\n",
    "povo_dataset = ImageDataset(povo_labels, transform=vit_transform, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34e247fc-988b-4850-b908-ed363357f2b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|█████████████████████████████████████████| 23/23 [03:00<00:00,  7.83s/it]\n",
      "/home/lui/anaconda3/envs/ind_thesis/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Projecting data onto the off-the-shelf pre-trained embedding space from ViT\n",
    "from transformers import ViTModel\n",
    "\n",
    "# Loading model\n",
    "model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "model.to(device)\n",
    "\n",
    "# Getting data\n",
    "povo_dataloader = DataLoader(povo_dataset, batch_size=512, shuffle=True, \\\n",
    "                             num_workers=0, pin_memory=True)\n",
    "\n",
    "# Computing image embeddings\n",
    "image_embeddings, vanilla_image_indices = get_embeddings(model, povo_dataloader, device)\n",
    "image_embeddings = np.concatenate(image_embeddings, axis=0)\n",
    "\n",
    "# Computing data projection\n",
    "vanilla_vit_trimap, vanilla_vit_tsne, vanilla_vit_umap = data_projections(image_embeddings)\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model, image_embeddings])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f18e80f-1305-4675-8f89-e70f6ee00187",
   "metadata": {},
   "source": [
    "### Fine-Tuning Embedding Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "397cc9e7-c214-4327-bc09-827d8b0413c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our own ViT classifier (multi-)head for fine-tuning\n",
    "class ViTClassifier(nn.Module):\n",
    "    def __init__(self, num_classes1, num_classes2=0, freeze=0):\n",
    "        super(ViTClassifier, self).__init__()\n",
    "        self.vit = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "        self.classifier1 = nn.Linear(self.vit.config.hidden_size, num_classes1)\n",
    "        self.multi_head = False\n",
    "        \n",
    "        # Multi-head architecture\n",
    "        if num_classes2 > 0:\n",
    "            self.classifier2 = nn.Linear(self.vit.config.hidden_size, num_classes2)\n",
    "            self.multi_head = True\n",
    "        \n",
    "        self.freeze_layers(freeze)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.vit(x)\n",
    "        \n",
    "        # Getting embeddings from last_hidden_state of CLS token (maybe pooler_output?)\n",
    "        embeddings = outputs['last_hidden_state'][:, 0, :]\n",
    "        # embeddings = outputs['pooler_output']\n",
    "\n",
    "        logits1 = self.classifier1(embeddings)\n",
    "        if self.multi_head:\n",
    "            logits2 = self.classifier2(embeddings)\n",
    "            return logits1, logits2\n",
    "        return logits1\n",
    "\n",
    "    # Freezing early layers so we don't lose generalization and speed up training\n",
    "    def freeze_layers(self, freeze):\n",
    "        if freeze <= 0:\n",
    "            return\n",
    "\n",
    "        # Accounting for the embedding freeze\n",
    "        freeze -= 1\n",
    "        \n",
    "        for name, param in self.vit.named_parameters():\n",
    "            if \"embeddings\" in name:\n",
    "                param.requires_grad = False\n",
    "            elif int(name.split('.')[2]) < freeze:\n",
    "                param.requires_grad = False\n",
    "            else:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0093a1e-f85f-48b9-b75e-391fb8cd390b",
   "metadata": {},
   "source": [
    "#### *povo* Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f1eed02-7da5-4671-8136-390d5530246d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile X Data Percentage:\n",
      "Q-10: 1.00, 99.84% of data\n",
      "Q-25: 4.00, 99.18% of data\n",
      "Q-50: 19.00, 95.96% of data\n",
      "Q-75: 65.75, 83.18% of data\n",
      "Q-90: 158.20, 63.25% of data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Studying data distribution to filter out rare classes\n",
    "povo_categories, categories_keys, categories_freq, \\\n",
    "qs, masks = study_class_distribution(povo_labels)\n",
    "\n",
    "# Filtering classes so that we retain around 85% of data\n",
    "povo_filtered_categories = {}\n",
    "povo_filtered_categories_names = {}\n",
    "for c in masks[3][0]:\n",
    "    povo_filtered_categories[categories_keys[c]] = povo_categories[categories_keys[c]]\n",
    "    \n",
    "    povo_filtered_categories_names[povo_num_to_name[categories_keys[c]]] = \\\n",
    "    povo_categories[categories_keys[c]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd6a5e63-5680-4a09-a96e-c6fbb91b28b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering dataframe for selected categories\n",
    "threshold_multiplier = 2\n",
    "minority_classes, majority_classes, labels_minority, labels_majority, \\\n",
    "val_labels, test_labels, povo_augmented_dataset, povo_balanced_val_dataset, \\\n",
    "povo_balanced_test_dataset = filter_image_data_distribution(ind_df, \\\n",
    "                                                            povo_filtered_categories_names, \\\n",
    "                                                            vit_transform, \\\n",
    "                                                            threshold_multiplier, \\\n",
    "                                                            'povo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa94d49e-e893-4a83-8917-b34f6a83031e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9wAAAGMCAYAAAAoQarDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABu90lEQVR4nO3deXgN5///8VcWWWQVsogliK32NohQW6Via6uopdqGKmpr0dq6WFta2tpq7UJVKPGhWkql1n40llIfqqWorSVBSGKpIJnfH36ZryOJJJrjJDwf13WuK3PPPTPvOfe55+R95p4ZO8MwDAEAAAAAgDxlb+sAAAAAAAC4H5FwAwAAAABgBSTcAAAAAABYAQk3AAAAAABWQMINAAAAAIAVkHADAAAAAGAFJNwAAAAAAFgBCTcAAAAAAFZAwg0AAAAAgBWQcAMFRJkyZdStWzdbh/GvjR49WnZ2dvdkW02aNFGTJk3M6U2bNsnOzk7Lli27J9vv1q2bypQpc0+2da+sXbtWtWrVkouLi+zs7JSYmGjrkO4pOzs7jR49Ok/XuXPnTtWvX19ubm6ys7PTnj178nT9tlSmTBm1adMmz9Z37Ngx2dnZaf78+Xm2zrt1+/HlXrpx44aGDh2qUqVKyd7eXm3btrVJHMiaNY4VAAomEm7Axo4cOaLevXurXLlycnFxkaenpxo0aKCpU6fqn3/+sXV4dzR//nzZ2dmZLxcXFwUGBioiIkLTpk3TxYsX82Q7p06d0ujRo/NlIpIfY0tPSm59eXp6qlatWvr444+Vmpp6V+tNSEhQx44d5erqqhkzZujLL7+Um5tbHkd/f/n999/NvpHZjxPXr1/XM888o/Pnz2vy5Mn68ssvFRQUpJkzZ97zpLJMmTIWnxk3NzfVrVtXCxYsuKdxIHuff/65Jk2apA4dOuiLL77QoEGDrLq9Jk2aFLgffEePHp2rHzw3bdqkdu3aKSAgQE5OTvLz89MTTzyh5cuXWy9IAA8ER1sHADzIVq9erWeeeUbOzs564YUXVK1aNV27dk3//e9/NWTIEO3fv19z5861dZjZGjt2rMqWLavr168rLi5OmzZt0sCBA/XRRx/pm2++UY0aNcy6b731loYPH56r9Z86dUpjxoxRmTJlVKtWrRwvt27dulxt527cKbZPPvlEaWlpVo8hK126dFGrVq0kSUlJSfruu+80YMAAHT9+XJMmTcr1+nbu3KmLFy9q3LhxCg8Pz+tw70sLFy5UQECALly4oGXLlumll16ymH/kyBEdP35cn3zyicW8mTNnqlixYvc8yalVq5Zee+01SdLp06f16aefKjIyUikpKerZs+c9jSW/uxfHl6xs2LBBJUqU0OTJk20Ww/1k1KhRGjt2rCpUqKDevXsrKChICQkJ+u6779S+fXtFRUXp2WeftXWYAAooEm7ARo4eParOnTsrKChIGzZsUPHixc15/fr10+HDh7V69WobRphzLVu2VO3atc3pESNGaMOGDWrTpo2efPJJ/f7773J1dZUkOTo6ytHRuoeeK1euqHDhwnJycrLqdrJTqFAhm27/kUce0XPPPWdO9+3bV6GhoVq0aNFdJdxnzpyRJHl7e+dViLp8+fJ9e5bcMAwtWrRIzz77rI4ePaqoqKgMCbc13tOs3LhxQ2lpaXfsFyVKlLD4zHTr1k3lypXT5MmTSbhvY8vjy5kzZ/L0M5OWlqZr167JxcUlz9ZZUCxbtkxjx45Vhw4dtGjRIovj9pAhQ/T999/r+vXrNowQQEHHkHLARiZOnKhLly7ps88+s0i205UvX16vvvpqlsufP39er7/+uqpXry53d3d5enqqZcuW+t///peh7vTp01W1alUVLlxYRYoUUe3atbVo0SJz/sWLFzVw4ECVKVNGzs7O8vPz0+OPP67du3ff9f499thjevvtt3X8+HEtXLjQLM/sGu6YmBg9+uij8vb2lru7uypVqqQ33nhD0s1hfnXq1JEkde/e3Rzumj7ctkmTJqpWrZp27dqlRo0aqXDhwuayWV1jmZqaqjfeeEMBAQFyc3PTk08+qZMnT1rUyeqa+VvXmV1smV3DffnyZb322msqVaqUnJ2dValSJX3wwQcyDMOinp2dnfr376+vv/5a1apVk7Ozs6pWraq1a9dm/obngJ2dnfz9/TP9wWPNmjVq2LCh3Nzc5OHhodatW2v//v0W+x0ZGSlJqlOnjuzs7Czen+joaIWEhMjV1VXFihXTc889p7///ttiG926dZO7u7uOHDmiVq1aycPDQ127dpV08x/+KVOmqGrVqnJxcZG/v7969+6tCxcuZLtfe/fuNRNDFxcXBQQE6MUXX1RCQoJFvfTP3uHDh9WtWzd5e3vLy8tL3bt315UrVyzqpqSkaNCgQfL19ZWHh4eefPJJ/fXXX9nGcqutW7fq2LFj6ty5szp37qwtW7ZYrKNbt25q3LixJOmZZ56RnZ2dmjRpojJlymj//v3avHmz+Zm69XOcmJiogQMHmp+h8uXL6/3337cYTZF+WcEHH3ygKVOmKDg4WM7Ozvrtt99ytQ++vr6qXLmyjhw5YlGe2/Zat26dee1/lSpVMgzTzc3x7HbWaH/p5uiEunXrmsfNRo0aWZzVzuoeEUuXLtW7776rkiVLysXFRc2aNdPhw4czrH/GjBkqV66cXF1dVbduXf3444/ZXhee3q4bN27U/v37zc/Hpk2bJOX++BIVFaWqVavK2dk5V8eW9H1dsmRJtsdSKfvjwwcffCA7OzsdP348w7IjRoyQk5OTxWcrJ8ebnHr77bfl4+Ojzz//PNMfSSMiIizuQ3DmzBn16NFD/v7+cnFxUc2aNfXFF19ku52s7umR2XdievtER0erSpUqcnV1VVhYmPbt2ydJmjNnjsqXLy8XFxc1adJEx44ds1g+/Xvxt99+U9OmTVW4cGGVKFFCEydOzME7AiCvcYYbsJFvv/1W5cqVU/369e9q+T///FNff/21nnnmGZUtW1bx8fGaM2eOGjdurN9++02BgYGSbg5rfuWVV9ShQwe9+uqrunr1qvbu3avt27ebQ+RefvllLVu2TP3791eVKlWUkJCg//73v/r999/1yCOP3PU+Pv/883rjjTe0bt26LM+O7d+/X23atFGNGjU0duxYOTs76/Dhw9q6dask6aGHHtLYsWM1cuRI9erVSw0bNpQki/ctISFBLVu2VOfOnfXcc8/J39//jnG9++67srOz07Bhw3TmzBlNmTJF4eHh2rNnj3kmPidyEtutDMPQk08+qY0bN6pHjx6qVauWvv/+ew0ZMkR///13huGh//3vf7V8+XL17dtXHh4emjZtmtq3b68TJ06oaNGi2cZ35coVnTt3TpKUnJysNWvWaO3atRoxYoRFvS+//FKRkZGKiIjQ+++/rytXrmjWrFl69NFH9csvv6hMmTJ68803ValSJc2dO9e8hCA4OFjSzWv5u3fvrjp16mjChAmKj4/X1KlTtXXrVv3yyy8WZ+Ju3LihiIgIPfroo/rggw9UuHBhSVLv3r3N9bzyyis6evSoPv74Y/3yyy/aunXrHUcLxMTE6M8//1T37t0VEBBgXoqxf/9+bdu2LcM/sx07dlTZsmU1YcIE7d69W59++qn8/Pz0/vvvm3VeeuklLVy4UM8++6zq16+vDRs2qHXr1tm+57eKiopScHCw6tSpo2rVqqlw4cJavHixhgwZYu5ziRIlNH78eL3yyiuqU6eO/P39dfnyZQ0YMEDu7u568803Jcn8TF+5ckWNGzfW33//rd69e6t06dL66aefNGLECJ0+fVpTpkyxiGHevHm6evWqevXqJWdnZ/n4+ORqH27cuKG//vpLRYoUsSjPTXsdOnRInTp10ssvv6zIyEjNmzdPzzzzjNauXavHH39cUs6PZ5mxRvuPGTNGo0ePVv369TV27Fg5OTlp+/bt2rBhg5o3b37H9+y9996Tvb29Xn/9dSUlJWnixInq2rWrtm/fbtaZNWuW+vfvr4YNG2rQoEE6duyY2rZtqyJFiqhkyZJZrtvX11dffvml3n33XV26dEkTJkyQdPNYlNvjy4YNG7R06VL1799fxYoVu6sbPObkWJqT40PHjh01dOhQLV261Owf6ZYuXarmzZubn8HcHG+yc+jQIR04cEAvvviiPDw8sq3/zz//qEmTJjp8+LD69++vsmXLKjo6Wt26dVNiYuIdfyTPrR9//FHffPON+vXrJ0maMGGC2rRpo6FDh2rmzJnq27evLly4oIkTJ+rFF1/Uhg0bLJa/cOGCWrRooXbt2qljx45atmyZhg0bpurVq6tly5Z5FieAHDAA3HNJSUmGJOOpp57K8TJBQUFGZGSkOX316lUjNTXVos7Ro0cNZ2dnY+zYsWbZU089ZVStWvWO6/by8jL69euX41jSzZs3z5Bk7Ny5847rfvjhh83pUaNGGbceeiZPnmxIMs6ePZvlOnbu3GlIMubNm5dhXuPGjQ1JxuzZszOd17hxY3N648aNhiSjRIkSRnJyslm+dOlSQ5IxdepUs+z29zurdd4ptsjISCMoKMic/vrrrw1JxjvvvGNRr0OHDoadnZ1x+PBhs0yS4eTkZFH2v//9z5BkTJ8+PcO2bnX06FFDUqavPn36GGlpaWbdixcvGt7e3kbPnj0t1hEXF2d4eXlZlGfW3teuXTP8/PyMatWqGf/8849ZvmrVKkOSMXLkSIv3Q5IxfPhwi239+OOPhiQjKirKonzt2rWZlt/uypUrGcoWL15sSDK2bNlilqV/9l588UWLuk8//bRRtGhRc3rPnj2GJKNv374W9Z599llDkjFq1Kg7xmMYN9+XokWLGm+++abF8jVr1rSol/6ZjI6OtiivWrWqxecs3bhx4ww3Nzfjjz/+sCgfPny44eDgYJw4ccIwjP/7DHh6ehpnzpzJNl7DuPmZb968uXH27Fnj7Nmzxr59+4znn3/ekGRxfMhNewUFBRmSjP/85z9mWVJSklG8eHGL40JOj2fp+3Vrf8vr9j906JBhb29vPP300xliurXvZHV8eeihh4yUlBSzfOrUqYYkY9++fYZhGEZKSopRtGhRo06dOsb169fNevPnzzckZdrut2vcuHGG43pujy/29vbG/v37s91WZnJ6LM3N8SEsLMwICQmx2M6OHTsMScaCBQtyvb6cWLlypSHJmDx5co7qT5kyxZBkLFy40Cy7du2aERYWZri7u1u8F7cfK27/Pkh3+3di+rLOzs7G0aNHzbI5c+YYkoyAgACL7YwYMcKQZFE3/Xsx/X0zjJufu4CAAKN9+/Y52lcAeYch5YANJCcnS1KOflHPirOzs+ztb3bh1NRUJSQkmMOxbx0K7u3trb/++ks7d+7Mcl3e3t7avn27Tp06ddfxZMXd3f2OdytPPxuxcuXKu77BmLOzs7p3757j+i+88ILFe9+hQwcVL15c33333V1tP6e+++47OTg46JVXXrEof+2112QYhtasWWNRHh4ebp5FlqQaNWrI09NTf/75Z46216tXL8XExCgmJkb/+c9/1K9fP82ZM0eDBw8268TExCgxMVFdunTRuXPnzJeDg4NCQ0O1cePGO27j559/1pkzZ9S3b1+L6z9bt26typUrZ3ofgj59+lhMR0dHy8vLS48//rhFDCEhIXJ3d882hltHJVy9elXnzp1TvXr1JCnTyyJefvlli+mGDRsqISHB7Jfpn4Pb22ngwIF3jONWa9asUUJCgrp06WKWdenSRf/73/8shurnVnR0tBo2bKgiRYpYvFfh4eFKTU3Vli1bLOq3b99evr6+OV7/unXr5OvrK19fX1WvXl1ffvmlunfvbnHNf27bKzAwUE8//bQ57enpqRdeeEG//PKL4uLiJOX8eJaZvG7/r7/+WmlpaRo5cqQZU7qcPNKwe/fuFtd3p498Se+3P//8sxISEtSzZ0+Lyzu6du2aYSRBbuT2+NK4cWNVqVLlrrcnZX8szc3xoVOnTtq1a5fF5QtLliyRs7OznnrqqVyvLydy+1383XffKSAgwKJfFypUSK+88oouXbqkzZs352r7d9KsWTOLUQehoaGSbvbpW+NNL7/9e8Hd3d3ifgxOTk6qW7dujr8/AOQdEm7ABjw9PSXpXz02Ky0tTZMnT1aFChXk7OysYsWKydfXV3v37lVSUpJZb9iwYXJ3d1fdunVVoUIF9evXzxyunW7ixIn69ddfVapUKdWtW1ejR4/Osy/lS5cu3fGfmU6dOqlBgwZ66aWX5O/vr86dO2vp0qW5Sr5LlCiRqxsYVahQwWLazs5O5cuXz3AdXF47fvy4AgMDM7wfDz30kDn/VqVLl86wjiJFiuToumbp5n6Gh4crPDxc7dq108cff6y+fftqypQp5rWAhw4dknTzmvv0RCv9tW7dOvOmXnfaJ0mqVKlShnmVK1fOsE+Ojo4ZhsweOnRISUlJ8vPzyxDDpUuXso3h/PnzevXVV+Xv7y9XV1f5+vqqbNmykmTRF9Ld/r6mJznp7+vx48dlb29v8WNHVvuYlYULF6ps2bLmJRKHDx9WcHCwChcurKioqByv53aHDh3S2rVrM7xP6XeNv/29Sn8fcio0NFQxMTFau3atPvjgA3l7e+vChQsW/Su37VW+fPkMiWrFihUlyexzOT2eZSav2//IkSOyt7e/62Q0J58v6eb7citHR8e7GtadLrfHl9x+NjKT3bE0N8eHZ555Rvb29lqyZImkm5fgREdHq2XLluZ3Zm6PN9nJ7Xfx8ePHVaFChQw/xGT1Hv8bt3+OvLy8JEmlSpXKtPz274WSJUtm6He5+f4AkHe4hhuwAU9PTwUGBurXX3+963WMHz9eb7/9tl588UWNGzdOPj4+sre318CBAy2S1YceekgHDx7UqlWrtHbtWv3nP//RzJkzNXLkSI0ZM0bSzWsaGzZsqBUrVmjdunWaNGmS3n//fS1fvvxfXev1119/KSkpKcM/lrdydXXVli1btHHjRq1evVpr167VkiVL9Nhjj2ndunVycHDIdju5ue46p7I6k5WampqjmPJCVtsxbrsBUm40a9ZMH3/8sbZs2aLq1aubn5Uvv/xSAQEBGern9R3lbz2TmS4tLU1+fn5ZJqLZnaHt2LGjfvrpJw0ZMkS1atWSu7u70tLS1KJFi0x/uLHG+3qr5ORkffvtt7p69WqGhESSFi1aZF77mltpaWl6/PHHNXTo0Eznpyey6XLbN4oVK2Ym7xEREapcubLatGmjqVOnmiMj/m17ZSanx7PM5Lf2t/b684o1jpv/RmBgoBo2bKilS5fqjTfe0LZt23TixAmLa+vzWuXKlSXJ/AHSmu70nZKZrD5HOf18FZTPIfAgIOEGbKRNmzaaO3euYmNjFRYWluvlly1bpqZNm+qzzz6zKE9MTFSxYsUsytzc3NSpUyd16tRJ165dU7t27fTuu+9qxIgR5rC84sWLq2/fvurbt6/OnDmjRx55RO++++6/Sri//PJLSTf/cb8Te3t7NWvWTM2aNdNHH32k8ePH680339TGjRsVHh5+V4nJnaSf1U1nGIYOHz5s8bzwIkWKKDExMcOyx48fV7ly5czp3MQWFBSkH374QRcvXrQ4C3XgwAFzvrXduHFD0s2RB5LMs7h+fn539Wzt9JgPHjyoxx57zGLewYMHc7RPwcHB+uGHH9SgQYNcJwEXLlzQ+vXrNWbMGI0cOdIsv72NcyMoKEhpaWk6cuSIxZm0gwcP5mj55cuX6+rVq5o1a1aGvnjw4EG99dZb2rp1qx599NEs15HV5yo4OFiXLl26Z89Bb926tRo3bqzx48erd+/ecnNzy3V7HT58WIZhWOzTH3/8IUnmGd3cHM9uZY32Dw4OVlpamn777TfVqlXrrteTlfQ+cfjwYTVt2tQsv3Hjho4dO2ZxHMrteu/18SW7Y2lujw+dOnVS3759dfDgQS1ZskSFCxfWE088Yc7Pi+PNrSpWrKhKlSpp5cqVmjp1qtzd3e9YPygoSHv37lVaWprFD4c5eY/v9J0C4P7GkHLARoYOHSo3Nze99NJLio+PzzD/yJEjmjp1apbLOzg4ZPilOjo6OsOjUW5/NI6Tk5OqVKkiwzB0/fp1paamZhh26efnp8DAQKWkpOR2t0wbNmzQuHHjVLZsWfPRT5k5f/58hrL0f3LTt5/+nObM/lm5GwsWLLAYQrhs2TKdPn3a4seF4OBgbdu2TdeuXTPLVq1aleGRN7mJrVWrVkpNTdXHH39sUT558mTZ2dndkzvHfvvtt5KkmjVrSrr5Y4inp6fGjx+f6bNmz549e8f11a5dW35+fpo9e7bF52XNmjX6/fffc3Rn744dOyo1NVXjxo3LMO/GjRt3fG/Tz+Lc3hduv1t3bqS3w7Rp0+5qnQsXLlS5cuX08ssvq0OHDhav119/Xe7u7tkOK3dzc8t0vzt27KjY2Fh9//33GeYlJiaaP6jkpWHDhikhIUGffPKJGUNu2uvUqVNasWKFOZ2cnKwFCxaoVq1a5qiKnB7PbmeN9m/btq3s7e01duzYDGfI8+LsYO3atVW0aFF98sknFu0VFRX1r4b72uL4kt2xNLfHh/bt28vBwUGLFy9WdHS02rRpYx5j72Z9OTFmzBglJCTopZdeyrT/rFu3TqtWrZJ08z2Oi4szh71LNz/z06dPl7u7u/mYv8wEBwcrKSlJe/fuNctOnz5t0TcA3J84ww3YSHBwsBYtWqROnTrpoYce0gsvvKBq1arp2rVr+umnn8xHjWSlTZs2Gjt2rLp376769etr3759ioqKsjj7KknNmzdXQECAGjRoIH9/f/3+++/6+OOP1bp1a3l4eCgxMVElS5ZUhw4dVLNmTbm7u+uHH37Qzp079eGHH+ZoX9asWaMDBw7oxo0bio+P14YNGxQTE6OgoCB98803Fje3ud3YsWO1ZcsWtW7dWkFBQTpz5oxmzpypkiVLmmcAg4OD5e3trdmzZ8vDw0Nubm4KDQ2962sQfXx89Oijj6p79+6Kj4/XlClTVL58eYtHl7300ktatmyZWrRooY4dO+rIkSNauHBhhut6cxPbE088oaZNm+rNN9/UsWPHVLNmTa1bt04rV67UwIEDM6z739q9e7f5DPSLFy9q/fr1+s9//qP69eubjzby9PTUrFmz9Pzzz+uRRx5R586d5evrqxMnTmj16tVq0KBBhn/gb1WoUCG9//776t69uxo3bqwuXbqYj+kpU6aMBg0alG2cjRs3Vu/evTVhwgTt2bNHzZs3V6FChXTo0CFFR0dr6tSp6tChQ6bLenp6qlGjRpo4caKuX7+uEiVKaN26dTp69OhdvGM31apVS126dNHMmTOVlJSk+vXra/369Zk+S/l2p06d0saNGzPcuCqds7OzIiIiFB0dnSGhv1VISIhmzZqld955R+XLl5efn58ee+wxDRkyRN98843atGmjbt26KSQkRJcvX9a+ffu0bNkyHTt27I5nhO9Gy5YtVa1aNX300Ufq169frturYsWK6tGjh3bu3Cl/f399/vnnio+P17x588w6OT2e3c4a7V++fHm9+eabGjdunBo2bKh27drJ2dlZO3fuVGBgoPkorrvl5OSk0aNHa8CAAXrsscfUsWNHHTt2TPPnz1dwcPBdj+i518cXKftjaW6PD35+fmratKk++ugjXbx4UZ06dbKYnxfHm9t16tRJ+/bt07vvvqtffvlFXbp0UVBQkBISErR27VqtX79eixYtknTzRpRz5sxRt27dtGvXLpUpU0bLli3T1q1bNWXKlDver6Rz584aNmyYnn76ab3yyivm4xcrVqyY7Y0BARRw9/q26AAs/fHHH0bPnj2NMmXKGE5OToaHh4fRoEEDY/r06cbVq1fNepk9Fuy1114zihcvbri6uhoNGjQwYmNjMzyqZs6cOUajRo2MokWLGs7OzkZwcLAxZMgQIykpyTCMm48KGTJkiFGzZk3Dw8PDcHNzM2rWrGnMnDkz29jTHxOV/nJycjICAgKMxx9/3Jg6darFo0vS3f4IlPXr1xtPPfWUERgYaDg5ORmBgYFGly5dMjz2aOXKlUaVKlUMR0dHi8cCZfZ4nHRZPbZn8eLFxogRIww/Pz/D1dXVaN26tXH8+PEMy3/44YdGiRIlDGdnZ6NBgwbGzz//nGGdd4ots8fAXLx40Rg0aJARGBhoFCpUyKhQoYIxadIki8cNGYaR4VFM6bJ6XNmtMnssmKOjo1GuXDljyJAhxsWLFzMss3HjRiMiIsLw8vIyXFxcjODgYKNbt27Gzz//bNa502PglixZYjz88MOGs7Oz4ePjY3Tt2tX466+/LOpERkYabm5uWcY9d+5cIyQkxHB1dTU8PDyM6tWrG0OHDjVOnTp1x/3966+/jKefftrw9vY2vLy8jGeeecY4depUhsfypH/2bn8EXfp+3fpYnX/++cd45ZVXjKJFixpubm7GE088YZw8eTLbx4J9+OGHhiRj/fr1WdZJf/zTypUrs3wsWFxcnNG6dWvDw8Mjw6OiLl68aIwYMcIoX7684eTkZBQrVsyoX7++8cEHHxjXrl0zDOP/PgOTJk2643t3q6CgIKN169Z3jPnWx3HlpL3S1/n9998bNWrUMJydnY3KlStn2N+cHs8yeyyYNdrfMAzj888/Nz/TRYoUMRo3bmzExMSY87M6vty+b5nFbBiGMW3aNCMoKMhwdnY26tata2zdutUICQkxWrRokUkLWMrquPdvjy85ldtjaU6OD+k++eQTQ5Lh4eFh8eivu11fTqV/F/n5+RmOjo6Gr6+v8cQTTxgrV660qBcfH290797dKFasmOHk5GRUr14908dCZnasWLdunVGtWjXDycnJqFSpkrFw4cIsHwt2e/tk1acz+9xl9fnI6tFkAKzLzjC4ewIAAIAtpaWlydfXV+3atTOH7+dXmzZtUtOmTRUdHZ3l6BMAwE1cww0AAHAPXb16NcP14AsWLND58+fVpEkT2wQFALAKruEGAAC4h7Zt26ZBgwbpmWeeUdGiRbV792599tlnqlatmp555hlbhwcAyEMk3AAAAPdQmTJlVKpUKU2bNk3nz5+Xj4+PXnjhBb333ntycnKydXgAgDzENdwAAAAAAFgB13ADAAAAAGAFJNwAAAAAAFgBCTcAAAAAAFZAwg0AAAAAgBWQcAMAAAAAYAUk3AAAAAAAWAEJNwAAAAAAVkDCDQAAAACAFZBwAwAAAABgBSTcAAAAAABYAQk3AAAAAABWQMINAAAAAIAVkHADAAAAAGAFJNwAAAAAAFgBCTcAAAAAAFZAwg0AAAAAgBWQcAMAAAAAYAUk3AAAAAAAWAEJNwAAAAAAVkDCDQAAAACAFZBwAwAAAABgBSTcAABkY9KkSSpXrpwcHBxUq1YtW4djNU2aNFG1atXydJ12dnYaPXp0nq7zbnTr1k1lypSxdRgAgAcMCTcA4L4wf/582dnZWbz8/PzUtGlTrVmz5q7Xu27dOg0dOlQNGjTQvHnzNH78+DyM+u41adLEYl9dXV1Vo0YNTZkyRWlpabYODwAASHK0dQAAAOSlsWPHqmzZsjIMQ/Hx8Zo/f75atWqlb7/9Vm3atMn1+jZs2CB7e3t99tlncnJyskLEd69kyZKaMGGCJOncuXNatGiRBg0apLNnz+rdd9+1cXT5yyeffMIPEQCAe46EGwBwX2nZsqVq165tTvfo0UP+/v5avHjxXSXcZ86ckaura54l24Zh6OrVq3J1df3X6/Ly8tJzzz1nTr/88suqXLmypk+frrFjx8rBweFfb+N+UahQIVuHAAB4ADGkHABwX/P29parq6scHS1/Y05LS9OUKVNUtWpVubi4yN/fX71799aFCxfMOnZ2dpo3b54uX75sDt2eP3++JOnGjRsaN26cgoOD5ezsrDJlyuiNN95QSkqKxXbKlCmjNm3a6Pvvv1ft2rXl6uqqOXPmSJISExM1cOBAlSpVSs7Ozipfvrzef//9uz4T6+Liojp16ujixYs6c+aMxbyFCxcqJCRErq6u8vHxUefOnXXy5MlM17Nr1y7Vr19frq6uKlu2rGbPnm0x/9q1axo5cqRCQkLk5eUlNzc3NWzYUBs3bsw2xuPHj6tv376qVKmSXF1dVbRoUT3zzDM6duyYRb30SwS2bt2qwYMHy9fXV25ubnr66ad19uzZDOtds2aNGjduLA8PD3l6eqpOnTpatGiROf/2a7iPHTsmOzs7ffDBB5o7d67ZjnXq1NHOnTszrD86OlpVqlSRi4uLqlWrphUrVnBdOAAgW5zhBgDcV5KSknTu3DkZhqEzZ85o+vTpunTpksWZYEnq3bu35s+fr+7du+uVV17R0aNH9fHHH+uXX37R1q1bVahQIX355ZeaO3euduzYoU8//VSSVL9+fUnSSy+9pC+++EIdOnTQa6+9pu3bt2vChAn6/ffftWLFCottHTx4UF26dFHv3r3Vs2dPVapUSVeuXFHjxo31999/q3fv3ipdurR++uknjRgxQqdPn9aUKVPuav/TE0lvb2+z7N1339Xbb7+tjh076qWXXtLZs2c1ffp0NWrUSL/88otF3QsXLqhVq1bq2LGjunTpoqVLl6pPnz5ycnLSiy++KElKTk7Wp59+qi5duqhnz566ePGiPvvsM0VERGjHjh13vLHczp079dNPP6lz584qWbKkjh07plmzZqlJkyb67bffVLhwYYv6AwYMUJEiRTRq1CgdO3ZMU6ZMUf/+/bVkyRKzzvz58/Xiiy+qatWqGjFihLy9vfXLL79o7dq1evbZZ+/4fi1atEgXL15U7969ZWdnp4kTJ6pdu3b6888/zbPiq1evVqdOnVS9enVNmDBBFy5cUI8ePVSiRIkctgoA4IFlAABwH5g3b54hKcPL2dnZmD9/vkXdH3/80ZBkREVFWZSvXbs2Q3lkZKTh5uZmUW/Pnj2GJOOll16yKH/99dcNScaGDRvMsqCgIEOSsXbtWou648aNM9zc3Iw//vjDonz48OGGg4ODceLEiTvub+PGjY3KlSsbZ8+eNc6ePWscOHDAGDJkiCHJaN26tVnv2LFjhoODg/Huu+9aLL9v3z7D0dHRorxx48aGJOPDDz80y1JSUoxatWoZfn5+xrVr1wzDMIwbN24YKSkpFuu7cOGC4e/vb7z44osW5ZKMUaNGmdNXrlzJsC+xsbGGJGPBggVmWXp7hoeHG2lpaWb5oEGDDAcHByMxMdEwDMNITEw0PDw8jNDQUOOff/6xWO+ty0VGRhpBQUHm9NGjRw1JRtGiRY3z58+b5StXrjQkGd9++61ZVr16daNkyZLGxYsXzbJNmzYZkizWCQDA7RhSDgC4r8yYMUMxMTGKiYnRwoUL1bRpU7300ktavny5WSc6OlpeXl56/PHHde7cOfMVEhIid3f3bIdGf/fdd5KkwYMHW5S/9tprkm6eEb1V2bJlFRERYVEWHR2thg0bqkiRIhYxhIeHKzU1VVu2bMl2Xw8cOCBfX1/5+vqqcuXKmjRpkp588klz2LskLV++XGlpaerYsaPFdgICAlShQoUM++ro6KjevXub005OTurdu7fOnDmjXbt2SZIcHBzMa9rT0tJ0/vx53bhxQ7Vr19bu3bvvGPOt165fv35dCQkJKl++vLy9vTNdtlevXrKzszOnGzZsqNTUVB0/flySFBMTo4sXL2r48OFycXGxWPbW5bLSqVMnFSlSxGL9kvTnn39Kkk6dOqV9+/bphRdekLu7u1mvcePGql69erbrBwA82BhSDgC4r9StW9fipmldunTRww8/rP79+6tNmzZycnLSoUOHlJSUJD8/v0zXcfv1z7c7fvy47O3tVb58eYvygIAAeXt7m8lgurJly2ZYx6FDh7R37175+vreVQzSzevD0+++feTIEb377rs6e/asReJ56NAhGYahChUqZLqO228mFhgYKDc3N4uyihUrSro5XL1evXqSpC+++EIffvihDhw4oOvXr99xX2/1zz//aMKECZo3b57+/vtvGYZhzktKSspQv3Tp0hbT6clx+rX2R44ckaS7fn54dutPb8vb2zq9LLsfGAAADzYSbgDAfc3e3l5NmzbV1KlTdejQIVWtWlVpaWny8/NTVFRUpstklQTfLidnUCVlekfytLQ0Pf744xo6dGimy6QnuXfi5uam8PBwc7pBgwZ65JFH9MYbb2jatGnmduzs7LRmzZpM71p+61nbnFq4cKG6deumtm3basiQIfLz85ODg4MmTJhgJsBZGTBggObNm6eBAwcqLCxMXl5esrOzU+fOnTO9WVxWd1q/NVH/N6y9fgDAg42EGwBw37tx44Yk6dKlS5Kk4OBg/fDDD2rQoMFdPZ4rKChIaWlpOnTokB566CGzPD4+XomJiQoKCsp2HcHBwbp06ZJFwvxv1ahRQ88995zmzJmj119/XaVLl1ZwcLAMw1DZsmVzlMSfOnVKly9ftjjL/ccff0iSeUfuZcuWqVy5clq+fLnFjw6jRo3Kdv3Lli1TZGSkPvzwQ7Ps6tWrSkxMzOFeWgoODpYk/frrr5mehf630tvy8OHDGeZlVgYAwK24hhsAcF+7fv261q1bJycnJzM57tixo1JTUzVu3LgM9W/cuJFt8teqVStJynAn8Y8++kiS1Lp162zj6tixo2JjY/X9999nmJeYmGj+SJBbQ4cO1fXr181Y2rVrJwcHB40ZMybDWVvDMJSQkGBRduPGDfOxZdLNR4DNmTNHvr6+CgkJkfR/Z4VvXd/27dsVGxubbXwODg4Z4pg+fbpSU1NzsZf/p3nz5vLw8NCECRN09epVi3l5cZY6MDBQ1apV04IFC8wfbCRp8+bN2rdv379ePwDg/sYZbgDAfWXNmjU6cOCApJvXQS9atEiHDh3S8OHD5enpKenmDa969+6tCRMmaM+ePWrevLkKFSqkQ4cOKTo6WlOnTlWHDh2y3EbNmjUVGRmpuXPnKjExUY0bN9aOHTv0xRdfqG3btmratGm2cQ4ZMkTffPON2rRpo27duikkJESXL1/Wvn37tGzZMh07dkzFihXL9f5XqVJFrVq10qeffqq3335bwcHBeueddzRixAgdO3ZMbdu2lYeHh44ePaoVK1aoV69eev31183lAwMD9f777+vYsWOqWLGilixZoj179mju3Lnm9d5t2rTR8uXL9fTTT6t169Y6evSoZs+erSpVqlgkpZlp06aNvvzyS3l5ealKlSqKjY3VDz/8oKJFi+Z6XyXJ09NTkydP1ksvvaQ6dero2WefVZEiRfS///1PV65c0RdffHFX673V+PHj9dRTT6lBgwbq3r27Lly4oI8//ljVqlXLdn8BAA82Em4AwH1l5MiR5t8uLi6qXLmyZs2aZXHnbUmaPXu2QkJCNGfOHL3xxhtydHRUmTJl9Nxzz6lBgwbZbufTTz9VuXLlNH/+fK1YsUIBAQEaMWJEjoZVS1LhwoW1efNmjR8/XtHR0VqwYIE8PT1VsWJFjRkzRl5eXrnb8VsMGTJEq1ev1vTp0zV69GgNHz5cFStW1OTJkzVmzBhJUqlSpdS8eXM9+eSTFssWKVJEX3zxhQYMGKBPPvlE/v7++vjjj9WzZ0+zTrdu3RQXF6c5c+bo+++/V5UqVbRw4UJFR0dr06ZNd4xt6tSpcnBwUFRUlK5evaoGDRrohx9+yHAX99zo0aOH/Pz89N5772ncuHEqVKiQKleurEGDBt31Om/1xBNPaPHixeZ7WaFCBc2fP19ffPGF9u/fnyfbAADcn+wM7goCAACQa7Vq1ZKvr69iYmJsHQoAIJ/iGm4AAIA7uH79eoZr6jdt2qT//e9/atKkiW2CAgAUCJzhBgAAuINjx44pPDxczz33nAIDA3XgwAHNnj1bXl5e+vXXX+/6+nMAwP2Pa7gBAADuoEiRIgoJCdGnn36qs2fPys3NTa1bt9Z7771Hsg0AuCPOcAMAAAAAYAVcww0AAAAAgBXct0PK09LSdOrUKXl4eMjOzs7W4QAAAAAACjjDMHTx4kUFBgbK3j7789f3bcJ96tQplSpVytZhAAAAAADuMydPnlTJkiWzrXffJtweHh6Sbr4Rnp6eNo4GAAAAAFDQJScnq1SpUma+mZ37NuFOH0bu6elJwg0AAAAAyDM5vWyZm6YBAAAAAGAFJNwAAAAAAFgBCTcAAAAAAFZw317DjbxTZvhqi+lj77W2USQAAAAAUHBwhhsAAAAAACsg4QYAAAAAwApIuAEAAAAAsAISbgAAAAAArICEGwAAAAAAKyDhBgAAAADACki4AQAAAACwAhJuAAAAAACsgIQbAAAAAAArIOEGAAAAAMAKSLgBAAAAALCCXCfcW7Zs0RNPPKHAwEDZ2dnp66+/tpjfrVs32dnZWbxatGhhUef8+fPq2rWrPD095e3trR49eujSpUsWdfbu3auGDRvKxcVFpUqV0sSJE3O/dwAAAAAA2EiuE+7Lly+rZs2amjFjRpZ1WrRoodOnT5uvxYsXW8zv2rWr9u/fr5iYGK1atUpbtmxRr169zPnJyclq3ry5goKCtGvXLk2aNEmjR4/W3LlzcxsuAAAAAAA24ZjbBVq2bKmWLVvesY6zs7MCAgIynff7779r7dq12rlzp2rXri1Jmj59ulq1aqUPPvhAgYGBioqK0rVr1/T555/LyclJVatW1Z49e/TRRx9ZJOa3SklJUUpKijmdnJyc210DAAAAACDPWOUa7k2bNsnPz0+VKlVSnz59lJCQYM6LjY2Vt7e3mWxLUnh4uOzt7bV9+3azTqNGjeTk5GTWiYiI0MGDB3XhwoVMtzlhwgR5eXmZr1KlSllj1wAAAAAAyJE8T7hbtGihBQsWaP369Xr//fe1efNmtWzZUqmpqZKkuLg4+fn5WSzj6OgoHx8fxcXFmXX8/f0t6qRPp9e53YgRI5SUlGS+Tp48mde7hnyszPDV5gsAAAAA8oNcDynPTufOnc2/q1evrho1aig4OFibNm1Ss2bN8npzJmdnZzk7O1tt/QAAAAAA5IbVHwtWrlw5FStWTIcPH5YkBQQE6MyZMxZ1bty4ofPnz5vXfQcEBCg+Pt6iTvp0VteGAwAAAACQn1g94f7rr7+UkJCg4sWLS5LCwsKUmJioXbt2mXU2bNigtLQ0hYaGmnW2bNmi69evm3ViYmJUqVIlFSlSxNohAwAAAADwr+U64b506ZL27NmjPXv2SJKOHj2qPXv26MSJE7p06ZKGDBmibdu26dixY1q/fr2eeuoplS9fXhEREZKkhx56SC1atFDPnj21Y8cObd26Vf3791fnzp0VGBgoSXr22Wfl5OSkHj16aP/+/VqyZImmTp2qwYMH592eAwAAAABgRblOuH/++Wc9/PDDevjhhyVJgwcP1sMPP6yRI0fKwcFBe/fu1ZNPPqmKFSuqR48eCgkJ0Y8//mhxfXVUVJQqV66sZs2aqVWrVnr00UctnrHt5eWldevW6ejRowoJCdFrr72mkSNHZvlIMAAAAAAA8ptc3zStSZMmMgwjy/nff/99tuvw8fHRokWL7linRo0a+vHHH3MbHgAAAAAA+YLVr+EGAAAAAOBBRMINAAAAAIAVkHADAAAAAGAFJNwAAAAAAFgBCTcAAAAAAFZAwg0AAAAAgBWQcAMAAAAAYAUk3AAAAAAAWAEJNwAAAAAAVkDCDQAAAACAFZBwAwAAAABgBSTcAAAAAABYAQk3AAAAAABWQMINAAAAAIAVkHADAAAAAGAFJNwAAAAAAFgBCTcAAAAAAFZAwg0AAAAAgBWQcAMAAAAAYAUk3AAAAAAAWEGuE+4tW7boiSeeUGBgoOzs7PT1119bzDcMQyNHjlTx4sXl6uqq8PBwHTp0yKLO+fPn1bVrV3l6esrb21s9evTQpUuXLOrs3btXDRs2lIuLi0qVKqWJEyfmfu8AAAAAALCRXCfcly9fVs2aNTVjxoxM50+cOFHTpk3T7NmztX37drm5uSkiIkJXr14163Tt2lX79+9XTEyMVq1apS1btqhXr17m/OTkZDVv3lxBQUHatWuXJk2apNGjR2vu3Ll3sYsAAAAAANx7jrldoGXLlmrZsmWm8wzD0JQpU/TWW2/pqaeekiQtWLBA/v7++vrrr9W5c2f9/vvvWrt2rXbu3KnatWtLkqZPn65WrVrpgw8+UGBgoKKionTt2jV9/vnncnJyUtWqVbVnzx599NFHFok5AAAAAAD5VZ5ew3306FHFxcUpPDzcLPPy8lJoaKhiY2MlSbGxsfL29jaTbUkKDw+Xvb29tm/fbtZp1KiRnJyczDoRERE6ePCgLly4kOm2U1JSlJycbPECAAAAAMBW8jThjouLkyT5+/tblPv7+5vz4uLi5OfnZzHf0dFRPj4+FnUyW8et27jdhAkT5OXlZb5KlSr173cIAAAAAIC7dN/cpXzEiBFKSkoyXydPnrR1SAAAAACAB1ieJtwBAQGSpPj4eIvy+Ph4c15AQIDOnDljMf/GjRs6f/68RZ3M1nHrNm7n7OwsT09PixcAAAAAALaSpwl32bJlFRAQoPXr15tlycnJ2r59u8LCwiRJYWFhSkxM1K5du8w6GzZsUFpamkJDQ806W7Zs0fXr1806MTExqlSpkooUKZKXIQMAAAAAYBW5TrgvXbqkPXv2aM+ePZJu3ihtz549OnHihOzs7DRw4EC98847+uabb7Rv3z698MILCgwMVNu2bSVJDz30kFq0aKGePXtqx44d2rp1q/r376/OnTsrMDBQkvTss8/KyclJPXr00P79+7VkyRJNnTpVgwcPzrMdBwAAAADAmnL9WLCff/5ZTZs2NafTk+DIyEjNnz9fQ4cO1eXLl9WrVy8lJibq0Ucf1dq1a+Xi4mIuExUVpf79+6tZs2ayt7dX+/btNW3aNHO+l5eX1q1bp379+ikkJETFihXTyJEjeSQYAAAAAKDAsDMMw7B1ENaQnJwsLy8vJSUlcT33v1Rm+GqL6WPvtbZRJFm7Ncb8GB8AAACAgi+3eeZ9c5dyAAAAAADyExJuAAAAAACsgIQbAAAAAAAryPVN05D3uP4YAAAAAO4/nOEGAAAAAMAKSLgBAAAAALACEm4AAAAAAKyAhBsAAAAAACsg4QYAAAAAwApIuAEAAAAAsAISbgAAAAAArICEGwAAAAAAKyDhBgAAAADACki4AQAAAACwAhJuAAAAAACsgIQbAAAAAAArIOEGAAAAAMAKSLgBAAAAALACEm4AAAAAAKyAhBsAAAAAACvI84R79OjRsrOzs3hVrlzZnH/16lX169dPRYsWlbu7u9q3b6/4+HiLdZw4cUKtW7dW4cKF5efnpyFDhujGjRt5HSoAAAAAAFbjaI2VVq1aVT/88MP/bcTx/zYzaNAgrV69WtHR0fLy8lL//v3Vrl07bd26VZKUmpqq1q1bKyAgQD/99JNOnz6tF154QYUKFdL48eOtES4AAAAAAHnOKgm3o6OjAgICMpQnJSXps88+06JFi/TYY49JkubNm6eHHnpI27ZtU7169bRu3Tr99ttv+uGHH+Tv769atWpp3LhxGjZsmEaPHi0nJydrhAwAAAAAQJ6yyjXchw4dUmBgoMqVK6euXbvqxIkTkqRdu3bp+vXrCg8PN+tWrlxZpUuXVmxsrCQpNjZW1atXl7+/v1knIiJCycnJ2r9/f5bbTElJUXJyssULAAAAAABbyfOEOzQ0VPPnz9fatWs1a9YsHT16VA0bNtTFixcVFxcnJycneXt7Wyzj7++vuLg4SVJcXJxFsp0+P31eViZMmCAvLy/zVapUqbzdMQAAAAAAciHPh5S3bNnS/LtGjRoKDQ1VUFCQli5dKldX17zenGnEiBEaPHiwOZ2cnEzSDQAAAACwGas/Fszb21sVK1bU4cOHFRAQoGvXrikxMdGiTnx8vHnNd0BAQIa7lqdPZ3ZdeDpnZ2d5enpavAAAAAAAsBWrJ9yXLl3SkSNHVLx4cYWEhKhQoUJav369Of/gwYM6ceKEwsLCJElhYWHat2+fzpw5Y9aJiYmRp6enqlSpYu1wAQAAAADIE3k+pPz111/XE088oaCgIJ06dUqjRo2Sg4ODunTpIi8vL/Xo0UODBw+Wj4+PPD09NWDAAIWFhalevXqSpObNm6tKlSp6/vnnNXHiRMXFxemtt95Sv3795OzsnNfhAiigygxfbTF97L3WNooEAAAAyFyeJ9x//fWXunTpooSEBPn6+urRRx/Vtm3b5OvrK0maPHmy7O3t1b59e6WkpCgiIkIzZ840l3dwcNCqVavUp08fhYWFyc3NTZGRkRo7dmxehwoAAAAAgNXkecL91Vdf3XG+i4uLZsyYoRkzZmRZJygoSN99911ehwYAAAAAwD1j9Wu4AQAAAAB4EJFwAwAAAABgBSTcAAAAAABYAQk3AAAAAABWQMINAAAAAIAV5PldygEAuJdufSY7z2MHAAD5CQl3AXXrP5gS/2QCAAAAQH7DkHIAAAAAAKyAM9wACgSGDQMAAKCg4Qw3AAAAAABWQMINAAAAAIAVMKT8AVMQh+UWxJgBKWef3fz++eYGjQAAAHePM9wAAAAAAFgBZ7gLiPx+FgwACjLO5AMAAGsg4cZd4QcAALZAYgwAAAoShpQDAAAAAGAFnOEGbvGgnrnnrOH9hza9/zyoxycAAAoyEu4HHP+U31levT85WQ9tAQAAANxfSLjvI7ef/chvCVx+iwcAAAAArImEOx8qiIlpQYwZyEpOfrxieO+/x3sIAADudyTcuC/dyx8A8tuPDXczfN2acpJU5VXiRQKHrPDZAPIGfQkAcidfJ9wzZszQpEmTFBcXp5o1a2r69OmqW7eurcOCjd3L66qzW+5BSuRzgmvV78zWn928wj/cAAAAOZNvE+4lS5Zo8ODBmj17tkJDQzVlyhRFRETo4MGD8vPzs3V4yIEH+Z/y7Pb9fkm87ge0hSVr9dv8/gNXXsmL/czNcvlJfhtZdD+8pwCAgi/fJtwfffSRevbsqe7du0uSZs+erdWrV+vzzz/X8OHDM9RPSUlRSkqKOZ2UlCRJSk5OvjcB/wtpKVfMv5OTky2mMyuzdp1qo743p38dE2HVbeWEtbZly/f5djmtc2vb5HQ9pQdFW0xn1qbZbevXMREZtn17WV5+VjLb1t2sJyds3d9ysu85iTknbZGTNs2r9/luPhuZyat4sqtzt8envFpPbvttTtebk357t3LSxnnlbraVkz6QV/Hklbttr5z07byK524+h7j/WKsPAAVB+rHPMIwc1bczclrzHrp27ZoKFy6sZcuWqW3btmZ5ZGSkEhMTtXLlygzLjB49WmPGjLmHUQIAAAAAHkQnT55UyZIls62XL89wnzt3TqmpqfL397co9/f314EDBzJdZsSIERo8eLA5nZaWpvPnz6to0aKys7Ozarx5ITk5WaVKldLJkyfl6elp63CQS7RfwUb7FWy0X8FHGxZstF/BRvsVbLTfvWcYhi5evKjAwMAc1c+XCffdcHZ2lrOzs0WZt7e3bYL5Fzw9PeksBRjtV7DRfgUb7Vfw0YYFG+1XsNF+BRvtd295eXnluK69FeO4a8WKFZODg4Pi4+MtyuPj4xUQEGCjqAAAAAAAyLl8mXA7OTkpJCRE69evN8vS0tK0fv16hYWF2TAyAAAAAAByJt8OKR88eLAiIyNVu3Zt1a1bV1OmTNHly5fNu5bfb5ydnTVq1KgMw+JRMNB+BRvtV7DRfgUfbViw0X4FG+1XsNF++V++vEt5uo8//liTJk1SXFycatWqpWnTpik0NNTWYQEAAAAAkK18nXADAAAAAFBQ5ctruAEAAAAAKOhIuAEAAAAAsAISbgAAAAAArICEGwAAAAAAKyDhzgdmzJihMmXKyMXFRaGhodqxY4etQ0ImJkyYoDp16sjDw0N+fn5q27atDh48aFGnSZMmsrOzs3i9/PLLNooYtxo9enSGtqlcubI5/+rVq+rXr5+KFi0qd3d3tW/fXvHx8TaMGLcrU6ZMhja0s7NTv379JNH/8pstW7boiSeeUGBgoOzs7PT1119bzDcMQyNHjlTx4sXl6uqq8PBwHTp0yKLO+fPn1bVrV3l6esrb21s9evTQpUuX7uFePLju1H7Xr1/XsGHDVL16dbm5uSkwMFAvvPCCTp06ZbGOzPrse++9d4/35MGUXf/r1q1bhrZp0aKFRR36n21l14aZfR/a2dlp0qRJZh36YP5Awm1jS5Ys0eDBgzVq1Cjt3r1bNWvWVEREhM6cOWPr0HCbzZs3q1+/ftq2bZtiYmJ0/fp1NW/eXJcvX7ao17NnT50+fdp8TZw40UYR43ZVq1a1aJv//ve/5rxBgwbp22+/VXR0tDZv3qxTp06pXbt2NowWt9u5c6dF+8XExEiSnnnmGbMO/S//uHz5smrWrKkZM2ZkOn/ixImaNm2aZs+ere3bt8vNzU0RERG6evWqWadr167av3+/YmJitGrVKm3ZskW9evW6V7vwQLtT+125ckW7d+/W22+/rd27d2v58uU6ePCgnnzyyQx1x44da9EnBwwYcC/Cf+Bl1/8kqUWLFhZts3jxYov59D/byq4Nb22706dP6/PPP5ednZ3at29vUY8+mA8YsKm6desa/fr1M6dTU1ONwMBAY8KECTaMCjlx5swZQ5KxefNms6xx48bGq6++arugkKVRo0YZNWvWzHReYmKiUahQISM6Otos+/333w1JRmxs7D2KELn16quvGsHBwUZaWpphGPS//EySsWLFCnM6LS3NCAgIMCZNmmSWJSYmGs7OzsbixYsNwzCM3377zZBk7Ny506yzZs0aw87Ozvj777/vWezI2H6Z2bFjhyHJOH78uFkWFBRkTJ482brBIVuZtV9kZKTx1FNPZbkM/S9/yUkffOqpp4zHHnvMoow+mD9whtuGrl27pl27dik8PNwss7e3V3h4uGJjY20YGXIiKSlJkuTj42NRHhUVpWLFiqlatWoaMWKErly5YovwkIlDhw4pMDBQ5cqVU9euXXXixAlJ0q5du3T9+nWLvli5cmWVLl2avphPXbt2TQsXLtSLL74oOzs7s5z+VzAcPXpUcXFxFn3Oy8tLoaGhZp+LjY2Vt7e3ateubdYJDw+Xvb29tm/ffs9jxp0lJSXJzs5O3t7eFuXvvfeeihYtqocffliTJk3SjRs3bBMgMti0aZP8/PxUqVIl9enTRwkJCeY8+l/BEh8fr9WrV6tHjx4Z5tEHbc/R1gE8yM6dO6fU1FT5+/tblPv7++vAgQM2igo5kZaWpoEDB6pBgwaqVq2aWf7ss88qKChIgYGB2rt3r4YNG6aDBw9q+fLlNowWkhQaGqr58+erUqVKOn36tMaMGaOGDRvq119/VVxcnJycnDL8o+jv76+4uDjbBIw7+vrrr5WYmKhu3bqZZfS/giO9X2X2/Zc+Ly4uTn5+fhbzHR0d5ePjQ7/MZ65evaphw4apS5cu8vT0NMtfeeUVPfLII/Lx8dFPP/2kESNG6PTp0/roo49sGC2km8PJ27Vrp7Jly+rIkSN644031LJlS8XGxsrBwYH+V8B88cUX8vDwyHApHH0wfyDhBu5Cv3799Ouvv1pcAyzJ4tqm6tWrq3jx4mrWrJmOHDmi4ODgex0mbtGyZUvz7xo1aig0NFRBQUFaunSpXF1dbRgZ7sZnn32mli1bKjAw0Cyj/wH33vXr19WxY0cZhqFZs2ZZzBs8eLD5d40aNeTk5KTevXtrwoQJcnZ2vteh4hadO3c2/65evbpq1Kih4OBgbdq0Sc2aNbNhZLgbn3/+ubp27SoXFxeLcvpg/sCQchsqVqyYHBwcMtwJOT4+XgEBATaKCtnp37+/Vq1apY0bN6pkyZJ3rBsaGipJOnz48L0IDbng7e2tihUr6vDhwwoICNC1a9eUmJhoUYe+mD8dP35cP/zwg1566aU71qP/5V/p/epO338BAQEZbiB648YNnT9/nn6ZT6Qn28ePH1dMTIzF2e3MhIaG6saNGzp27Ni9CRA5Vq5cORUrVsw8XtL/Co4ff/xRBw8ezPY7UaIP2goJtw05OTkpJCRE69evN8vS0tK0fv16hYWF2TAyZMYwDPXv318rVqzQhg0bVLZs2WyX2bNnjySpePHiVo4OuXXp0iUdOXJExYsXV0hIiAoVKmTRFw8ePKgTJ07QF/OhefPmyc/PT61bt75jPfpf/lW2bFkFBARY9Lnk5GRt377d7HNhYWFKTEzUrl27zDobNmxQWlqa+WMKbCc92T506JB++OEHFS1aNNtl9uzZI3t7+wxDlWF7f/31lxISEszjJf2v4Pjss88UEhKimjVrZluXPmgbDCm3scGDBysyMlK1a9dW3bp1NWXKFF2+fFndu3e3dWi4Tb9+/bRo0SKtXLlSHh4e5jVMXl5ecnV11ZEjR7Ro0SK1atVKRYsW1d69ezVo0CA1atRINWrUsHH0eP311/XEE08oKChIp06d0qhRo+Tg4KAuXbrIy8tLPXr00ODBg+Xj4yNPT08NGDBAYWFhqlevnq1Dxy3S0tI0b948RUZGytHx/77C6H/5z6VLlyxGFxw9elR79uyRj4+PSpcurYEDB+qdd95RhQoVVLZsWb399tsKDAxU27ZtJUkPPfSQWrRooZ49e2r27Nm6fv26+vfvr86dO1tcSgDruFP7FS9eXB06dNDu3bu1atUqpaammt+JPj4+cnJyUmxsrLZv366mTZvKw8NDsbGxGjRokJ577jkVKVLEVrv1wLhT+/n4+GjMmDFq3769AgICdOTIEQ0dOlTly5dXRESEJPpffpDdMVS6+UNldHS0PvzwwwzL0wfzEVvfJh2GMX36dKN06dKGk5OTUbduXWPbtm22DgmZkJTpa968eYZhGMaJEyeMRo0aGT4+Poazs7NRvnx5Y8iQIUZSUpJtA4dhGIbRqVMno3jx4oaTk5NRokQJo1OnTsbhw4fN+f/884/Rt29fo0iRIkbhwoWNp59+2jh9+rQNI0Zmvv/+e0OScfDgQYty+l/+s3HjxkyPmZGRkYZh3Hw02Ntvv234+/sbzs7ORrNmzTK0a0JCgtGlSxfD3d3d8PT0NLp3725cvHjRBnvz4LlT+x09ejTL78SNGzcahmEYu3btMkJDQw0vLy/DxcXFeOihh4zx48cbV69ete2OPSDu1H5Xrlwxmjdvbvj6+hqFChUygoKCjJ49expxcXEW66D/2VZ2x1DDMIw5c+YYrq6uRmJiYobl6YP5h51hGIbVs3oAAAAAAB4wXMMNAAAAAIAVkHADAAAAAGAFJNwAAAAAAFgBCTcAAAAAAFZAwg0AAAAAgBWQcAMAAAAAYAUk3AAAAAAAWAEJNwAAAAAAVkDCDQAAAACAFZBwAwAAAABgBSTcAAAAAABYAQk3AAAAAABWQMINAAAAAIAVkHADAAAAAGAFJNwAAAAAAFgBCTcAAAAAAFZAwg0AAAAAgBWQcAMAkIkvv/xSlStXVqFCheTt7W3rcPLMsWPHZGdnpw8++CDP1jl//nzZ2dnp2LFjebbOu2VnZ6fRo0fbOgwAACSRcAMAHkAzZ86UnZ2dQkNDM51/4MABdevWTcHBwfrkk080d+5cXblyRaNHj9amTZvuWZzpyXH6y97eXj4+PmrZsqViY2PvWRwAAODuONo6AAAA7rWoqCiVKVNGO3bs0OHDh1W+fHmL+Zs2bVJaWpqmTp1qzjt37pzGjBkjSWrSpMk9jbdLly5q1aqVUlNT9ccff2jmzJlq2rSpdu7cqerVq9/TWPK7f/75R46O/HsDAMgfOMMNAHigHD16VD/99JM++ugj+fr6KioqKkOdM2fOSNI9GUp++fLlbOs88sgjeu655xQZGal3331XixcvVkpKimbNmmX1+AoaFxcXEm4AQL5Bwg0AeKBERUWpSJEiat26tTp06JAh4S5TpoxGjRolSfL19ZWdnZ26desmX19fSdKYMWPMId63Xit84MABdejQQT4+PnJxcVHt2rX1zTffWKw7/VrnzZs3q2/fvvLz81PJkiVzvQ8NGzaUJB05csSiPDExUQMHDlSpUqXk7Oys8uXL6/3331daWlqm65k8ebKCgoLk6uqqxo0b69dff7WYv3fvXnXr1k3lypWTi4uLAgIC9OKLLyohISHbGFeuXKnWrVsrMDBQzs7OCg4O1rhx45SammpRr0mTJqpWrZp+++03NW3aVIULF1aJEiU0ceLEDOu8evWqRo8erYoVK8rFxUXFixdXu3btLN6H29tl9OjRsrOz0+HDh9WtWzd5e3vLy8tL3bt315UrVyzW/88//+iVV15RsWLF5OHhoSeffFJ///0314UDAO4aPwEDAB4oUVFRateunZycnNSlSxfNmjVLO3fuVJ06dSRJU6ZM0YIFC7RixQrNmjVL7u7uql69uurVq6c+ffro6aefVrt27SRJNWrUkCTt379fDRo0UIkSJTR8+HC5ublp6dKlatu2rf7zn//o6aeftoihb9++8vX11ciRI3N0hvt26TcnK1KkiFl25coVNW7cWH///bd69+6t0qVL66efftKIESN0+vRpTZkyxWIdCxYs0MWLF9WvXz9dvXpVU6dO1WOPPaZ9+/bJ399fkhQTE6M///xT3bt3V0BAgPbv36+5c+dq//792rZtm+zs7LKMcf78+XJ3d9fgwYPl7u6uDRs2aOTIkUpOTtakSZMs6l64cEEtWrRQu3bt1LFjRy1btkzDhg1T9erV1bJlS0lSamqq2rRpo/Xr16tz58569dVXdfHiRcXExOjXX39VcHDwHd+zjh07qmzZspowYYJ2796tTz/9VH5+fnr//ffNOt26ddPSpUv1/PPPq169etq8ebNat26dbXsAAJAlAwCAB8TPP/9sSDJiYmIMwzCMtLQ0o2TJksarr75qUW/UqFGGJOPs2bNm2dmzZw1JxqhRozKst1mzZkb16tWNq1evmmVpaWlG/fr1jQoVKphl8+bNMyQZjz76qHHjxo1s4z169KghyRgzZoxx9uxZIy4uzvjxxx+NOnXqGJKM6Ohos+64ceMMNzc3448//rBYx/Dhww0HBwfjxIkTFut0dXU1/vrrL7Pe9u3bDUnGoEGDzLIrV65kiGnx4sWGJGPLli0Z9uvo0aN3XLZ3795G4cKFLd6nxo0bG5KMBQsWmGUpKSlGQECA0b59e7Ps888/NyQZH330UYb1pqWlmX/f3kbpbfniiy9aLPP0008bRYsWNad37dplSDIGDhxoUa9bt25ZtjsAANlhSDkA4IERFRUlf39/NW3aVNLN4cedOnXSV199lWGoc06dP39eGzZsUMeOHXXx4kWdO3dO586dU0JCgiIiInTo0CH9/fffFsv07NlTDg4OOd7GqFGj5Ovrq4CAADVs2FC///67PvzwQ3Xo0MGsEx0drYYNG6pIkSJmDOfOnVN4eLhSU1O1ZcsWi3W2bdtWJUqUMKfr1q2r0NBQfffdd2aZq6ur+ffVq1d17tw51atXT5K0e/fuO8Z867Lp70vDhg115coVHThwwKKuu7u7nnvuOXPayclJdevW1Z9//mmW/ec//1GxYsU0YMCADNu605n2dC+//LLFdMOGDZWQkKDk5GRJ0tq1ayXdHH1wq8y2BwBATjGkHADwQEhNTdVXX32lpk2b6ujRo2Z5aGioPvzwQ61fv17NmzfP9XoPHz4swzD09ttv6+233860zpkzZyyS27Jly+ZqG7169dIzzzyjq1evasOGDZo2bVqGHwgOHTqkvXv3mteaZxbDrSpUqJChTsWKFbV06VJz+vz58xozZoy++uqrDMsnJSXdMeb9+/frrbfe0oYNG8ykNqtlS5YsmSFpLlKkiPbu3WtOHzlyRJUqVbrrG6KVLl06w/qlm8PZPT09dfz4cdnb22dom9vvYA8AQG6QcAMAHggbNmzQ6dOn9dVXX+mrr77KMD8qKuquEu70G5K9/vrrioiIyLTO7UnbrWd/c6JChQoKDw+XJLVp00YODg4aPny4mjZtqtq1a5txPP744xo6dGim66hYsWKutindvO75p59+0pAhQ1SrVi25u7srLS1NLVq0yPJGbNLNm7c1btxYnp6eGjt2rIKDg+Xi4qLdu3dr2LBhGZbN6my/YRi5jjkr92IbAADcjoQbAPBAiIqKkp+fn2bMmJFh3vLly7VixQrNnj07y2Q4q2HL5cqVkyQVKlTITIqt7c0339Qnn3yit956yxwKHRwcrEuXLuU4hkOHDmUo++OPP1SmTBlJN8/8rl+/XmPGjNHIkSPvuNztNm3apISEBC1fvlyNGjUyy28dWZBbwcHB2r59u65fv65ChQrd9XqyEhQUpLS0NB09etTi7P/hw4fzfFsAgAcH13ADAO57//zzj5YvX642bdqoQ4cOGV79+/fXxYsXMzzG61aFCxeWdPPs7a38/PzUpEkTzZkzR6dPn86w3NmzZ/N0X6Sbzwfv3bu3vv/+e+3Zs0fSzbPRsbGx+v777zPUT0xM1I0bNyzKvv76a4try3fs2KHt27ebdwVPPyN8+xng2+92npnMlr127ZpmzpyZ/c5loX379jp37pw+/vjjDPPy4ix1+uiE22OcPn36v143AODBxRluAMB975tvvtHFixf15JNPZjq/Xr168vX1VVRUlDp16pRpHVdXV1WpUkVLlixRxYoV5ePjo2rVqqlatWqaMWOGHn30UVWvXl09e/ZUuXLlFB8fr9jYWP3111/63//+l+f79Oqrr2rKlCl677339NVXX2nIkCH65ptv1KZNG3Xr1k0hISG6fPmy9u3bp2XLlunYsWMqVqyYuXz58uX16KOPqk+fPkpJSdGUKVNUtGhRc0i6p6enGjVqpIkTJ+r69esqUaKE1q1bl6Oz1PXr11eRIkUUGRmpV155RXZ2dvryyy//VWL8wgsvaMGCBRo8eLB27Nihhg0b6vLly/rhhx/Ut29fPfXUU3e9bkkKCQlR+/btNWXKFCUkJJiPBfvjjz8k5ezGbAAA3I6EGwBw34uKipKLi4sef/zxTOfb29urdevWioqKUkJCQpbr+fTTTzVgwAANGjRI165d06hRo1StWjVVqVJFP//8s8aMGaP58+crISFBfn5+evjhhy2GY+elwMBAPfvss/ryyy915MgRBQcHa/PmzRo/fryio6O1YMECeXp6qmLFihozZoy8vLwsln/hhRdkb2+vKVOm6MyZM6pbt64+/vhjFS9e3KyzaNEiDRgwQDNmzJBhGGrevLnWrFmjwMDAO8ZWtGhRrVq1Sq+99preeustFSlSRM8995yaNWuW5XXu2XFwcNB3332nd999V4sWLdJ//vMfFS1a1PyhIy8sWLBAAQEBWrx4sVasWKHw8HAtWbJElSpVkouLS55sAwDwYLEzuFsIAABApvbs2aOHH35YCxcuVNeuXW0dDgCggOEabgAAAN281v92U6ZMkb29vcXN3wAAyCmGlAMAAEiaOHGidu3apaZNm8rR0VFr1qzRmjVr1KtXL5UqVcrW4QEACiCGlAMAAEiKiYnRmDFj9Ntvv+nSpUsqXbq0nn/+eb355ptydOQcBQAg90i4AQAAAACwAq7hBgAAAADACu7b8VFpaWk6deqUPDw8eHYmAAAAAOBfMwxDFy9eVGBgoOztsz9/fd8m3KdOneIGJwAAAACAPHfy5EmVLFky23r3bcLt4eEh6eYb4enpaeNoAAAAAAAFXXJyskqVKmXmm9m5bxPu9GHknp6eJNwAAAAAgDyT08uWuWkaAAAAAABWQMINAAAAAIAVkHADAAAAAGAF9+013AAAAABwL5QZvjpP1nPsvdZ5sh7kH1ZJuP/++28NGzZMa9as0ZUrV1S+fHnNmzdPtWvXlnTz2WWjRo3SJ598osTERDVo0ECzZs1ShQoVzHWcP39eAwYM0Lfffit7e3u1b99eU6dOlbu7uzVCBgAAAIAHQl78QMCPAzmT5wn3hQsX1KBBAzVt2lRr1qyRr6+vDh06pCJFiph1Jk6cqGnTpumLL75Q2bJl9fbbbysiIkK//fabXFxcJEldu3bV6dOnFRMTo+vXr6t79+7q1auXFi1alNchAwAAALhLnN0FspbnCff777+vUqVKad68eWZZ2bJlzb8Nw9CUKVP01ltv6amnnpIkLViwQP7+/vr666/VuXNn/f7771q7dq127txpnhWfPn26WrVqpQ8++ECBgYF5HTYAAAAAAHkqz2+a9s0336h27dp65pln5Ofnp4cffliffPKJOf/o0aOKi4tTeHi4Webl5aXQ0FDFxsZKkmJjY+Xt7W0m25IUHh4ue3t7bd++PdPtpqSkKDk52eIFAAAAAICt5HnC/eeff5rXY3///ffq06ePXnnlFX3xxReSpLi4OEmSv7+/xXL+/v7mvLi4OPn5+VnMd3R0lI+Pj1nndhMmTJCXl5f5KlWqVF7vGgAAAAAAOZbnQ8rT0tJUu3ZtjR8/XpL08MMP69dff9Xs2bMVGRmZ15szjRgxQoMHDzank5OTSboBAACAAoobe+F+kOdnuIsXL64qVapYlD300EM6ceKEJCkgIECSFB8fb1EnPj7enBcQEKAzZ85YzL9x44bOnz9v1rmds7OzPD09LV4AAAAAANhKnifcDRo00MGDBy3K/vjjDwUFBUm6eQO1gIAArV+/3pyfnJys7du3KywsTJIUFhamxMRE7dq1y6yzYcMGpaWlKTQ0NK9DBgAAAAAgz+X5kPJBgwapfv36Gj9+vDp27KgdO3Zo7ty5mjt3riTJzs5OAwcO1DvvvKMKFSqYjwULDAxU27ZtJd08I96iRQv17NlTs2fP1vXr19W/f3917tyZO5QDAAAAAAqEPE+469SpoxUrVmjEiBEaO3asypYtqylTpqhr165mnaFDh+ry5cvq1auXEhMT9eijj2rt2rXmM7glKSoqSv3791ezZs1kb2+v9u3ba9q0aXkdLgAAAAAAVpHnCbcktWnTRm3atMlyvp2dncaOHauxY8dmWcfHx0eLFi2yRngAAAAAAFhdnl/DDQAAAAAASLgBAAAAALAKqwwpBwAAQP7CM40B4N7jDDcAAAAAAFZAwg0AAAAAgBUwpBwAgLuQF8NzJYboAgBwP+MMNwAAAAAAVsAZbty3OPsEAAAAwJZIuAEAuM/xAyQAALZBwg0AAAAA+Fd49GDmSLgB5AucgQMAAMD9hpumAQAAAABgBSTcAAAAAABYAQk3AAAAAABWQMINAAAAAIAVcNM0AAAAAA8M7qaNe4kz3AAAAAAAWAEJNwAAAAAAVsCQcgAAcN/LiyGkEsNIAQC5wxluAAAAAACsgIQbAAAAAAArIOEGAAAAAMAKuIb7PsW1agAAAABgW5zhBgAAAADACqx+hvu9997TiBEj9Oqrr2rKlCmSpKtXr+q1117TV199pZSUFEVERGjmzJny9/c3lztx4oT69OmjjRs3yt3dXZGRkZowYYIcHTkpDwDA/SwvRmkxQgsAkB9YNXvduXOn5syZoxo1aliUDxo0SKtXr1Z0dLS8vLzUv39/tWvXTlu3bpUkpaamqnXr1goICNBPP/2k06dP64UXXlChQoU0fvx4a4YMAAAAAPkCP0AWfFYbUn7p0iV17dpVn3zyiYoUKWKWJyUl6bPPPtNHH32kxx57TCEhIZo3b55++uknbdu2TZK0bt06/fbbb1q4cKFq1aqlli1baty4cZoxY4auXbtmrZABAAAAAMgzVjvD3a9fP7Vu3Vrh4eF65513zPJdu3bp+vXrCg8PN8sqV66s0qVLKzY2VvXq1VNsbKyqV69uMcQ8IiJCffr00f79+/Xwww9n2F5KSopSUlLM6eTkZCvtGZD3uMkdAAAAcP+xSsL91Vdfaffu3dq5c2eGeXFxcXJycpK3t7dFub+/v+Li4sw6tybb6fPT52VmwoQJGjNmTB5EDwAAAADAv5fnQ8pPnjypV199VVFRUXJxccnr1WdpxIgRSkpKMl8nT568Z9sGAAAAAOB2eZ5w79q1S2fOnNEjjzwiR0dHOTo6avPmzZo2bZocHR3l7++va9euKTEx0WK5+Ph4BQQESJICAgIUHx+fYX76vMw4OzvL09PT4gUAAAAAgK3kecLdrFkz7du3T3v27DFftWvXVteuXc2/CxUqpPXr15vLHDx4UCdOnFBYWJgkKSwsTPv27dOZM2fMOjExMfL09FSVKlXyOmQAAAAAAPJcnl/D7eHhoWrVqlmUubm5qWjRomZ5jx49NHjwYPn4+MjT01MDBgxQWFiY6tWrJ0lq3ry5qlSpoueff14TJ05UXFyc3nrrLfXr10/Ozs55HTIAAAAAAHnOqs/hzsrkyZNlb2+v9u3bKyUlRREREZo5c6Y538HBQatWrVKfPn0UFhYmNzc3RUZGauzYsbYIFwAAAACAXLsnCfemTZsspl1cXDRjxgzNmDEjy2WCgoL03XffWTkyAAAAAACsI8+v4QYAAAAAACTcAAAAAABYBQk3AAAAAABWYJObpgEAAOD+UGb46n+9jmPvtc6DSAAg/+EMNwAAAAAAVsAZbgD3Nc68AAAAwFY4ww0AAAAAgBWQcAMAAAAAYAUMKQeAu8BQdQAAAGSHhBsAgHyEH3MAALh/MKQcAAAAAAAr4Aw3ACDX8uIsrMSZWBR8jEgAANwJZ7gBAAAAALACznADAAAA/wIjHQBkhTPcAAAAAABYAQk3AAAAAABWwJByIJcYNgYAAAAgJzjDDQAAAACAFZBwAwAAAABgBSTcAAAAAABYAddwI1/gumgAKHg4dgMAcGec4QYAAAAAwApIuAEAAAAAsAKGlCNXGD4IAAAAADmT5wn3hAkTtHz5ch04cECurq6qX7++3n//fVWqVMmsc/XqVb322mv66quvlJKSooiICM2cOVP+/v5mnRMnTqhPnz7auHGj3N3dFRkZqQkTJsjRkd8IAOB+xY96AADgfpLn2evmzZvVr18/1alTRzdu3NAbb7yh5s2b67fffpObm5skadCgQVq9erWio6Pl5eWl/v37q127dtq6daskKTU1Va1bt1ZAQIB++uknnT59Wi+88IIKFSqk8ePH53XIAAAAyEfy4sc3iR/gANhenifca9eutZieP3++/Pz8tGvXLjVq1EhJSUn67LPPtGjRIj322GOSpHnz5umhhx7Stm3bVK9ePa1bt06//fabfvjhB/n7+6tWrVoaN26chg0bptGjR8vJySnDdlNSUpSSkmJOJycn5/WuAQWOtc4WchYSAAAAyJ7Vb5qWlJQkSfLx8ZEk7dq1S9evX1d4eLhZp3LlyipdurRiY2MlSbGxsapevbrFEPOIiAglJydr//79mW5nwoQJ8vLyMl+lSpWy1i4BAAAAAJAtq14QnZaWpoEDB6pBgwaqVq2aJCkuLk5OTk7y9va2qOvv76+4uDizzq3Jdvr89HmZGTFihAYPHmxOJycnF5ikm7OFAKyJYwwAAIBtWDXh7tevn3799Vf997//teZmJEnOzs5ydna2+nYAAAAAa+M6duD+YLWEu3///lq1apW2bNmikiVLmuUBAQG6du2aEhMTLc5yx8fHKyAgwKyzY8cOi/XFx8eb8wAAyA3O8qOg4TNrHbyvAO61PL+G2zAM9e/fXytWrNCGDRtUtmxZi/khISEqVKiQ1q9fb5YdPHhQJ06cUFhYmCQpLCxM+/bt05kzZ8w6MTEx8vT0VJUqVfI6ZAAAAAAA8lyen+Hu16+fFi1apJUrV8rDw8O85trLy0uurq7y8vJSjx49NHjwYPn4+MjT01MDBgxQWFiY6tWrJ0lq3ry5qlSpoueff14TJ05UXFyc3nrrLfXr149h4wDuW5x5AQAAuL/kecI9a9YsSVKTJk0syufNm6du3bpJkiZPnix7e3u1b99eKSkpioiI0MyZM826Dg4OWrVqlfr06aOwsDC5ubkpMjJSY8eOzetwAQAAAACwijxPuA3DyLaOi4uLZsyYoRkzZmRZJygoSN99911ehgYAAAA80BhNBdxbVn8ONwAAAAAADyISbgAAAAAArICEGwAAAAAAKyDhBgAAAADACki4AQAAAACwAhJuAAAAAACsgIQbAAAAAAArIOEGAAAAAMAKSLgBAAAAALACEm4AAAAAAKyAhBsAAAAAACsg4QYAAAAAwApIuAEAAAAAsAISbgAAAAAArICEGwAAAAAAKyDhBgAAAADACki4AQAAAACwAhJuAAAAAACsgIQbAAAAAAArIOEGAAAAAMAKSLgBAAAAALACEm4AAAAAAKyAhBsAAAAAACsg4QYAAAAAwArydcI9Y8YMlSlTRi4uLgoNDdWOHTtsHRIAAAAAADmSbxPuJUuWaPDgwRo1apR2796tmjVrKiIiQmfOnLF1aAAAAAAAZMvR1gFk5aOPPlLPnj3VvXt3SdLs2bO1evVqff755xo+fHiG+ikpKUpJSTGnk5KSJEnJycn3JuB/IS3lyr9ex+37mRfrtNZ6M2uTB/09KEixWmu9vAcPXqzWWi/vQcGO1Vrr5T148GK11np5Dwp2rNZaL++B9WLNb9JjNAwjR/XtjJzWvIeuXbumwoULa9myZWrbtq1ZHhkZqcTERK1cuTLDMqNHj9aYMWPuYZQAAAAAgAfRyZMnVbJkyWzr5csz3OfOnVNqaqr8/f0tyv39/XXgwIFMlxkxYoQGDx5sTqelpen8+fMqWrSo7OzsrBqvNSUnJ6tUqVI6efKkPD09bR0OcoA2K1hor4KF9ipYaK+ChfYqWGivgoX2Klju1F6GYejixYsKDAzM0bryZcJ9N5ydneXs7GxR5u3tbZtgrMDT05POWcDQZgUL7VWw0F4FC+1VsNBeBQvtVbDQXgVLVu3l5eWV43Xky5umFStWTA4ODoqPj7coj4+PV0BAgI2iAgAAAAAg5/Jlwu3k5KSQkBCtX7/eLEtLS9P69esVFhZmw8gAAAAAAMiZfDukfPDgwYqMjFTt2rVVt25dTZkyRZcvXzbvWv6gcHZ21qhRozIMl0f+RZsVLLRXwUJ7FSy0V8FCexUstFfBQnsVLHnZXvnyLuXpPv74Y02aNElxcXGqVauWpk2bptDQUFuHBQAAAABAtvJ1wg0AAAAAQEGVL6/hBgAAAACgoCPhBgAAAADACki4AQAAAACwAhJuAAAAAACsgIQ7n5sxY4bKlCkjFxcXhYaGaseOHbYOCZkYPXq07OzsLF6VK1e2dVj4/7Zs2aInnnhCgYGBsrOz09dff20x3zAMjRw5UsWLF5erq6vCw8N16NAh2wSLbNurW7duGfpbixYtbBMsNGHCBNWpU0ceHh7y8/NT27ZtdfDgQYs6V69eVb9+/VS0aFG5u7urffv2io+Pt1HED7actFeTJk0y9LGXX37ZRhE/2GbNmqUaNWrI09NTnp6eCgsL05o1a8z59K38Jbv2om/lb++9957s7Ow0cOBAsywv+hgJdz62ZMkSDR48WKNGjdLu3btVs2ZNRURE6MyZM7YODZmoWrWqTp8+bb7++9//2jok/H+XL19WzZo1NWPGjEznT5w4UdOmTdPs2bO1fft2ubm5KSIiQlevXr3HkULKvr0kqUWLFhb9bfHixfcwQtxq8+bN6tevn7Zt26aYmBhdv35dzZs31+XLl806gwYN0rfffqvo6Ght3rxZp06dUrt27WwY9YMrJ+0lST179rToYxMnTrRRxA+2kiVL6r333tOuXbv0888/67HHHtNTTz2l/fv3S6Jv5TfZtZdE38qvdu7cqTlz5qhGjRoW5XnSxwzkW3Xr1jX69etnTqemphqBgYHGhAkTbBgVMjNq1CijZs2atg4DOSDJWLFihTmdlpZmBAQEGJMmTTLLEhMTDWdnZ2Px4sU2iBC3ur29DMMwIiMjjaeeesom8SB7Z86cMSQZmzdvNgzjZn8qVKiQER0dbdb5/fffDUlGbGysrcLE/3d7exmGYTRu3Nh49dVXbRcU7qhIkSLGp59+St8qINLbyzDoW/nVxYsXjQoVKhgxMTEWbZRXfYwz3PnUtWvXtGvXLoWHh5tl9vb2Cg8PV2xsrA0jQ1YOHTqkwMBAlStXTl27dtWJEydsHRJy4OjRo4qLi7Poa15eXgoNDaWv5WObNm2Sn5+fKlWqpD59+ighIcHWIeH/S0pKkiT5+PhIknbt2qXr169b9LHKlSurdOnS9LF84Pb2ShcVFaVixYqpWrVqGjFihK5cuWKL8HCL1NRUffXVV7p8+bLCwsLoW/nc7e2Vjr6V//Tr10+tW7e26EtS3n1/OeZZpMhT586dU2pqqvz9/S3K/f39deDAARtFhayEhoZq/vz5qlSpkk6fPq0xY8aoYcOG+vXXX+Xh4WHr8HAHcXFxkpRpX0ufh/ylRYsWateuncqWLasjR47ojTfeUMuWLRUbGysHBwdbh/dAS0tL08CBA9WgQQNVq1ZN0s0+5uTkJG9vb4u69DHby6y9JOnZZ59VUFCQAgMDtXfvXg0bNkwHDx7U8uXLbRjtg2vfvn0KCwvT1atX5e7urhUrVqhKlSras2cPfSsfyqq9JPpWfvTVV19p9+7d2rlzZ4Z5efX9RcIN5IGWLVuaf9eoUUOhoaEKCgrS0qVL1aNHDxtGBtx/OnfubP5dvXp11ahRQ8HBwdq0aZOaNWtmw8jQr18//frrr9zDooDIqr169epl/l29enUVL15czZo105EjRxQcHHyvw3zgVapUSXv27FFSUpKWLVumyMhIbd682dZhIQtZtVeVKlXoW/nMyZMn9eqrryomJkYuLi5W2w5DyvOpYsWKycHBIcNd8OLj4xUQEGCjqJBT3t7eqlixog4fPmzrUJCN9P5EXyu4ypUrp2LFitHfbKx///5atWqVNm7cqJIlS5rlAQEBunbtmhITEy3q08dsK6v2ykxoaKgk0cdsxMnJSeXLl1dISIgmTJigmjVraurUqfStfCqr9soMfcu2du3apTNnzuiRRx6Ro6OjHB0dtXnzZk2bNk2Ojo7y9/fPkz5Gwp1POTk5KSQkROvXrzfL0tLStH79eovrQJA/Xbp0SUeOHFHx4sVtHQqyUbZsWQUEBFj0teTkZG3fvp2+VkD89ddfSkhIoL/ZiGEY6t+/v1asWKENGzaobNmyFvNDQkJUqFAhiz528OBBnThxgj5mA9m1V2b27NkjSfSxfCItLU0pKSn0rQIivb0yQ9+yrWbNmmnfvn3as2eP+apdu7a6du1q/p0XfYwh5fnY4MGDFRkZqdq1a6tu3bqaMmWKLl++rO7du9s6NNzm9ddf1xNPPKGgoCCdOnVKo0aNkoODg7p06WLr0KCbP4Dc+uvx0aNHtWfPHvn4+Kh06dIaOHCg3nnnHVWoUEFly5bV22+/rcDAQLVt29Z2QT/A7tRePj4+GjNmjNq3b6+AgAAdOXJEQ4cOVfny5RUREWHDqB9c/fr106JFi7Ry5Up5eHiY17V5eXnJ1dVVXl5e6tGjhwYPHiwfHx95enpqwIABCgsLU7169Wwc/YMnu/Y6cuSIFi1apFatWqlo0aLau3evBg0apEaNGmV4XA6sb8SIEWrZsqVKly6tixcvatGiRdq0aZO+//57+lY+dKf2om/lPx4eHhb3r5AkNzc3FS1a1CzPkz6WtzdVR16bPn26Ubp0acPJycmoW7eusW3bNluHhEx06tTJKF68uOHk5GSUKFHC6NSpk3H48GFbh4X/b+PGjYakDK/IyEjDMG4+Guztt982/P39DWdnZ6NZs2bGwYMHbRv0A+xO7XXlyhWjefPmhq+vr1GoUCEjKCjI6NmzpxEXF2frsB9YmbWVJGPevHlmnX/++cfo27evUaRIEaNw4cLG008/bZw+fdp2QT/AsmuvEydOGI0aNTJ8fHwMZ2dno3z58saQIUOMpKQk2wb+gHrxxReNoKAgw8nJyfD19TWaNWtmrFu3zpxP38pf7tRe9K2C4fZHt+VFH7MzDMO4u98EAAAAAABAVriGGwAAAAAAKyDhBgAAAADACki4AQAAAACwAhJuAAAAAACsgIQbAAAAAAArIOEGAAAAAMAKSLgBAAAAALACEm4AAAAAAKyAhBsAAAAAACsg4QYAAAAAwApIuAEAAAAAsIL/By2gedGWMhGxAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting old and new class distributions\n",
    "plot_class_distributions(povo_categories, povo_filtered_categories, labels_minority, \\\n",
    "                         labels_majority, threshold_multiplier, 'povo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be368210-2317-4991-aac4-12dc1fd6e9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the dataset is still unbalanced, we also create class weights for the loss function\n",
    "povo_class_weights = compute_class_weights(povo_filtered_categories, labels_minority, \\\n",
    "                                           labels_majority, device, threshold_multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fe3bdc-df2c-40ed-b0c7-a2ac7989e256",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   5%|██▎                                          | 1/20 [04:12<1:19:52, 252.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 1\n",
      "Epoch 1, Loss: 1105.0194, Validation Accuracy: 0.3665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  10%|████▌                                        | 2/20 [08:21<1:15:12, 250.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 2\n",
      "Epoch 2, Loss: 805.4055, Validation Accuracy: 0.4739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  15%|██████▊                                      | 3/20 [12:30<1:10:44, 249.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 3\n",
      "Epoch 3, Loss: 610.7271, Validation Accuracy: 0.5369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  20%|█████████                                    | 4/20 [16:36<1:06:12, 248.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 4\n",
      "Epoch 4, Loss: 447.2005, Validation Accuracy: 0.5872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  25%|███████████▎                                 | 5/20 [20:41<1:01:49, 247.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 5\n",
      "Epoch 5, Loss: 311.7768, Validation Accuracy: 0.6286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  30%|██████████████                                 | 6/20 [24:47<57:34, 246.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 6\n",
      "Epoch 6, Loss: 208.0585, Validation Accuracy: 0.6591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  35%|████████████████▍                              | 7/20 [28:48<53:00, 244.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 136.4552, Validation Accuracy: 0.6542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  40%|██████████████████▊                            | 8/20 [32:48<48:40, 243.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 8\n",
      "Epoch 8, Loss: 90.3738, Validation Accuracy: 0.6611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  45%|█████████████████████▏                         | 9/20 [36:49<44:29, 242.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 9\n",
      "Epoch 9, Loss: 60.5071, Validation Accuracy: 0.6650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  50%|███████████████████████                       | 10/20 [40:50<40:19, 241.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 40.7643, Validation Accuracy: 0.6631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  55%|█████████████████████████▎                    | 11/20 [44:50<36:14, 241.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 11\n",
      "Epoch 11, Loss: 28.8275, Validation Accuracy: 0.6729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  60%|███████████████████████████▌                  | 12/20 [48:54<32:17, 242.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch 12\n",
      "Epoch 12, Loss: 20.3957, Validation Accuracy: 0.6749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  65%|█████████████████████████████▉                | 13/20 [53:03<28:30, 244.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 15.0493, Validation Accuracy: 0.6709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  70%|████████████████████████████████▏             | 14/20 [57:13<24:35, 245.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 11.8458, Validation Accuracy: 0.6709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  75%|█████████████████████████████████           | 15/20 [1:01:25<20:39, 247.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 14.0964, Validation Accuracy: 0.6010\n"
     ]
    }
   ],
   "source": [
    "# Recreating datasets for proper training and testing\n",
    "povo_train_val_labels = povo_labels.copy()\n",
    "povo_test_labels_aux = random.sample(list(povo_train_val_labels), \\\n",
    "                                     int(0.1*len(povo_train_val_labels)))\n",
    "povo_test_labels = {}\n",
    "for key in povo_test_labels_aux:\n",
    "    povo_test_labels[key] = povo_train_val_labels[key]\n",
    "    del povo_train_val_labels[key]\n",
    "    \n",
    "povo_train_val_dataset = ImageDataset(povo_train_val_labels, transform=vit_transform, \\\n",
    "                                      augment=False)\n",
    "povo_test_dataset = ImageDataset(povo_test_labels, transform=vit_transform, augment=False)\n",
    "\n",
    "# Setting-up training, executing training and then running tests\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "num_classes = ind_df['povo'].dropna().nunique()\n",
    "model = ViTClassifier(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=5e-5, weight_decay=2e-6)\n",
    "model_name = 'vit_povo'\n",
    "column_name = 'povo'\n",
    "\n",
    "test_prec, test_rec = execute_train_test(povo_train_val_dataset, povo_test_dataset, device, \\\n",
    "                                         batch_size, epochs, num_classes, model, criterion, \\\n",
    "                                         opt, model_name, column_name)\n",
    "prec_rec_on_selected_classes(povo_categories, povo_filtered_categories, test_prec, test_rec)\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0871d528-56a5-4773-8e47-92426a19c1cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retraining model with augmented dataset to see the difference in the results\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "num_classes = len(povo_filtered_categories)\n",
    "model = ViTClassifier(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=povo_class_weights)\n",
    "opt = optim.Adam(model.parameters(), lr=2e-5, weight_decay=2e-6)\n",
    "model_name = 'balanced_vit_povo'\n",
    "column_name = 'povo'\n",
    "\n",
    "execute_train_test(povo_augmented_dataset, povo_balanced_test_dataset, device, batch_size, \\\n",
    "                   epochs, num_classes, model, criterion, opt, model_name, column_name, \\\n",
    "                   povo_balanced_val_dataset)\n",
    "\n",
    "povo_vit_trimap, povo_vit_tsne, \\\n",
    "povo_vit_umap, povo_image_indices = compute_classifier_embeddings(povo_dataloader, model, \\\n",
    "                                                                  device)\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4ae93b-0c01-4264-8334-042474bd2b70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training partially frozen model on balanced dataset to see the difference in results\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "num_classes = len(povo_filtered_categories)\n",
    "freeze = 7\n",
    "model = ViTClassifier(num_classes, freeze=freeze).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=povo_class_weights)\n",
    "opt = optim.Adam(model.parameters(), lr=2e-5, weight_decay=2e-6)\n",
    "model_name = 'frozen_vit_povo'\n",
    "column_name = 'povo'\n",
    "\n",
    "execute_train_test(povo_augmented_dataset, povo_balanced_test_dataset, device, batch_size, \\\n",
    "                   epochs, num_classes, model, criterion, opt, model_name, column_name, \\\n",
    "                   povo_balanced_val_dataset)\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0a9205-5eaf-4bbe-ba8c-79f0d81653d8",
   "metadata": {},
   "source": [
    "#### *categoria* Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fade66-3cd8-4a50-a8f1-da9b84b1f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now rebalancing the 'categoria' column\n",
    "categoria_labels, categoria_name_to_num, categoria_num_to_name = \\\n",
    "preparing_image_labels(ind_df, 'categoria')\n",
    "categoria_dataset = ImageDataset(categoria_labels, transform=vit_transform)\n",
    "categoria_dataloader = DataLoader(categoria_dataset, batch_size=512, shuffle=True, \\\n",
    "                                  num_workers=0, pin_memory=True)\n",
    "\n",
    "categoria_categories, categories_keys, categories_freq, qs, \\\n",
    "masks = study_class_distribution(categoria_labels)\n",
    "\n",
    "# Filtering out 'etnobotânica' (and 'armas')\n",
    "filter_out = [categoria_name_to_num['etnobotânica']]\n",
    "categoria_filtered_categories = {}\n",
    "categoria_filtered_categories_names = {}\n",
    "for c in set(categoria_name_to_num.values()) - set(filter_out):\n",
    "    categoria_filtered_categories[categories_keys[c]] = \\\n",
    "    categoria_categories[categories_keys[c]]\n",
    "    \n",
    "    categoria_filtered_categories_names[categoria_num_to_name[categories_keys[c]]] = \\\n",
    "    categoria_categories[categories_keys[c]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9493d23c-372a-4c29-a1b1-13bb41f7f1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering dataframe for selected categories\n",
    "threshold_multiplier = 1.5\n",
    "minority_classes, majority_classes, labels_minority, labels_majority, val_labels, \\\n",
    "test_labels, categoria_augmented_dataset, categoria_balanced_val_dataset, \\\n",
    "categoria_balanced_test_dataset = \\\n",
    "filter_image_data_distribution(ind_df, categoria_filtered_categories_names, vit_transform, \\\n",
    "                               threshold_multiplier, 'categoria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051ce382-430c-4026-8484-145c1da501d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting old and new class distributions\n",
    "plot_class_distributions(categoria_categories, categoria_filtered_categories, \\\n",
    "                         labels_minority, labels_majority, threshold_multiplier, 'categoria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f03e8aa-db16-4cfc-a7f3-3b0dc41f4186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the dataset is still unbalanced, we also create class weights for the loss function\n",
    "categoria_class_weights = compute_class_weights(categoria_filtered_categories, \\\n",
    "                                                labels_minority, labels_majority, device, \\\n",
    "                                                threshold_multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47f319d-f46f-4197-bc9b-7006224bac68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Recreating datasets for proper training and testing\n",
    "categoria_train_val_labels = categoria_labels.copy()\n",
    "categoria_test_labels_aux = random.sample(list(categoria_train_val_labels), \\\n",
    "                                          int(0.1*len(categoria_train_val_labels)))\n",
    "categoria_test_labels = {}\n",
    "for key in categoria_test_labels_aux:\n",
    "    categoria_test_labels[key] = categoria_train_val_labels[key]\n",
    "    del categoria_train_val_labels[key]\n",
    "    \n",
    "categoria_train_val_dataset = ImageDataset(categoria_train_val_labels, \\\n",
    "                                           transform=vit_transform, augment=False)\n",
    "categoria_test_dataset = ImageDataset(categoria_test_labels, \\\n",
    "                                      transform=vit_transform, augment=False)\n",
    "\n",
    "# Setting-up training, executing training and then running tests\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "num_classes = ind_df['categoria'].dropna().nunique()\n",
    "model = ViTClassifier(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-5, weight_decay=2e-6)\n",
    "model_name = 'vit_categoria'\n",
    "column_name = 'categoria'\n",
    "\n",
    "test_prec, test_rec = execute_train_test(categoria_train_val_dataset, categoria_test_dataset, \\\n",
    "                                         device, batch_size, epochs, num_classes, model, \\\n",
    "                                         criterion, opt, model_name, column_name)\n",
    "prec_rec_on_selected_classes(categoria_categories, categoria_filtered_categories, test_prec, \\\n",
    "                             test_rec)\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddf8fac-6f67-4ea7-ab8c-8d2be9add2e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retraining model with augmented dataset to see the difference in the results\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "num_classes = len(categoria_filtered_categories)\n",
    "model = ViTClassifier(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=categoria_class_weights)\n",
    "opt = optim.Adam(model.parameters(), lr=3e-6, weight_decay=1e-6)\n",
    "model_name = 'balanced_vit_categoria'\n",
    "column_name = 'categoria'\n",
    "\n",
    "execute_train_test(categoria_augmented_dataset, categoria_balanced_test_dataset, device, \\\n",
    "                   batch_size, epochs, num_classes, model, criterion, opt, model_name, \\\n",
    "                   column_name, categoria_balanced_val_dataset)\n",
    "\n",
    "categoria_vit_trimap, categoria_vit_tsne, categoria_vit_umap, \\\n",
    "categoria_image_indices = compute_classifier_embeddings(categoria_dataloader, model, device)\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f58fdaa-04d0-44fc-93a0-5ebbf9b7a4d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training partially frozen model on balanced dataset to see the difference in results\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "num_classes = len(categoria_filtered_categories)\n",
    "freeze = 7\n",
    "model = ViTClassifier(num_classes, freeze=freeze).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=categoria_class_weights)\n",
    "opt = optim.Adam(model.parameters(), lr=3e-6, weight_decay=1e-6)\n",
    "model_name = 'frozen_vit_categoria'\n",
    "column_name = 'categoria'\n",
    "\n",
    "execute_train_test(categoria_augmented_dataset, categoria_balanced_test_dataset, device, \\\n",
    "                   batch_size, epochs, num_classes, model, criterion, opt, model_name, \\\n",
    "                   column_name, categoria_balanced_val_dataset)\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c773629-dfd3-43ec-8e5a-c9e8e4117fa7",
   "metadata": {},
   "source": [
    "#### Multi-Head Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a574bade-683d-42b5-805a-4e1a41a89c61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting data that passes both heads' data-filters\n",
    "povo_set = set(np.array(list(povo_labels.keys()))\\\n",
    "                [np.where(np.isin(np.array(list(povo_labels.values())), \\\n",
    "                np.array(list(povo_filtered_categories.keys()))))[0]])\n",
    "categoria_set = set(np.array(list(categoria_labels.keys()))\\\n",
    "                    [np.where(np.isin(np.array(list(categoria_labels.values())), \\\n",
    "                    np.array(list(categoria_filtered_categories.keys()))))[0]])\n",
    "multi_head_keys = [str(x) for x in povo_set.intersection(categoria_set)]\n",
    "\n",
    "# Studying individual and joint classes' distributions\n",
    "povo_freq = {}\n",
    "categoria_freq = {}\n",
    "multi_freq = {}\n",
    "for key in multi_head_keys:\n",
    "    try:\n",
    "        povo_freq[povo_labels[key]] += 1\n",
    "    except:\n",
    "        povo_freq[povo_labels[key]] = 1\n",
    "\n",
    "    try:\n",
    "        categoria_freq[categoria_labels[key]] += 1\n",
    "    except:\n",
    "        categoria_freq[categoria_labels[key]] = 1\n",
    "\n",
    "    try:\n",
    "        multi_freq[f'{(povo_labels[key], categoria_labels[key])}'] += 1\n",
    "    except:\n",
    "        multi_freq[f'{(povo_labels[key], categoria_labels[key])}'] = 1\n",
    "\n",
    "# Utility function to plot rows on data distribution plot\n",
    "def row_bar_plot(col_freq, name, row, rows=3, cols=1, remove_xticks=False):\n",
    "    plt.subplot(rows, cols, row)\n",
    "    plt.bar(list(col_freq.keys()), list(col_freq.values()))\n",
    "    plt.title(name)\n",
    "\n",
    "    if remove_xticks:\n",
    "        plt.xlabel(\"\")\n",
    "        plt.xticks([])\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.suptitle('Classes Distributions for Multi-Head Data')\n",
    "\n",
    "row_bar_plot(povo_freq, \"'povo' Column\", 1)\n",
    "row_bar_plot(categoria_freq, \"'categoria' Column\", 2)\n",
    "row_bar_plot(multi_freq, \"Both Columns (Joint Distribution)\", 3, remove_xticks=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa01612-aadc-4200-ae15-dcfb01d448bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because of the even worse degree of unbalanced data on the joint distribution, we balance\n",
    "# the dataset taking the 'povo' column into consideration and study the new joint distribution\n",
    "multi_povo_labels = {}\n",
    "multi_categoria_labels = {}\n",
    "for key in multi_head_keys:\n",
    "    multi_povo_labels[key] = povo_labels[key]\n",
    "    multi_categoria_labels[key] = categoria_labels[key]\n",
    "\n",
    "# Reusing previous dataset infrastructure to build multi-label dataset\n",
    "multi_povo_categories, categories_keys, categories_freq, \\\n",
    "qs, masks = study_class_distribution(multi_povo_labels)\n",
    "multi_povo_filtered_categories = multi_povo_categories\n",
    "multi_povo_filtered_categories_names = {}\n",
    "for c in categories_keys:\n",
    "    multi_povo_filtered_categories_names[povo_num_to_name[c]] = multi_povo_categories[c]\n",
    "\n",
    "multi_categoria_categories, categories_keys, categories_freq, \\\n",
    "qs, masks = study_class_distribution(multi_categoria_labels)\n",
    "multi_categoria_filtered_categories = multi_categoria_categories\n",
    "multi_categoria_filtered_categories_names = {}\n",
    "for c in categories_keys:\n",
    "    multi_categoria_filtered_categories_names[categoria_num_to_name[c]] = \\\n",
    "    multi_categoria_categories[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffb1c1a-b60b-4a08-82f0-2484d837e78d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filtering dataframe for selected categories\n",
    "threshold_multiplier = 2\n",
    "minority_classes, majority_classes, labels_minority, labels_majority, \\\n",
    "val_labels, test_labels, multi_augmented_dataset, multi_balanced_val_dataset, \\\n",
    "multi_balanced_test_dataset = \\\n",
    "multihead_filter_image_data_distribution(ind_df, [multi_povo_filtered_categories_names, \\\n",
    "                                         multi_categoria_filtered_categories_names], \\\n",
    "                                         vit_transform, threshold_multiplier, \\\n",
    "                                         ['povo', 'categoria'])\n",
    "\n",
    "# Plotting old and new class distributions\n",
    "multihead_plot_class_distributions(multi_povo_categories, multi_povo_filtered_categories, \\\n",
    "                                   labels_minority, labels_majority, threshold_multiplier, \\\n",
    "                                   'povo')\n",
    "\n",
    "multihead_plot_class_distributions(multi_categoria_categories, \\\n",
    "                                   multi_categoria_filtered_categories, \\\n",
    "                                   labels_minority, labels_majority, threshold_multiplier, \\\n",
    "                                   'categoria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb11d70-889b-43f1-819b-12118d21e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the dataset is still unbalanced, we also create class weights for the loss function\n",
    "multi_povo_class_weights = multihead_compute_class_weights(multi_povo_filtered_categories, \\\n",
    "                                                           labels_minority, labels_majority, \\\n",
    "                                                           device, threshold_multiplier, \\\n",
    "                                                           'povo')\n",
    "\n",
    "multi_categoria_class_weights = \\\n",
    "multihead_compute_class_weights(multi_categoria_filtered_categories, labels_minority, \\\n",
    "                                labels_majority, device, threshold_multiplier,'categoria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f343bf-bbd9-496e-9f95-b1a14b914287",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training multi-head model on balanced dataset to see the difference in results\n",
    "batch_size = 16\n",
    "epochs = 30\n",
    "num_classes = [len(multi_povo_filtered_categories), len(multi_categoria_filtered_categories)]\n",
    "model = ViTClassifier(num_classes[0], num_classes[1]).to(device)\n",
    "criterions = [nn.CrossEntropyLoss(weight=multi_povo_class_weights), \\\n",
    "              nn.CrossEntropyLoss(weight=multi_categoria_class_weights)]\n",
    "opt = optim.Adam(model.parameters(), lr=1e-5, weight_decay=3e-6)\n",
    "model_name = 'multihead_vit'\n",
    "column_names = ['povo', 'categoria']\n",
    "arch_name = 'ViT'\n",
    "head_weights = [0.3, 0.7]\n",
    "\n",
    "multihead_execute_train_test(multi_augmented_dataset, multi_balanced_test_dataset, device, \\\n",
    "                             batch_size, epochs, num_classes, model, \\\n",
    "                             criterions, opt, model_name, column_names, \\\n",
    "                             multi_balanced_val_dataset, arch_name, head_weights)\n",
    "\n",
    "multihead_vit_trimap, multihead_vit_tsne, multihead_vit_umap, \\\n",
    "multihead_image_indices = compute_classifier_embeddings(categoria_dataloader, model, device)\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81730faf-1ab3-4473-9268-04b25559bc14",
   "metadata": {},
   "source": [
    "### Visualizing and Comparing Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7622319c-08ac-475d-8376-c66bd3e76fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing data for later plot on tool\n",
    "norm_factor = 12\n",
    "vanilla_vit_trimap = normalize(vanilla_vit_trimap, norm_factor)\n",
    "vanilla_vit_tsne = normalize(vanilla_vit_tsne, norm_factor)\n",
    "vanilla_vit_umap = normalize(vanilla_vit_umap, norm_factor)\n",
    "\n",
    "povo_vit_trimap = normalize(povo_vit_trimap, norm_factor)\n",
    "povo_vit_tsne = normalize(povo_vit_tsne, norm_factor)\n",
    "povo_vit_umap = normalize(povo_vit_umap, norm_factor)\n",
    "\n",
    "categoria_vit_trimap = normalize(categoria_vit_trimap, norm_factor)\n",
    "categoria_vit_tsne = normalize(categoria_vit_tsne, norm_factor)\n",
    "categoria_vit_umap = normalize(categoria_vit_umap, norm_factor)\n",
    "\n",
    "multihead_vit_trimap = normalize(multihead_vit_trimap, norm_factor)\n",
    "multihead_vit_tsne = normalize(multihead_vit_tsne, norm_factor)\n",
    "multihead_vit_umap = normalize(multihead_vit_umap, norm_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fce310-fb5f-4218-afb7-5ffcb02dbf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to plot rows on projection comparison plot\n",
    "def row_scatter_plot(projs, proj_names, row, color, rows=3, cols=3):\n",
    "    for i, (proj, proj_name) in enumerate(zip(projs, proj_names)):\n",
    "        plt.subplot(rows, cols, i+1+(cols*(row-1)))\n",
    "        plt.scatter(proj[:, 0], proj[:, 1], c=color)\n",
    "        plt.title(f\"{proj_name}\")\n",
    "        plt.xlabel(\"\")\n",
    "        plt.ylabel(\"\")\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "\n",
    "# Visualizing resulting projections\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.suptitle('Comparing Projections of ViT Models')\n",
    "\n",
    "# Plotting vanilla ViT projections\n",
    "projs = [vanilla_vit_trimap, vanilla_vit_tsne, vanilla_vit_umap]\n",
    "proj_names = ['Vanilla ViT with TriMap', 'Vanilla ViT with t-SNE', 'Vanilla ViT with UMAP']\n",
    "row_scatter_plot(projs, proj_names, 1, 'b')\n",
    "\n",
    "# Plotting ViT fine-tuned on 'povo' projections\n",
    "projs = [povo_vit_trimap, povo_vit_tsne, povo_vit_umap]\n",
    "proj_names = [\"ViT Fine-Tuned on 'povo' with TriMap\", \"ViT Fine-Tuned on 'povo' with t-SNE\", \\\n",
    "              \"ViT Fine-Tuned on 'povo' with UMAP\"]\n",
    "row_scatter_plot(projs, proj_names, 2, 'r')\n",
    "\n",
    "# Plotting ViT fine-tuned on 'categoria' projections\n",
    "projs = [categoria_vit_trimap, categoria_vit_tsne, categoria_vit_umap]\n",
    "proj_names = [\"ViT Fine-Tuned on 'categoria' with TriMap\", \\\n",
    "              \"ViT Fine-Tuned on 'categoria' with t-SNE\", \\\n",
    "              \"ViT Fine-Tuned on 'categoria' with UMAP\"]\n",
    "row_scatter_plot(projs, proj_names, 3, 'g')\n",
    "\n",
    "# Plotting ViT fine-tuned on 'povo' and 'categoria' (multi-head) projections\n",
    "projs = [categoria_vit_trimap, categoria_vit_tsne, categoria_vit_umap]\n",
    "proj_names = [\"ViT Fine-Tuned on 'categoria' with TriMap\", \\\n",
    "              \"ViT Fine-Tuned on 'categoria' with t-SNE\", \\\n",
    "              \"ViT Fine-Tuned on 'categoria' with UMAP\"]\n",
    "row_scatter_plot(projs, proj_names, 4, 'yellow')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d358406-41c1-40ba-8580-398ff90a1872",
   "metadata": {},
   "source": [
    "### Visualizing Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7ccb9a-0d2f-4f97-adc5-686a4310b555",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filtering dataframe to get only the part that contains images\n",
    "filtered_df = ind_df.loc[ind_df['image_path'].notna()]\n",
    "\n",
    "# Visualizing 'povo' cluster\n",
    "visualizing_clusters(filtered_df, povo_vit_umap, povo_image_indices, 'povo', 'UMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a072ba0-1e61-4288-b4ff-27ad22e1c3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing 'categoria' cluster\n",
    "visualizing_clusters(filtered_df, categoria_vit_umap, categoria_image_indices, \\\n",
    "                     'categoria', 'UMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6824912b-0827-4e88-b3d3-abe9fed90ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing 'povo' cluster for multi-head modedl\n",
    "visualizing_clusters(filtered_df, multihead_vit_umap, multihead_image_indices, \\\n",
    "                     'povo', 'UMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2d5f57-7fe5-4dfb-b3dc-b550fb26913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing 'categoria' cluster for multi-head modedl\n",
    "visualizing_clusters(filtered_df, multihead_vit_umap, multihead_image_indices, \\\n",
    "                     'categoria', 'UMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba8e8d-256f-4681-9fa8-8c1026781225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving outputs for visualization tool\n",
    "_ = saving_outputs(filtered_df, povo_labels, vanilla_vit_umap, vanilla_image_indices, \\\n",
    "                   save_file='vanilla_vit.csv', no_clusters=True)\n",
    "\n",
    "_ = saving_outputs(filtered_df, povo_labels, povo_vit_umap, povo_image_indices, 'povo', \\\n",
    "                   'povo_vit.csv')\n",
    "\n",
    "_ = saving_outputs(filtered_df, categoria_labels, categoria_vit_umap, \\\n",
    "                   categoria_image_indices, 'categoria', 'categoria_vit.csv')\n",
    "\n",
    "_ = saving_outputs(filtered_df, multi_povo_labels, multihead_vit_umap, \\\n",
    "                   multihead_image_indices, save_file='multihead_vit.csv', no_clusters=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50709824-9e61-4a0e-9963-fd10b5a1f727",
   "metadata": {},
   "source": [
    "## DINOv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c9fd41-14e6-48a0-836f-d4ee23073892",
   "metadata": {},
   "source": [
    "### Pre-Trained Embedding Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c387c93-d1e2-458d-85d8-ebc65a74559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, AutoModel\n",
    "\n",
    "# Rebuilding dataset with DINO transform and dataloader with smaller batch_size because of \n",
    "# the model's size\n",
    "dino_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop((224, 224)),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "povo_dataset = ImageDataset(povo_labels, transform=dino_transform, augment=False)\n",
    "povo_dataloader = DataLoader(povo_dataset, batch_size=16, shuffle=True, \\\n",
    "                             num_workers=0, pin_memory=True)\n",
    "\n",
    "# Loading model and pre-processor\n",
    "dino_processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')\n",
    "model = AutoModel.from_pretrained('facebook/dinov2-base')\n",
    "model.to(device)\n",
    "\n",
    "# Projecting data onto the off-the-shelf pre-trained embedding space from DINOv2\n",
    "image_embeddings, vanilla_image_indices = get_embeddings(model, povo_dataloader, device, \\\n",
    "                                                         model_name='dino')\n",
    "image_embeddings = np.concatenate(image_embeddings, axis=0)\n",
    "\n",
    "# Computing data reduced-dimensionality projections\n",
    "_, _, vanilla_dino_umap = data_projections(image_embeddings)\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model, image_embeddings])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fba030-df4f-434a-a90e-d08cebc2e38b",
   "metadata": {},
   "source": [
    "### Fine-Tuning Embedding Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96872a49-4b39-4693-872a-627e5191ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our own DINO classifier head for fine-tuning\n",
    "class DINOClassifier(nn.Module):\n",
    "    def __init__(self, num_classes1, num_classes2=0, freeze=0):\n",
    "        super(DINOClassifier, self).__init__()\n",
    "        self.dino = AutoModel.from_pretrained('facebook/dinov2-base')\n",
    "        self.classifier1 = nn.Linear(self.dino.config.hidden_size, num_classes1)\n",
    "        self.multi_head = False\n",
    "        \n",
    "        # Multi-head architecture\n",
    "        if num_classes2 > 0:\n",
    "            self.classifier2 = nn.Linear(self.dino.config.hidden_size, num_classes2)\n",
    "            self.multi_head = True\n",
    "        \n",
    "        self.freeze_layers(freeze)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        outputs = self.dino(x)\n",
    "        \n",
    "        # Getting embeddings from last_hidden_state of CLS token (maybe pooler_output?)\n",
    "        embeddings = outputs['last_hidden_state'][:, 0, :]\n",
    "        # embeddings = outputs['pooler_output']\n",
    "\n",
    "        logits1 = self.classifier1(embeddings)\n",
    "        if self.multi_head:\n",
    "            logits2 = self.classifier2(embeddings)\n",
    "            return logits1, logits2\n",
    "        return logits1\n",
    "\n",
    "    # Freezing early layers so we don't lose generalization and speed up training\n",
    "    def freeze_layers(self, freeze):\n",
    "        if freeze <= 0:\n",
    "            return\n",
    "\n",
    "        # Accounting for the embedding freeze\n",
    "        freeze -= 1\n",
    "        \n",
    "        for name, param in self.dino.named_parameters():\n",
    "            if \"embeddings\" in name:\n",
    "                param.requires_grad = False\n",
    "            elif int(name.split('.')[2]) < freeze:\n",
    "                param.requires_grad = False\n",
    "            else:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6609639-35a5-4fae-b1a8-799d4a37a585",
   "metadata": {},
   "source": [
    "#### *povo* Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39e11a4-c5cb-4524-9dc5-3f2fca00adaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Recreating datasets for proper training and testing\n",
    "povo_train_val_dataset = ImageDataset(povo_train_val_labels, transform=dino_transform, \\\n",
    "                                      augment=False)\n",
    "povo_test_dataset = ImageDataset(povo_test_labels, transform=dino_transform, augment=False)\n",
    "\n",
    "# Setting-up training, executing training and then running tests\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "num_classes = ind_df['povo'].dropna().nunique()\n",
    "model = DINOClassifier(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-6, weight_decay=3e-7)\n",
    "model_name = 'dino_povo'\n",
    "column_name = 'povo'\n",
    "\n",
    "test_prec, test_rec = execute_train_test(povo_train_val_dataset, povo_test_dataset, device, \\\n",
    "                                        batch_size, epochs, num_classes, model, criterion, \\\n",
    "                                        opt, model_name, column_name, \\\n",
    "                                        architecture_name='DINOv2')\n",
    "prec_rec_on_selected_classes(povo_categories, povo_filtered_categories, test_prec, test_rec)\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ed537e-c895-4f46-a748-97bb0cf56995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering dataframe for selected categories. We need to recompute this part of the dataset\n",
    "# because of the different transform used\n",
    "threshold_multiplier = 2\n",
    "minority_classes, majority_classes, labels_minority, labels_majority, \\\n",
    "val_labels, test_labels, povo_augmented_dataset, povo_balanced_val_dataset, \\\n",
    "povo_balanced_test_dataset = filter_image_data_distribution(ind_df, \\\n",
    "                                                            povo_filtered_categories_names, \\\n",
    "                                                            dino_transform, \\\n",
    "                                                            threshold_multiplier, \\\n",
    "                                                            'povo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78db26c8-d6f3-4dbb-8f9f-b6804b352454",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retraining model with augmented dataset to see the difference in the results\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "num_classes = len(povo_filtered_categories)\n",
    "model = DINOClassifier(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=povo_class_weights)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-6, weight_decay=3e-7)\n",
    "model_name = 'balanced_dino_povo'\n",
    "column_name = 'povo'\n",
    "\n",
    "execute_train_test(povo_augmented_dataset, povo_balanced_test_dataset, device, batch_size, \\\n",
    "                   epochs, num_classes, model, criterion, opt, model_name, column_name, \\\n",
    "                   povo_balanced_val_dataset, architecture_name='DINOv2')\n",
    "\n",
    "# _, _, \\\n",
    "# povo_dino_umap, povo_image_indices = compute_classifier_embeddings(povo_dataloader, model, \\\n",
    "#                                                                    device, 'dino')\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d89dd8-9eea-44e4-8f11-72af1825171b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training partially frozen model on balanced dataset to see the difference in results\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "num_classes = len(povo_filtered_categories)\n",
    "freeze = 9\n",
    "model = DINOClassifier(num_classes, freeze=freeze).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=povo_class_weights)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-6, weight_decay=3e-7)\n",
    "model_name = 'frozen_dino_povo'\n",
    "column_name = 'povo'\n",
    "\n",
    "execute_train_test(povo_augmented_dataset, povo_balanced_test_dataset, device, \\\n",
    "                   batch_size, epochs, num_classes, model, criterion, opt, model_name, \\\n",
    "                   column_name, povo_balanced_val_dataset, architecture_name='DINOv2')\n",
    "\n",
    "_, _, \\\n",
    "povo_dino_umap, povo_image_indices = compute_classifier_embeddings(povo_dataloader, model, \\\n",
    "                                                                   device, 'dino')\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064d659b-247f-4ec8-996f-b0f50e36c3ed",
   "metadata": {},
   "source": [
    "#### *categoria* Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c80e65-f3e3-447b-84b6-af6d6f114a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now creating the 'categoria' dataset\n",
    "categoria_dataset = ImageDataset(categoria_labels, transform=dino_transform)\n",
    "categoria_dataloader = DataLoader(categoria_dataset, batch_size=8, shuffle=True, \\\n",
    "                                  num_workers=0, pin_memory=True)\n",
    "\n",
    "# Recreating datasets for proper training and testing\n",
    "categoria_train_val_dataset = ImageDataset(categoria_train_val_labels, \\\n",
    "                                           transform=dino_transform, augment=False)\n",
    "categoria_test_dataset = ImageDataset(categoria_test_labels, transform=dino_transform, \\\n",
    "                                      augment=False)\n",
    "\n",
    "# Setting-up training, executing training and then running tests\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "num_classes = ind_df['categoria'].dropna().nunique()\n",
    "model = DINOClassifier(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-5, weight_decay=2e-6)\n",
    "model_name = 'dino_categoria'\n",
    "column_name = 'categoria'\n",
    "\n",
    "test_prec, test_rec = execute_train_test(categoria_train_val_dataset, categoria_test_dataset, \\\n",
    "                                         device, batch_size, epochs, num_classes, model, \\\n",
    "                                         criterion, opt, model_name, column_name, \\\n",
    "                                         architecture_name='DINOv2')\n",
    "prec_rec_on_selected_classes(categoria_categories, categoria_filtered_categories, test_prec, \\\n",
    "                             test_rec)\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff0224d-df2c-432e-87c6-4d8f30906601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering dataframe for selected categories. We need to recompute this part of the dataset\n",
    "# because of the different transform used\n",
    "threshold_multiplier = 1.5\n",
    "minority_classes, majority_classes, labels_minority, labels_majority, \\\n",
    "val_labels, test_labels, categoria_augmented_dataset, categoria_balanced_val_dataset, \\\n",
    "categoria_balanced_test_dataset = \\\n",
    "filter_image_data_distribution(ind_df, categoria_filtered_categories_names, dino_transform, \\\n",
    "                               threshold_multiplier, 'categoria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506c7d49-68a2-4593-86a0-b916298e888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retraining model with augmented dataset to see the difference in the results\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "num_classes = len(categoria_filtered_categories)\n",
    "model = DINOClassifier(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=povo_class_weights)\n",
    "opt = optim.Adam(model.parameters(), lr=2e-5, weight_decay=2e-6)\n",
    "model_name = 'balanced_dino_categoria'\n",
    "column_name = 'categoria'\n",
    "\n",
    "execute_train_test(categoria_augmented_dataset, categoria_balanced_test_dataset, device, \\\n",
    "                   batch_size, epochs, num_classes, model, criterion, opt, model_name, \\\n",
    "                   column_name, categoria_balanced_val_dataset, architecture_name='DINOv2')\n",
    "\n",
    "# _, _, \\\n",
    "# categoria_dino_umap, categoria_image_indices = \\\n",
    "# compute_classifier_embeddings(categoria_dataloader, model, device, 'dino')\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498b0ccb-5116-4131-ae55-446a32140d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training partially frozen model on balanced dataset to see the difference in results\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "num_classes = len(categoria_filtered_categories)\n",
    "freeze = 7\n",
    "model = DINOClassifier(num_classes, freeze=freeze).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=categoria_class_weights)\n",
    "opt = optim.Adam(model.parameters(), lr=2e-5, weight_decay=2e-6)\n",
    "model_name = 'frozen_dino_categoria'\n",
    "column_name = 'categoria'\n",
    "\n",
    "execute_train_test(categoria_augmented_dataset, categoria_balanced_test_dataset, device, \\\n",
    "                   batch_size, epochs, num_classes, model, criterion, opt, model_name, \\\n",
    "                   column_name, categoria_balanced_val_dataset, architecture_name='DINOv2')\n",
    "\n",
    "_, _, \\\n",
    "categoria_dino_umap, categoria_image_indices = \\\n",
    "compute_classifier_embeddings(categoria_dataloader, model, device, 'dino')\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0973b009-6372-4d31-ab43-b0be7ad21ff5",
   "metadata": {},
   "source": [
    "#### Multi-Head Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba1ceba-58c4-412d-bf76-fa70f4f5cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering dataframe for selected categories\n",
    "threshold_multiplier = 2\n",
    "minority_classes, majority_classes, labels_minority, labels_majority, \\\n",
    "val_labels, test_labels, multi_augmented_dataset, multi_balanced_val_dataset, \\\n",
    "multi_balanced_test_dataset = \\\n",
    "multihead_filter_image_data_distribution(ind_df, [multi_povo_filtered_categories_names, \\\n",
    "                                         multi_categoria_filtered_categories_names], \\\n",
    "                                         dino_transform, threshold_multiplier, \\\n",
    "                                         ['povo', 'categoria'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a0004c-9c36-4920-866a-bb035d9985e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the dataset is still unbalanced, we also create class weights for the loss function\n",
    "multi_povo_class_weights = multihead_compute_class_weights(multi_povo_filtered_categories, \\\n",
    "                                                           labels_minority, labels_majority, \\\n",
    "                                                           device, threshold_multiplier, \\\n",
    "                                                           'povo')\n",
    "\n",
    "multi_categoria_class_weights = \\\n",
    "multihead_compute_class_weights(multi_categoria_filtered_categories, labels_minority, \\\n",
    "                                labels_majority, device, threshold_multiplier,'categoria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461388ef-352a-4ee7-acec-88a2205152cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import image_training_utils\n",
    "importlib.reload(image_training_utils)\n",
    "from image_training_utils import *\n",
    "\n",
    "# Training multi-head model on balanced dataset to see the difference in results\n",
    "batch_size = 8\n",
    "epochs = 20\n",
    "num_classes = [len(multi_povo_filtered_categories), len(multi_categoria_filtered_categories)]\n",
    "model = DINOClassifier(num_classes[0], num_classes[1]).to(device)\n",
    "criterions = [nn.CrossEntropyLoss(weight=multi_povo_class_weights), \\\n",
    "              nn.CrossEntropyLoss(weight=multi_categoria_class_weights)]\n",
    "opt = optim.Adam(model.parameters(), lr=3e-6, weight_decay=1e-6)\n",
    "model_name = 'multihead_dino'\n",
    "column_names = ['povo', 'categoria']\n",
    "arch_name = 'DINOv2'\n",
    "head_weights = [0.5, 0.5]\n",
    "\n",
    "multihead_execute_train_test(multi_augmented_dataset, multi_balanced_test_dataset, device, \\\n",
    "                             batch_size, epochs, num_classes, model, \\\n",
    "                             criterions, opt, model_name, column_names, \\\n",
    "                             multi_balanced_val_dataset, arch_name, head_weights)\n",
    "\n",
    "_, _, multihead_dino_umap, \\\n",
    "multihead_image_indices = compute_classifier_embeddings(categoria_dataloader, model, device)\n",
    "\n",
    "# Cleaning up memory\n",
    "clean_mem([model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff69dbc0-c068-49e5-9ead-cba4df5f6621",
   "metadata": {},
   "source": [
    "### Visualizing and Comparing Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57420473-f668-471a-86fa-e3306d01f59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing data for later plot on tool\n",
    "vanilla_dino_umap = normalize(vanilla_dino_umap, norm_factor)\n",
    "povo_dino_umap = normalize(povo_dino_umap, norm_factor)\n",
    "categoria_dino_umap = normalize(categoria_dino_umap, norm_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ef94fc-64d8-4863-9695-7588e6ca47d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing resulting projections\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.suptitle('Comparing ViT and DINO Projections')\n",
    "\n",
    "# Plotting all ViT projections\n",
    "projs = [vanilla_vit_umap, povo_vit_umap, categoria_vit_umap, multihead_vit_umap]\n",
    "proj_names = [\"Vanilla ViT\", \"'povo' ViT\", \"'categoria' ViT\", \"Multi-head ViT\"]\n",
    "row_scatter_plot(projs, proj_names, 1, 'b', 2, 4)\n",
    "\n",
    "# Plotting all DINO projections\n",
    "projs = [vanilla_dino_umap, povo_dino_umap, categoria_dino_umap, multihead_dino_umap]\n",
    "proj_names = [\"Vanilla DINO\", \"'povo' DINO\", \"'categoria' DINO\", \"Multi-head DINO\"]\n",
    "row_scatter_plot(projs, proj_names, 2, 'r', 2, 4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037b94c6-b159-47ca-b81a-e162b7abf2c6",
   "metadata": {},
   "source": [
    "### Visualizing Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c12e262-61f8-4f7c-96df-cd86e3116a6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filtering dataframe to get only the part that contains images\n",
    "filtered_df = ind_df.loc[ind_df['image_path'].notna()]\n",
    "\n",
    "# Visualizing 'povo' cluster\n",
    "visualizing_clusters(filtered_df, povo_dino_umap, povo_image_indices, 'povo', 'UMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713d034d-00a4-4657-8f13-5fcc255af579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing 'categoria' cluster\n",
    "visualizing_clusters(filtered_df, categoria_dino_umap, categoria_image_indices, \\\n",
    "                     'categoria', 'UMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216f499f-2c92-4e16-b5e5-6f23abb9f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing 'povo' cluster for multi-head modedl\n",
    "visualizing_clusters(filtered_df, multihead_dino_umap, multihead_image_indices, \\\n",
    "                     'povo', 'UMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c251dd5-3d74-4daf-bcf1-e8b9f0c2e121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing 'categoria' cluster for multi-head modedl\n",
    "visualizing_clusters(filtered_df, multihead_dino_umap, multihead_image_indices, \\\n",
    "                     'categoria', 'UMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ff9039-99fd-40c8-90c7-dd0e2ceb32c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving outputs for visualization tool\n",
    "_ = saving_outputs(filtered_df, povo_labels, vanilla_dino_umap, vanilla_image_indices, \\\n",
    "                   save_file='vanilla_dino.csv', no_clusters=True)\n",
    "\n",
    "_ = saving_outputs(filtered_df, povo_labels, povo_dino_umap, povo_image_indices, 'povo', \\\n",
    "                   'povo_dino.csv')\n",
    "\n",
    "_ = saving_outputs(filtered_df, categoria_labels, categoria_dino_umap, \\\n",
    "                   categoria_image_indices, 'categoria', 'categoria_dino.csv')\n",
    "\n",
    "_ = saving_outputs(filtered_df, multi_povo_labels, multihead_dino_umap, \\\n",
    "                   multihead_image_indices, save_file='multihead_dino.csv', no_clusters=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
