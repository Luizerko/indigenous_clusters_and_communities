{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12e8d3d3-5137-4c49-a9c7-4ef40f64c737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe columns: \n",
      "Index(['url', 'thumbnail', 'creation_date', 'modification_date',\n",
      "       'numero_do_item', 'tripticos', 'categoria', 'nome_do_item',\n",
      "       'nome_do_item_dic', 'colecao', 'coletor', 'doador', 'modo_de_aquisicao',\n",
      "       'data_de_aquisicao', 'ano_de_aquisicao', 'data_de_confeccao', 'autoria',\n",
      "       'nome_etnico', 'descricao', 'dimensoes', 'funcao', 'materia_prima',\n",
      "       'tecnica_confeccao', 'descritor_tematico', 'descritor_comum',\n",
      "       'numero_de_pecas', 'itens_relacionados', 'responsavel_guarda',\n",
      "       'inst_detentora', 'povo', 'autoidentificacao', 'lingua',\n",
      "       'estado_de_origem', 'geolocalizacao', 'pais_de_origem', 'exposicao',\n",
      "       'referencias', 'disponibilidade', 'qualificacao', 'historia_adm',\n",
      "       'notas_gerais', 'observacao', 'conservacao', 'image_path'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading dataset\n",
    "ind_df = pd.read_csv('../data/indigenous_collection_processed.csv', index_col='id')\n",
    "print(f'Dataframe columns: \\n{ind_df.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7ccfb45-9155-48a9-b5fa-fbf4e585822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "# Creating skip cell command\n",
    "@register_cell_magic\n",
    "def skip(line, cell):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0915c122-a4e2-4a09-896f-0c1579ae45c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centralizing main imports so we can run the models separately\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from language_training_utils import *\n",
    "\n",
    "# import language_training_utils\n",
    "# importlib.reload(language_training_utils)\n",
    "# from language_training_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a033d0f-bc94-45f8-8d78-5e6b93d6e582",
   "metadata": {},
   "source": [
    "# Language Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46409cc-bfb6-4c8d-a12c-262e0b046f26",
   "metadata": {},
   "source": [
    "Clustering experiments with text feature extractors. The idea is to fine-tune some pre-trained transformer models on our dataset and then remove the last layer of the model to cluster on the embedding space projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88390f55-9681-455d-86af-4050b3e5014d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token importances:\n",
      "[CLS]      -> 0.0375\n",
      "Ha         -> 0.0529\n",
      "##ver      -> 0.0526\n",
      "##á        -> 0.1022\n",
      "uma        -> 0.0885\n",
      "festa      -> 0.1248\n",
      "aman       -> 0.0471\n",
      "##hã       -> 0.0980\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "# from transformers import AutoModelForPreTraining\n",
    "from captum.attr import LayerIntegratedGradients\n",
    "\n",
    "# Initializing device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initializing model\n",
    "model = AutoModel.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "model.zero_grad()\n",
    "\n",
    "# Initializing tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', \\\n",
    "                                          do_lower_case=False)\n",
    "\n",
    "# Getting sentence enconding\n",
    "sentence = 'Haverá uma festa amanhã'\n",
    "inputs = tokenizer(sentence, return_tensors='pt')\n",
    "input_ids = inputs['input_ids'].to(device)\n",
    "\n",
    "# Initializing baseline embedding\n",
    "baseline_input_ids = torch.full_like(input_ids, tokenizer.pad_token_id).to(device)\n",
    "\n",
    "# Captum compatible wrapper model. Notice that we need to use a scalar representation for the \n",
    "# [CLS] token so we can evaluate how ir varies with the other tokens (integrated gradients as\n",
    "# the name suggests). In this case, we decided to go for the norm of the embedding vector\n",
    "class WrappedModel(nn.Module):\n",
    "    def __init__(self, model, pad_token_id):\n",
    "        super(WrappedModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.pad_token_id = pad_token_id\n",
    "        \n",
    "    def forward(self, input_ids):\n",
    "        attention_mask = (input_ids != self.pad_token_id).to(device)\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0]\n",
    "        cls_scalar = cls_embedding.norm(p=2, dim=1)\n",
    "        return cls_scalar\n",
    "\n",
    "# Initializing captum compatible model\n",
    "wrapped_model = WrappedModel(model, tokenizer.pad_token_id).to(device)\n",
    "\n",
    "# Initializing integrated gradients\n",
    "lig = LayerIntegratedGradients(wrapped_model, model.embeddings)\n",
    "\n",
    "# Computing attributions and then summing over the embedding dimensions (because we compute \n",
    "# attributions for every dimension of the tokens' embeddings, so we need some kind of\n",
    "# aggregation to idedntify tokens individually)\n",
    "attributions, delta = lig.attribute(inputs=input_ids, baselines=baseline_input_ids, \\\n",
    "                                    return_convergence_delta=True, n_steps=50)\n",
    "attributions = attributions.sum(dim=-1)\n",
    "\n",
    "# Decoding tokens and getting attributions for the [CLS] token\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "attribs = attributions.squeeze().detach().cpu().numpy()\n",
    "\n",
    "# Normalizing to output easier to interpret and because we are more interested in the absolute\n",
    "# importance of tokens rather then their signal\n",
    "attribs = np.abs(attribs)\n",
    "attribs = attribs / attribs.sum()\n",
    "\n",
    "print(\"Token importances:\")\n",
    "for token, score in zip(tokens[:-1], attribs):\n",
    "    print(f\"{token:10} -> {score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
