{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12e8d3d3-5137-4c49-a9c7-4ef40f64c737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe columns: \n",
      "Index(['url', 'thumbnail', 'creation_date', 'modification_date',\n",
      "       'numero_do_item', 'tripticos', 'categoria', 'nome_do_item',\n",
      "       'nome_do_item_dic', 'colecao', 'coletor', 'doador', 'modo_de_aquisicao',\n",
      "       'data_de_aquisicao', 'ano_de_aquisicao', 'data_de_confeccao', 'autoria',\n",
      "       'nome_etnico', 'descricao', 'dimensoes', 'funcao', 'materia_prima',\n",
      "       'tecnica_confeccao', 'descritor_tematico', 'descritor_comum',\n",
      "       'numero_de_pecas', 'itens_relacionados', 'responsavel_guarda',\n",
      "       'inst_detentora', 'povo', 'autoidentificacao', 'lingua',\n",
      "       'estado_de_origem', 'geolocalizacao', 'pais_de_origem', 'exposicao',\n",
      "       'referencias', 'disponibilidade', 'qualificacao', 'historia_adm',\n",
      "       'notas_gerais', 'observacao', 'conservacao', 'image_path'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading dataset\n",
    "ind_df = pd.read_csv('../data/indigenous_collection_processed.csv', index_col='id')\n",
    "print(f'Dataframe columns: \\n{ind_df.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7ccfb45-9155-48a9-b5fa-fbf4e585822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "# Creating skip cell command\n",
    "@register_cell_magic\n",
    "def skip(line, cell):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0915c122-a4e2-4a09-896f-0c1579ae45c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centralizing main imports so we can run the models separately\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from language_training_utils import *\n",
    "\n",
    "# import language_training_utils\n",
    "# importlib.reload(language_training_utils)\n",
    "# from language_training_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a033d0f-bc94-45f8-8d78-5e6b93d6e582",
   "metadata": {},
   "source": [
    "# Language Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46409cc-bfb6-4c8d-a12c-262e0b046f26",
   "metadata": {},
   "source": [
    "Clustering experiments with text feature extractors. The idea is to fine-tune some pre-trained transformer models on our dataset and then remove the last layer of the model to cluster on the embedding space projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88390f55-9681-455d-86af-4050b3e5014d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token importances:\n",
      "[CLS]      -> 0.0675\n",
      "faca       -> 0.0079\n",
      "de         -> 0.0313\n",
      "material   -> 0.0319\n",
      "org        -> 0.0102\n",
      "##ânico    -> 0.0010\n",
      "confec     -> 0.0094\n",
      "##cionado  -> 0.0070\n",
      "com        -> 0.0058\n",
      "ponta      -> 0.0033\n",
      "lance      -> 0.0088\n",
      "##ola      -> 0.0024\n",
      "##da       -> 0.0011\n",
      "de         -> 0.0140\n",
      "ta         -> 0.0139\n",
      "##quara    -> 0.0513\n",
      "e          -> 0.0132\n",
      "cabo       -> 0.0138\n",
      "de         -> 0.0084\n",
      "madeira    -> 0.0112\n",
      "ro         -> 0.0028\n",
      "##li       -> 0.0011\n",
      "##ça       -> 0.0078\n",
      ".          -> 0.0029\n",
      "apresenta  -> 0.0155\n",
      "enga       -> 0.0120\n",
      "##te       -> 0.0002\n",
      "refor      -> 0.0037\n",
      "##çado     -> 0.0029\n",
      "com        -> 0.0105\n",
      "cera       -> 0.0003\n",
      "preta      -> 0.0046\n",
      "revesti    -> 0.0005\n",
      "##do       -> 0.0028\n",
      "de         -> 0.0082\n",
      "fios       -> 0.0042\n",
      "de         -> 0.0092\n",
      "algodão    -> 0.0136\n",
      ",          -> 0.0145\n",
      "arrem      -> 0.0121\n",
      "##ata      -> 0.0068\n",
      "##do       -> 0.0090\n",
      "com        -> 0.0004\n",
      "penas      -> 0.0002\n",
      "vermelhas  -> 0.0001\n",
      "presas     -> 0.0120\n",
      ",          -> 0.0067\n",
      "também     -> 0.0083\n",
      ",          -> 0.0280\n",
      "com        -> 0.0132\n",
      "cera       -> 0.0041\n",
      "preta      -> 0.0033\n",
      ".          -> 0.0152\n",
      "possui     -> 0.0177\n",
      "al         -> 0.0005\n",
      "##ça       -> 0.0056\n",
      "de         -> 0.0202\n",
      "fibra      -> 0.0112\n",
      "presa      -> 0.0047\n",
      "a          -> 0.0239\n",
      "extremidade -> 0.0246\n",
      "proxim     -> 0.0342\n",
      "##al       -> 0.0413\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from captum.attr import LayerIntegratedGradients\n",
    "\n",
    "# Getting device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initializing model, turning it into eval mode and zeroing out the gradients\n",
    "model = AutoModel.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
    "model.eval()\n",
    "model.zero_grad()\n",
    "\n",
    "# Initializing tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', \\\n",
    "                                          do_lower_case=False)\n",
    "\n",
    "# Getting sentences' dataset, dataloader and splits\n",
    "text_dataset = TextDataset(ind_df, tokenizer, max_length=64)\n",
    "batch_size = 2\n",
    "text_dataloader = get_dataloaders(text_dataset, batch_size)\n",
    "\n",
    "data_size = len(text_dataset)\n",
    "train_size = int(0.8*data_size)\n",
    "val_size = int(0.1*data_size)\n",
    "test_size = data_size - train_size - val_size\n",
    "splits = [train_size, val_size, test_size]\n",
    "text_dataset_splits, text_dataloader_splits = get_dataloaders(text_dataset, batch_size, splits)\n",
    "\n",
    "# Initializing captum compatible model and layer integrated gradients. We use layer integrated\n",
    "# gradients here because we can't compute gradients with respect to (discrete) indices\n",
    "# directly, so we compute gradients with respect to the embeddings of the input tokens\n",
    "vanilla_wrapped_model = VanillaWrappedModel(model, tokenizer.pad_token_id, device)\n",
    "vanilla_wrapped_model.eval()\n",
    "\n",
    "lig = LayerIntegratedGradients(vanilla_wrapped_model, model.embeddings)\n",
    "\n",
    "\n",
    "# Iterating through the dataloader to compute embeddings and token attributions\n",
    "text_indices = []\n",
    "text_embeddings = []\n",
    "text_attributions = []\n",
    "for indices, input_ids, labels in text_dataloader:\n",
    "    # Saving indices\n",
    "    text_indices.append(indices)\n",
    "    \n",
    "    # Moving appropriate tensors to device\n",
    "    input_ids = input_ids.to(device)\n",
    "    # labels = labels.to(device)\n",
    "    \n",
    "    # Initializing baseline embedding\n",
    "    baseline_input_ids = torch.full_like(input_ids, tokenizer.pad_token_id).to(device)\n",
    "\n",
    "    # Computing attention mask and the [CLS] token embeddings\n",
    "    attention_mask = (input_ids != tokenizer.pad_token_id).to(device).long()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_embeddings = outputs.last_hidden_state[:, 0]\n",
    "        text_embeddings.append(cls_embeddings.cpu().detach())\n",
    "\n",
    "    # Computing attributions and then summing over the embedding dimensions (because we\n",
    "    # compute attributions for every dimension of the tokens' embeddings, so we need some kind\n",
    "    # of aggregation to idedntify tokens individually)\n",
    "    attributions, delta = lig.attribute(inputs=input_ids, baselines=baseline_input_ids, \\\n",
    "                                        return_convergence_delta=True, n_steps=50)\n",
    "    attributions = attributions.sum(dim=-1)\n",
    "    attributions = attributions.cpu().detach()\n",
    "    text_attributions.append(attributions)\n",
    "    \n",
    "    # Decoding tokens and getting attributions for the [CLS] token for the first sample\n",
    "    sample_input_ids = input_ids[0]\n",
    "    tokens = tokenizer.convert_ids_to_tokens(sample_input_ids.cpu().tolist())\n",
    "    sample_attribution = attributions[0]\n",
    "    \n",
    "    # Normalizing to output easier to interpret and because we are more interested in the\n",
    "    # absolute importance of tokens rather then their signal\n",
    "    sample_attribution = torch.abs(sample_attribution)\n",
    "    if sample_attribution.sum() != 0:\n",
    "        sample_attribution = sample_attribution/sample_attribution.sum()\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    print(\"Token importances:\")\n",
    "    for token, score in zip(tokens[:-1], sample_attribution):\n",
    "        print(f\"{token:10} -> {score:.4f}\")\n",
    "\n",
    "    break\n",
    "\n",
    "# Concatenating the batches\n",
    "text_embeddings = torch.cat(text_embeddings, dim=0)\n",
    "text_attributions = torch.cat(text_attributions, dim=0)\n",
    "text_indices = torch.cat(text_indices, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7da32eb-3789-4ca2-a9fb-dbf32584d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForPreTraining"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
