{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e8d3d3-5137-4c49-a9c7-4ef40f64c737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading dataset\n",
    "ind_df = pd.read_csv('../data/indigenous_collection_processed.csv', index_col='id')\n",
    "print(f'Dataframe columns: \\n{ind_df.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ccfb45-9155-48a9-b5fa-fbf4e585822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "# Creating skip cell command\n",
    "@register_cell_magic\n",
    "def skip(line, cell):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0915c122-a4e2-4a09-896f-0c1579ae45c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centralizing main imports so we can run the models separately\n",
    "import math\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from captum.attr import LayerIntegratedGradients\n",
    "\n",
    "from language_training_utils import *\n",
    "\n",
    "# import language_training_utils\n",
    "# importlib.reload(language_training_utils)\n",
    "# from language_training_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a033d0f-bc94-45f8-8d78-5e6b93d6e582",
   "metadata": {},
   "source": [
    "# Language Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46409cc-bfb6-4c8d-a12c-262e0b046f26",
   "metadata": {},
   "source": [
    "Clustering experiments with text feature extractors. The idea is to fine-tune some pre-trained transformer models on our dataset and then remove the last layer of the model to cluster on the embedding space projections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78453df2-ef8f-4174-bd0c-1bca6db8aef7",
   "metadata": {},
   "source": [
    "## BERTimbau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126eed16-4cdc-4b27-9865-33531d0aae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Studying the distribution of sentence token-lengths on dataframe 'descricao' to make a \n",
    "# decision regarding the max sequence length to use for models (also with memory restrictions)\n",
    "sentence_list = list(ind_df['descricao'].dropna())\n",
    "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', \\\n",
    "                                          do_lower_case=False)\n",
    "token_lengths = [len(tokenizer.tokenize(sentence)) for sentence in sentence_list]\n",
    "token_lengths = np.array(token_lengths)\n",
    "\n",
    "# Printing statistics and finding out that, given the small amount of sentences with more than\n",
    "# 128 tokens, maybe we don't need to run an entire LLM pipeline to reduce sentence lengths. \n",
    "# Having said that, sequence length of 64 is pretty tight and would make us lose around 30%\n",
    "# of our data with no LLM pipeline to reduce sentences\n",
    "print(\"'descricao' token-length statistics:\")\n",
    "print(f\"\"\"Min: {np.min(token_lengths)}; Max: {np.max(token_lengths)}; \n",
    "Mean: {np.mean(token_lengths)}; std: {np.std(token_lengths)}; \n",
    "Mode: {stats.mode(token_lengths)}; \n",
    "Q1: {np.quantile(token_lengths, 0.25)}; \n",
    "Q2: {np.quantile(token_lengths, 0.50)}; \n",
    "Q3: {np.quantile(token_lengths, 0.75)};\"\"\")\n",
    "print(f\"How many sentences longer than 128 tokens? {len(np.where(token_lengths > 128)[0])}\\n\")\n",
    "\n",
    "# Plotting distribution\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.hist(token_lengths, \\\n",
    "         bins=int(len(np.unique(token_lengths))/2))\n",
    "plt.xlabel(\"'descricao' Token-Length\")\n",
    "plt.ylabel(\"(Bin) Count\")\n",
    "plt.title(\"Distribution of 'descricao' Token-Lengths\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ef15eb-d225-448e-b453-c55575cb7435",
   "metadata": {},
   "source": [
    "Due to the very small amount of sentences with more than 128 tokens, and to the fact that, even those, are normally very close to 128 tokens, we decided to postpone the bulding of an LLM pipeline to summarize longer sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924a164f-928d-446a-9da5-1b47265fa48a",
   "metadata": {},
   "source": [
    "### Vanilla Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ff6dff-82d0-4b1b-80be-bf1e25145b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initializing model, turning it into eval mode and zeroing out the gradients\n",
    "model = AutoModel.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "model.zero_grad()\n",
    "\n",
    "# Getting sentences' dataset, dataloader and splits\n",
    "text_ind_df = ind_df[~ind_df['descricao'].isna()]\n",
    "max_length = 128\n",
    "text_dataset = TextDataset(text_ind_df, tokenizer, max_length=max_length)\n",
    "full_batch_size = 1\n",
    "text_dataloader = get_dataloaders(text_dataset, full_batch_size)\n",
    "\n",
    "data_size = len(text_dataset)\n",
    "train_size = int(0.8*data_size)\n",
    "val_size = int(0.1*data_size)\n",
    "test_size = data_size - train_size - val_size\n",
    "splits = [train_size, val_size, test_size]\n",
    "split_batch_size = 32\n",
    "text_dataset_splits, text_dataloader_splits = get_dataloaders(text_dataset, \\\n",
    "                                                              split_batch_size, splits)\n",
    "\n",
    "# Initializing baseline input_ids and attention_mask, and computing its embedding\n",
    "baseline_input_ids = torch.full((1, max_length), tokenizer.pad_token_id).to(device)\n",
    "baseline_input_ids[:, 0] = tokenizer.cls_token_id\n",
    "baseline_input_ids[:, -1] = tokenizer.sep_token_id\n",
    "baseline_attention_mask = torch.zeros_like(baseline_input_ids).to(device)\n",
    "baseline_attention_mask[:, 0] = 1\n",
    "baseline_attention_mask[:, -1] = 1\n",
    "with torch.no_grad():\n",
    "    baseline_outputs = model(input_ids=baseline_input_ids, \\\n",
    "                             attention_mask=baseline_attention_mask)\n",
    "    baseline_embedding = baseline_outputs.last_hidden_state[:, 0]\n",
    "\n",
    "# Initializing captum compatible model and layer integrated gradients. We use layer integrated\n",
    "# gradients here because we can't compute gradients with respect to (discrete) indices\n",
    "# directly, so we compute gradients with respect to the embeddings of the input tokens\n",
    "vanilla_wrapped_model = CaptumWrappedModel(model, tokenizer.pad_token_id, \\\n",
    "                                          baseline_embedding, device, target_type='cos-sim')\n",
    "vanilla_wrapped_model.eval()\n",
    "\n",
    "lig = LayerIntegratedGradients(vanilla_wrapped_model, model.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88390f55-9681-455d-86af-4050b3e5014d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterating through the dataloader to compute embeddings and token attributions\n",
    "analyzed_sample = 0\n",
    "vanilla_bertimbau_indices = []\n",
    "vanilla_bertimbau_embeddings = []\n",
    "vanilla_bertimbau_tokens = []\n",
    "vanilla_bertimbau_attributions = []\n",
    "for indices, input_ids, _ in tqdm(text_dataloader):\n",
    "    # Saving indices\n",
    "    vanilla_bertimbau_indices.append(indices)\n",
    "    \n",
    "    # Moving appropriate tensors to device\n",
    "    input_ids = input_ids.to(device)\n",
    "\n",
    "    # Computing [CLS] token embeddings\n",
    "    cls_embeddings = get_embeddings(model, tokenizer, input_ids, device, fine_tuned=False)\n",
    "    vanilla_bertimbau_embeddings.append(cls_embeddings.cpu().detach())\n",
    "\n",
    "    # Computing attributions\n",
    "    tokens, attributions, delta = get_attributions(lig, tokenizer, input_ids, \\\n",
    "                                                   baseline_input_ids, \\\n",
    "                                                   attrib_aggreg_type='l2-norm', \\\n",
    "                                                   return_tokens=True, \\\n",
    "                                                   verbose=False, \\\n",
    "                                                   sample_num=min(analyzed_sample, \\\n",
    "                                                                  full_batch_size-1))\n",
    "    vanilla_bertimbau_tokens.append(tokens)\n",
    "    vanilla_bertimbau_attributions.append(attributions)\n",
    "\n",
    "    # break\n",
    "    \n",
    "# Concatenating the batches\n",
    "vanilla_bertimbau_indices = np.array(vanilla_bertimbau_indices)\n",
    "vanilla_bertimbau_embeddings = torch.cat(vanilla_bertimbau_embeddings, dim=0)\n",
    "vanilla_bertimbau_tokens = np.array(vanilla_bertimbau_tokens)\n",
    "vanilla_bertimbau_attributions = np.array(torch.cat(vanilla_bertimbau_attributions, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2834f8c9-2de2-44c7-af0f-7e4c26588c04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting data projections\n",
    "vanilla_bertimbau_trimap, vanilla_bertimbau_tsne, \\\n",
    "vanilla_bertimbau_umap = data_projections(np.array(vanilla_bertimbau_embeddings))\n",
    "\n",
    "# Normalizing data for later plot on tool\n",
    "norm_factor = 12\n",
    "vanilla_bertimbau_trimap = normalize(vanilla_bertimbau_trimap, norm_factor)\n",
    "vanilla_bertimbau_tsne = normalize(vanilla_bertimbau_tsne, norm_factor)\n",
    "vanilla_bertimbau_umap = normalize(vanilla_bertimbau_umap, norm_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2a6de6-5213-4f55-951c-69ab95f85256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to plot rows on projection comparison plot\n",
    "def row_scatter_plot(projs, proj_names, row, color, rows=1, cols=3):\n",
    "    for i, (proj, proj_name) in enumerate(zip(projs, proj_names)):\n",
    "        plt.subplot(rows, cols, i+1+(cols*(row-1)))\n",
    "        plt.scatter(proj[:, 0], proj[:, 1], c=color)\n",
    "        plt.title(f\"{proj_name}\")\n",
    "        plt.xlabel(\"\")\n",
    "        plt.ylabel(\"\")\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "\n",
    "# Visualizing resulting projections\n",
    "plt.figure(figsize=(10,4))\n",
    "# plt.suptitle('Comparing Projections of BERTimbau Models')\n",
    "\n",
    "# Plotting vanilla BERTimbau projections\n",
    "projs = [vanilla_bertimbau_trimap, vanilla_bertimbau_tsne, vanilla_bertimbau_umap]\n",
    "proj_names = ['Vanilla BERTimbau with TriMap', 'Vanilla BERTimbau with t-SNE', \\\n",
    "              'Vanilla BERTimbau with UMAP']\n",
    "row_scatter_plot(projs, proj_names, 1, 'b', 1, )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e8e1a7-e593-405e-8ba0-947a383506a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Saving outputs for visualization tool (trimap)\n",
    "_ = saving_outputs(vanilla_bertimbau_trimap, vanilla_bertimbau_tokens, \\\n",
    "                   vanilla_bertimbau_attributions, vanilla_bertimbau_indices, \\\n",
    "                   save_file='vanilla_bertimbau_trimap.csv')\n",
    "\n",
    "# Saving outputs for visualization tool (umap)\n",
    "_ = saving_outputs(vanilla_bertimbau_umap, vanilla_bertimbau_tokens, \\\n",
    "                   vanilla_bertimbau_attributions, vanilla_bertimbau_indices, \\\n",
    "                   save_file='vanilla_bertimbau_umap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deb8fa1-b3cd-4e8c-add2-f595995de51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning memory\n",
    "clean_mem([vanilla_bertimbau_embeddings, vanilla_bertimbau_trimap, vanilla_bertimbau_tsne, \\\n",
    "vanilla_bertimbau_umap, vanilla_bertimbau_attributions, vanilla_bertimbau_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f632b765-ef9d-453e-a9fc-76b55f8cd45a",
   "metadata": {},
   "source": [
    "### Unsupervised SimCSE (Contrastive Learning with no Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac0bf6a-842d-4149-9979-910b2515111f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initializing SimCSE model and auxiliar variables\n",
    "dropout_prob = 0.1\n",
    "model = SimCSEModel(model, tokenizer.pad_token_id, device, dropout_prob)\n",
    "lr = 2e-5\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "epochs = 15\n",
    "temperature = 0.05\n",
    "patience = max(4, math.ceil(epochs*0.1))\n",
    "model_name = 'simcse_bertimbau'\n",
    "train_dataloader, val_dataloader, test_dataloader = text_dataloader_splits\n",
    "\n",
    "# Calling training process\n",
    "simcse_indices, simcse_embeddings, \\\n",
    "train_losses, val_losses = contrastive_training_loop(model, optimizer, train_dataloader, \\\n",
    "                                                     val_dataloader, device, epochs, \\\n",
    "                                                     temperature, patience, model_name)\n",
    "\n",
    "plot_training_curves(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ef1adf-3894-4965-afef-a2e679eac9eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Recomputing baseline embedding for fine-tuned model\n",
    "with torch.no_grad():\n",
    "    baseline_embedding = model(input_ids=baseline_input_ids, train=False)\n",
    "\n",
    "# Intanciating attribution computation class for fine-tuned model\n",
    "simcse_wrapped_model = CaptumWrappedModel(model, tokenizer.pad_token_id, \\\n",
    "                                          baseline_embedding, device, target_type='cos-sim')\n",
    "simcse_wrapped_model.eval()\n",
    "lig = LayerIntegratedGradients(simcse_wrapped_model, model.embeddings)\n",
    "\n",
    "# Iterating through the dataloader to compute token attributions for fine-tuned model\n",
    "analyzed_sample = 0\n",
    "simcse_bertimbau_indices = []\n",
    "simcse_bertimbau_embeddings = []\n",
    "simcse_bertimbau_attributions = []\n",
    "for indices, input_ids, _ in tqdm(text_dataloader):\n",
    "    # Saving indices\n",
    "    simcse_bertimbau_indices.append(indices)\n",
    "    \n",
    "    # Moving appropriate tensors to device\n",
    "    input_ids = input_ids.to(device)\n",
    "\n",
    "    # Computing [CLS] token embeddings\n",
    "    cls_embeddings = get_embeddings(model, tokenizer, input_ids, device, fine_tuned=True)\n",
    "    simcse_bertimbau_embeddings.append(cls_embeddings.cpu().detach())\n",
    "\n",
    "    # Computing attributions\n",
    "    attributions, delta = get_attributions(lig, tokenizer, input_ids, baseline_input_ids, \\\n",
    "                                           attrib_aggreg_type='l2-norm', \\\n",
    "                                           return_tokens=False, verbose=False, \\\n",
    "                                           sample_num=min(analyzed_sample, full_batch_size-1))\n",
    "    simcse_bertimbau_attributions.append(attributions)\n",
    "\n",
    "# Concatenating the batches\n",
    "simcse_bertimbau_indices = np.array(simcse_bertimbau_indices)\n",
    "simcse_bertimbau_embeddings = torch.cat(simcse_bertimbau_embeddings, dim=0)\n",
    "simcse_bertimbau_attributions = np.array(torch.cat(simcse_bertimbau_attributions, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b75b63-07ab-4a90-bd13-7c49207d2b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting data projections\n",
    "simcse_bertimbau_trimap, simcse_bertimbau_tsne, \\\n",
    "simcse_bertimbau_umap = data_projections(simcse_bertimbau_embeddings)\n",
    "\n",
    "# Normalizing data for later plot on tool\n",
    "norm_factor = 12\n",
    "simcse_bertimbau_trimap = normalize(simcse_bertimbau_trimap, norm_factor)\n",
    "simcse_bertimbau_tsne = normalize(simcse_bertimbau_tsne, norm_factor)\n",
    "simcse_bertimbau_umap = normalize(simcse_bertimbau_umap, norm_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e04054e-2c39-435a-bffd-58405a73fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing resulting projections\n",
    "plt.figure(figsize=(10,6))\n",
    "# plt.suptitle('Comparing Projections of BERTimbau Models')\n",
    "\n",
    "# Plotting SimCSE BERTimbau projections\n",
    "projs = [simcse_bertimbau_trimap, simcse_bertimbau_tsne, simcse_bertimbau_umap]\n",
    "proj_names = ['SimCSE BERTimbau with TriMap', 'SimCSE BERTimbau with t-SNE', \\\n",
    "              'SimCSE BERTimbau with UMAP']\n",
    "row_scatter_plot(projs, proj_names, 1, 'b', 1, )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4877fdc2-2f86-4af4-818e-60a297f4bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving outputs for visualization tool (trimap)\n",
    "_ = saving_outputs(simcse_bertimbau_trimap, vanilla_brtimbau_tokens, \\\n",
    "                   simcse_bertimbau_attributions, simcse_bertimbau_indices, \\\n",
    "                   save_file='simcse_bertimbau_trimap.csv')\n",
    "\n",
    "# Saving outputs for visualization tool (umap)\n",
    "_ = saving_outputs(simcse_bertimbau_umap, vanilla_brtimbau_tokens, \\\n",
    "                   simcse_bertimbau_attributions, simcse_bertimbau_indices, \\\n",
    "                   save_file='simcse_bertimbau_umap.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
