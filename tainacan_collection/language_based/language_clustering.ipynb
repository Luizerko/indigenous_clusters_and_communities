{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12e8d3d3-5137-4c49-a9c7-4ef40f64c737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe columns: \n",
      "Index(['url', 'thumbnail', 'creation_date', 'modification_date',\n",
      "       'numero_do_item', 'tripticos', 'categoria', 'nome_do_item',\n",
      "       'nome_do_item_dic', 'colecao', 'coletor', 'doador', 'modo_de_aquisicao',\n",
      "       'data_de_aquisicao', 'ano_de_aquisicao', 'data_de_confeccao', 'autoria',\n",
      "       'nome_etnico', 'descricao', 'dimensoes', 'funcao', 'materia_prima',\n",
      "       'tecnica_confeccao', 'descritor_tematico', 'descritor_comum',\n",
      "       'numero_de_pecas', 'itens_relacionados', 'responsavel_guarda',\n",
      "       'inst_detentora', 'povo', 'autoidentificacao', 'lingua',\n",
      "       'estado_de_origem', 'geolocalizacao', 'pais_de_origem', 'exposicao',\n",
      "       'referencias', 'disponibilidade', 'qualificacao', 'historia_adm',\n",
      "       'notas_gerais', 'observacao', 'conservacao', 'image_path'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading dataset\n",
    "ind_df = pd.read_csv('../data/indigenous_collection_processed.csv', index_col='id')\n",
    "print(f'Dataframe columns: \\n{ind_df.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7ccfb45-9155-48a9-b5fa-fbf4e585822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "# Creating skip cell command\n",
    "@register_cell_magic\n",
    "def skip(line, cell):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0915c122-a4e2-4a09-896f-0c1579ae45c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centralizing main imports so we can run the models separately\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from language_training_utils import *\n",
    "\n",
    "# import language_training_utils\n",
    "# importlib.reload(language_training_utils)\n",
    "# from language_training_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a033d0f-bc94-45f8-8d78-5e6b93d6e582",
   "metadata": {},
   "source": [
    "# Language Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46409cc-bfb6-4c8d-a12c-262e0b046f26",
   "metadata": {},
   "source": [
    "Clustering experiments with text feature extractors. The idea is to fine-tune some pre-trained transformer models on our dataset and then remove the last layer of the model to cluster on the embedding space projections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78453df2-ef8f-4174-bd0c-1bca6db8aef7",
   "metadata": {},
   "source": [
    "## BERTimbau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924a164f-928d-446a-9da5-1b47265fa48a",
   "metadata": {},
   "source": [
    "### Vanilla Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5ff6dff-82d0-4b1b-80be-bf1e25145b5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from captum.attr import LayerIntegratedGradients\n",
    "\n",
    "# Getting device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initializing model, turning it into eval mode and zeroing out the gradients\n",
    "model = AutoModel.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "model.zero_grad()\n",
    "\n",
    "# Initializing tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', \\\n",
    "                                          do_lower_case=False)\n",
    "\n",
    "# Getting sentences' dataset, dataloader and splits\n",
    "text_ind_df = ind_df[~ind_df['descricao'].isna()]\n",
    "max_length = 64\n",
    "text_dataset = TextDataset(ind_df, tokenizer, max_length=64)\n",
    "batch_size = 3\n",
    "text_dataloader = get_dataloaders(text_dataset, batch_size)\n",
    "\n",
    "data_size = len(text_dataset)\n",
    "train_size = int(0.8*data_size)\n",
    "val_size = int(0.1*data_size)\n",
    "test_size = data_size - train_size - val_size\n",
    "splits = [train_size, val_size, test_size]\n",
    "text_dataset_splits, text_dataloader_splits = get_dataloaders(text_dataset, batch_size, splits)\n",
    "\n",
    "# Initializing baseline input_ids and attention_mask, and computing its embedding\n",
    "baseline_input_ids = torch.full((1, max_length), tokenizer.pad_token_id).to(device)\n",
    "baseline_input_ids[:, 0] = tokenizer.cls_token_id\n",
    "baseline_input_ids[:, -1] = tokenizer.sep_token_id\n",
    "baseline_attention_mask = torch.zeros_like(baseline_input_ids).to(device)\n",
    "baseline_attention_mask[:, 0] = 1\n",
    "baseline_attention_mask[:, -1] = 1\n",
    "with torch.no_grad():\n",
    "    baseline_outputs = model(input_ids=baseline_input_ids, \\\n",
    "                             attention_mask=baseline_attention_mask)\n",
    "    baseline_embedding = baseline_outputs.last_hidden_state[:, 0]\n",
    "\n",
    "# Initializing captum compatible model and layer integrated gradients. We use layer integrated\n",
    "# gradients here because we can't compute gradients with respect to (discrete) indices\n",
    "# directly, so we compute gradients with respect to the embeddings of the input tokens\n",
    "vanilla_wrapped_model = VanillaWrappedModel(model, tokenizer.pad_token_id, \\\n",
    "                                            baseline_embedding, device, target_type='cos-sim')\n",
    "vanilla_wrapped_model.eval()\n",
    "\n",
    "lig = LayerIntegratedGradients(vanilla_wrapped_model, model.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88390f55-9681-455d-86af-4050b3e5014d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                 | 0/6989 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token importances:\n",
      "faca                 -> 0.0812\n",
      "de                   -> 0.0394\n",
      "material             -> 0.0217\n",
      "orgânico             -> 0.0357\n",
      "confeccionado        -> 0.0236\n",
      "com                  -> 0.0080\n",
      "ponta                -> 0.0117\n",
      "lanceolada           -> 0.0295\n",
      "de                   -> 0.0081\n",
      "taquara              -> 0.0209\n",
      "e                    -> 0.0076\n",
      "cabo                 -> 0.0099\n",
      "de                   -> 0.0073\n",
      "madeira              -> 0.0084\n",
      "roliça               -> 0.0213\n",
      ".                    -> 0.0098\n",
      "apresenta            -> 0.0125\n",
      "engate               -> 0.0181\n",
      "reforçado            -> 0.0146\n",
      "com                  -> 0.0059\n",
      "cera                 -> 0.0073\n",
      "preta                -> 0.0070\n",
      "revestido            -> 0.0152\n",
      "de                   -> 0.0076\n",
      "fios                 -> 0.0078\n",
      "de                   -> 0.0068\n",
      "algodão              -> 0.0085\n",
      ",                    -> 0.0074\n",
      "arrematado           -> 0.0308\n",
      "com                  -> 0.0075\n",
      "penas                -> 0.0095\n",
      "vermelhas            -> 0.0076\n",
      "presas               -> 0.0100\n",
      ",                    -> 0.0095\n",
      "também               -> 0.0105\n",
      ",                    -> 0.0114\n",
      "com                  -> 0.0081\n",
      "cera                 -> 0.0085\n",
      "preta                -> 0.0091\n",
      ".                    -> 0.0142\n",
      "possui               -> 0.0154\n",
      "alça                 -> 0.0227\n",
      "de                   -> 0.0122\n",
      "fibra                -> 0.0219\n",
      "presa                -> 0.0215\n",
      "a                    -> 0.0278\n",
      "extremidade          -> 0.0386\n",
      "proximal             -> 0.2404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterating through the dataloader to compute embeddings and token attributions\n",
    "text_indices = []\n",
    "text_embeddings = []\n",
    "text_attributions = []\n",
    "for indices, input_ids, labels in tqdm(text_dataloader):\n",
    "    # Saving indices\n",
    "    text_indices.append(indices)\n",
    "    \n",
    "    # Moving appropriate tensors to device\n",
    "    input_ids = input_ids.to(device)\n",
    "    # labels = labels.to(device)\n",
    "\n",
    "    # Computing [CLS] token embeddings\n",
    "    cls_embeddings = get_embeddings(model, tokenizer, input_ids, device)\n",
    "    text_embeddings.append(cls_embeddings.cpu().detach())\n",
    "\n",
    "    # Computing attributions\n",
    "    attributions, delta = get_attributions(lig, tokenizer, input_ids, baseline_input_ids, \\\n",
    "                                           attrib_aggreg_type='l2-norm', verbose=True, \\\n",
    "                                           sample_num=0)\n",
    "    text_attributions.append(attributions)\n",
    "\n",
    "    break\n",
    "\n",
    "# Concatenating the batches\n",
    "text_embeddings = torch.cat(text_embeddings, dim=0)\n",
    "text_attributions = torch.cat(text_attributions, dim=0)\n",
    "text_indices = torch.cat(text_indices, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7da32eb-3789-4ca2-a9fb-dbf32584d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForPreTraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f632b765-ef9d-453e-a9fc-76b55f8cd45a",
   "metadata": {},
   "source": [
    "### SimCSE (Contrastive Learning with no Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac0bf6a-842d-4149-9979-910b2515111f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
